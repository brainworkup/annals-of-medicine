<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
  <front>
    <article-meta>
      <title-group>
        <article-title>Diagnosis of Attention-Deficit/Hyperactivity Disorder in
Adults</article-title>
        <subtitle>A Systematic Review</subtitle>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Trampush</surname>
            <given-names>Joey</given-names>
          </name>
          <string-name>Joey Trampush</string-name>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <xref ref-type="aff" rid="aff-1">a</xref>
          <xref ref-type="corresp" rid="cor-1">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Peterson</surname>
            <given-names>Brad</given-names>
          </name>
          <string-name>Brad Peterson</string-name>
          <xref ref-type="aff" rid="aff-2">b</xref>
        </contrib>
      </contrib-group>
      <aff id="aff-1">
        <institution-wrap>
          <institution>USC</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-2">
        <institution-wrap>
          <institution>CHLA</institution>
        </institution-wrap>
      </aff>
      <author-notes>
        <corresp id="cor-1"/>
      </author-notes>
      <history/>
    </article-meta>
  </front>
  <body>
    <sec id="abstract">
      <title>Abstract</title>
      <p><bold>Objectives.</bold> This evidence report synthesizes the
  results of evaluations of available tools for diagnosing attention
  deficit/hyperactivity disorder in adults to inform patients,
  clinicians, and policy makers.</p>
      <p><bold>Review methods.</bold> Following a detailed published
  protocol and informed by a technical expert panel, we reviewed the
  evidence for diagnostic tools. In October 2024, we searched nine
  research databases from inception, research and guideline registries,
  reference-mined existing reviews and practice guidelines, and
  consulted with experts to identify evaluations that compared tools
  used for the diagnosis of ADHD in people of 18 years or older to a
  clinical diagnosis. The review will be updated during peer review.
  Registration CRD42025638106.</p>
      <p><bold>Results.</bold> We identified 117 studies evaluating the
  diagnostic performance of self-report questionnaires, peer review
  questionnaires, neuropsychological tests, neuroimaging,
  electroencephalogram (EEG), diverse biomarkers, clinician tools,
  combinations of modalities, and tools to identify feigning ADHD.</p>
      <p>We found few direct performance comparisons between tests; the
  strength of evidence (SoE) was often insufficient for evidence
  statements. There was low SoE for lower clinical misdiagnosis rates
  (false positive rate in clinical samples) for self-report versus both
  clinician tools and neuropsychological tests, and for combinations of
  input versus neuropsychological tests alone. For sensitivity, results
  favored self-report and combinations of input over neuropsychological
  tests alone and studies found no difference between self-reports and
  clinician tools. For specificity, results favored combinations of
  input over neuropsychological tests alone, and self-reports over
  clinician tools.</p>
      <p>Combinations of input indicated a fair rate of clinical false
  positive rates, good sensitivity, and acceptable specificity.
  Self-reports showed good sensitivity and specificity, but often not
  both in the same study; administration time was short, but agreement
  with other raters was limited. Peer reports showed limited
  specificity. Neuropsychological tests reported substantial false
  positive rates in clinical samples, acceptable sensitivity and
  specificity, and short administration times. The small number of
  neuroimaging studies and EEG studies reported acceptable sensitivity
  and specificity, and short administration time. Clinician tools
  reported fair sensitivity. All results were rated low SoE. Results for
  all other key outcomes (e.g., diagnostic concordance between primary
  care clinicians and specialists) were rated insufficient, either due
  to lack of studies or wide variation in results.</p>
      <p><bold>Conclusions.</bold> A substantial volume of research for
  diagnostic performance of tests for ADHD in adults exists, in
  particular for self-report questionnaires and neuropsychological
  tests. Multiple different diagnostic modalities have been explored and
  combinations of input appear particularly promising. Despite the
  volume, evidence was insufficient for several key outcomes.
  Performance is associated with the comparator and whether diagnostic
  tools aim to distinguish between adults with ADHD and neurotypical
  adults, or adults with other clinical conditions.</p>
    </sec>
    <sec id="introduction">
      <title>Introduction</title>
      <sec id="background">
        <title>Background</title>
        <p>Attention-deficit/hyperactivity disorder (ADHD) is characterized
    by persistent symptoms in the domains of inattention, hyperactivity,
    and impulsivity that often begin in childhood.<sup>1</sup>
    Clinically significant symptoms, especially inattention, persist
    into adulthood in most individuals.<sup>1-5</sup> The lifetime
    prevalence of ADHD is approximately 5.3%,<sup>6</sup> although
    epidemiological studies that have not required a childhood onset
    have suggested that its prevalence in adults may be as high as seven
    percent.<sup>7-10</sup> Many adults with ADHD adopt lifestyles that
    help compensate for their symptoms, they often need to exert excess
    energy to overcome impairments. Impaired productivity because of
    poor time management, procrastination, and distractibility can limit
    work productivity and lower overall quality of life.<sup>11</sup>
    Affected adults are often distressed by their inability to realize
    their full potential and by persistent symptoms of restlessness,
    erratic moods, and poor self-esteem.<sup>11, 12</sup></p>
        <p>ADHD is most often first diagnosed in elementary or middle school
    age years or, less commonly, in high school or college when
    increasing academic demands surpass the attentional capacities of
    the affected person. ADHD can also be first diagnosed in adulthood,
    when impairments in attention, organization, and impulsivity produce
    recurrent problems with occupational, social, or family functioning.
    Adult diagnosis is often difficult because the outward
    manifestations most readily evident to others, especially
    hyperactivity and impulsivity, often improve during adolescence and
    no longer meet diagnostic criteria.<sup>13</sup> The symptoms of
    inattention (e.g., easy distractibility, poor organization, being
    “spacey,” avoiding and trouble completing tasks that require
    sustained attention, losing things, forgetfulness) are more subtle
    and may not reach the level of obvious functional impairment until
    adulthood, within an occupational setting or a marriage.</p>
        <p>The diagnosis of ADHD in adults, as in childhood, is complicated
    by the overlap of symptoms with other disorders.<sup>14, 15</sup>
    Attention and concentration, for example, can be impaired in persons
    who have depression, bipolar disorder, anxiety, psychosis,
    post-traumatic stress disorder, or substance abuse, or in adults who
    need to perform well in an overdemanding environment or who are
    highly stressed<sup>16</sup> or sleep-deprived. Hyperactivity can be
    confused with anxiety-related behaviors and the excessive movements
    of tic and obsessive-compulsive disorders. Impulsivity is often
    prominent in bipolar and substance use disorders. The accurate
    diagnosis of adult ADHD is further complicated by individuals who
    seek stimulant medications to aid cognitive performance, especially
    college students and highly driven working
    professionals.<sup>17</sup> Stimulants have long been known to
    improve sustained attention and reduce distractibility in healthy
    individuals who do not have ADHD,<sup>18-22</sup> which may prompt
    success-oriented individuals to feign symptoms in diagnostic
    interviews, self-reports, or neuropsychological test assessments to
    obtain stimulant medications, and some students feign illness to
    receive academic accommodations, such as extended time on tests,
    tutoring services, and alternative courses that can improve their
    grades.</p>
        <p>Claims of exceptional diagnostic performance of these tools, the
    differing measures of performance, and the differing performance
    characteristics of different versions of a given tool,<sup>23</sup>
    are controversial and often confusing to clinicians, patients, and
    other stakeholders. In addition, whether the performance of
    diagnostic tools varies with the characteristics of the participants
    with ADHD or comparator sample is unknown.<sup>24</sup> These
    diagnostic challenges can complicate the accurate and reliable
    diagnosis of adult ADHD even for experienced mental health
    clinicians.</p>
        <p>Thus, despite established criteria in the Diagnostic and
    Statistical Manual of Mental Disorders, Fifth Edition (DSM-5),
    diagnosing ADHD in adults remains challenging due to the frequent
    absence of hyperactivity and impulsivity symptoms, the subtlety of
    inattention symptoms, the inaccuracy of recall in adults for their
    retrospective assessments of ADHD symptoms in childhood (required to
    meet DSM-5 diagnostic criteria), the common symptom overlap with
    other mental health conditions,<sup>13-15</sup> and the large number
    of individuals,<sup>17-22</sup> including healthy college
    students,<sup>25, 26</sup> who feign symptoms to obtain stimulant
    medications. Moreover, the DSM-5 diagnostic criteria, developed
    primarily for children, may not be equally suitable for adult
    diagnosis, and its requirement that symptoms begin before age 12 has
    been debated.<sup>27-31</sup> The absence of a true and undisputed
    “gold-standard” to verify an ADHD diagnosis, the variability in
    performance of diagnostic tools among clinicians and settings, and
    the lack of clear practice guidelines further add to diagnostic
    complexity.<sup>32-35</sup></p>
        <p>Furthermore, the diagnosis of ADHD in adults is often made not by
    mental health specialists, but by primary care physicians and nurse
    practitioners,<sup>36</sup> who may benefit particularly from
    accurate diagnostic aids. Further, the dispensing of ADHD
    medications to adults has increased steadily over time.<sup>30</sup>
    The accuracy of diagnosis directly affects the management and
    treatment of ADHD and may help prevent medication misuse,
    highlighting the need for effective diagnostic tools and guidelines.
    The existing standards and guidelines for diagnosing ADHD in adults
    are limited, however, and the use of diagnostic tools and
    assessments varies widely in practice.<sup>37-39</sup> No clinical
    practice guidelines for the diagnosis of adults with ADHD have thus
    far been developed in the United States, though one is in
    development.<sup>40</sup> Moreover, the diagnostic accuracy of tools
    and assessments used in adult ADHD diagnosis is unclear, and their
    performance may vary depending on the characteristics of the ADHD
    participants and comparator samples.<sup>23, 24</sup></p>
      </sec>
      <sec id="purpose-and-scope">
        <title>Purpose and Scope</title>
        <p>This systematic review aims to provide a comprehensive and
    unbiased assessment of diagnostic tools used to diagnose ADHD in
    adults to inform patients, clinicians, and policy makers.
    Commissioned by the Food and Drug Administration (FDA), this Agency
    for Healthcare Research and Quality (AHRQ) report documents the
    evidence for the diagnostic performance of existing tools for ADHD.
    We explore the effects of setting and participant characteristics
    that may influence the diagnostic performance of available tools. A
    contextual question is which tools are frequently being used in
    current clinical practice.</p>
      </sec>
    </sec>
    <sec id="methods">
      <title>Methods</title>
      <p>The systematic review followed a protocol that outlines the methods
  in detail.<sup>41</sup> The methodology followed the EPC Methods
  Guide.<sup>42</sup> The review is registered as CRD42025638106. The
  project was supported by a technical expert panel (TEP) to provide
  different perspectives of a broad group of interest holders to ensure
  the evidence report is relevant to a large audience. The panel
  included multi-disciplinary experts in adult ADHD and well as
  advocates considering the needs of affected patients as well as family
  members.</p>
      <sec id="key-questions">
        <title>Key Questions</title>
        <p>The systematic review was guided by the following key
    questions:</p>
        <list list-type="bullet">
          <list-item>
            <p>Key Question 1. What is the comparative diagnostic accuracy,
        unintended consequences, and impact of tools that can be used in
        the primary care practice setting or by specialists to diagnose
        ADHD among adults?</p>
            <list list-type="bullet">
              <list-item>
                <p>Key Question 1a: How does the comparative diagnostic
            accuracy of these tools vary by clinical setting, including
            primary care or specialty clinic, or patient
            characteristics, including age, sex, cultural background,
            and risk factors associated with ADHD?</p>
              </list-item>
            </list>
          </list-item>
        </list>
        <p>In addition, a contextual question provided additional
    information:</p>
        <list list-type="bullet">
          <list-item>
            <p>Contextual Question. How frequently are the various tools to
        diagnose ADHD in adults currently being used?</p>
          </list-item>
        </list>
        <p>We addressed the key question in a systematic review documented
    in detail in the result chapter. Information pertaining to the
    context question was incorporated into the discussion.</p>
      </sec>
      <sec id="logic-model">
        <title>Logic Model</title>
        <p>Figure 1 illustrates the scope of the review.</p>
        <p><named-content id="_Toc188201399" content-type="anchor"/>Figure
    1. Logic Model for Diagnosis of ADHD in Adults</p>
        <fig>
          <caption>
            <p>A diagram of a diagram AI-generated content may be
      incorrect.</p>
          </caption>
          <graphic mimetype="image" mime-subtype="png" xlink:href="media/image1.png"/>
        </fig>
        <p>Notes: ADHD attention deficit hyperactivity disorder, KQ key
    question</p>
        <p>The model shows the population of interest (adults with suspected
    ADHD) and depicts the key question (diagnostic test performance) and
    sub-question (effect modifiers). The model also shows outcomes,
    ranging from side effects of the testing modality (e.g., relevant
    for invasive tests), to intermediate outcomes such as the diagnostic
    accuracy established in the study, to final outcomes such as the
    impact of a diagnosing or misdiagnosing ADHD.</p>
      </sec>
      <sec id="search-strategy">
        <title>Search Strategy</title>
        <p>The literature search used a combination of known tests to
    diagnose ADHD and general search terms for diagnostic accuracy
    studies to identify novel tools. In October 2024 we searched PubMed
    (biomedical literature), EMBASE (pharmacology emphasis), and
    PsycINFO (psychological research) without search date restriction
    and restricted to English language. The search strategy was peer
    reviewed within the EPC program. We used existing reviews for
    reference-mining; these were identified through the same databases
    plus searching the Cochrane Database of Systematic Reviews, Campbell
    Collaboration, and PROSPERO. We also searched the ECRI repository,
    G-I-N, and ClinicalKey for published guidelines and used these for
    reference-mining cited literature. All searches will be updated
    during the public comment period.</p>
        <p>In addition, we leveraged technical experts to ensure that
    relevant research studies had been identified. We provided a list of
    included studies, together with all associated publications, and a
    list of excluded studies to facilitate this process. A Supplemental
    Evidence And Data for Systematic Reviews (SEADs) portal was
    available from January 10 to February 4 2025 for this review.
    Additional data and publications suggested to us from any source,
    including peer and public review, will be screened applying the
    outlined eligibility criteria. The search will be updated during
    peer review.</p>
      </sec>
      <sec id="inclusionexclusion-criteria">
        <title>Inclusion/Exclusion Criteria</title>
        <p>The eligibility criteria for this review are shown in Table
    1.</p>
        <p><named-content id="_Toc188201365" content-type="anchor"/>Table
    1. Eligibility Criteria</p>
        <table-wrap>
          <table>
            <colgroup>
              <col width="19%"/>
              <col width="43%"/>
              <col width="37%"/>
            </colgroup>
            <thead>
              <tr>
                <th/>
                <th>
                  <bold>Inclusion Criteria</bold>
                </th>
                <th>
                  <bold>Exclusion Criteria</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Population</td>
                <td>Adults 18 years and older with symptoms of ADHD and
            without the diagnosis of ADHD; studies reporting on broader
            age samples, had to report separately for adults</td>
                <td>Individuals 17 years of age or younger unless findings
            are reported separately for older participants</td>
              </tr>
              <tr>
                <td>Intervention</td>
                <td>Any ADHD diagnostic tool used for the diagnosis of ADHD
            in adults</td>
                <td>Studies not reporting on diagnostic performance;
            non-English language questionnaires and interview
            guides</td>
              </tr>
              <tr>
                <td>Comparator</td>
                <td>Confirmation of diagnosis by a specialist (reference
            standard), such as a psychologist, psychiatrist or other
            healthcare provider using a well validated and reliable
            process of confirming a clinical diagnosis of ADHD</td>
                <td>Comparison to diagnosis with another diagnostic
            instrument</td>
              </tr>
              <tr>
                <td>Outcome</td>
                <td>Diagnostic accuracy (e.g., sensitivity, specificity,
            accuracy, area under the curve, positive predictive value,
            negative predictive value, likelihood ratios, false
            positives, false negatives); unintended consequences and
            impact associated with diagnosing ADHD</td>
                <td>Provider opinion of tests, cost without performance
            measure</td>
              </tr>
              <tr>
                <td>Timing</td>
                <td>Diagnostic follow-up must be completed before treatment
            is initiated</td>
                <td>Any other timing</td>
              </tr>
              <tr>
                <td>Setting</td>
                <td>Primary or specialty care settings, including
            telehealth</td>
                <td>Settings where diagnosis is for nonclinical or not
            research purposes</td>
              </tr>
              <tr>
                <td>Study Design</td>
                <td>Diagnostic accuracy studies</td>
                <td>
                  <p>Editorials, nonsystematic reviews, letters, case
            series, case reports, pre-post studies.</p>
                  <p>Systematic reviews were not eligible for inclusion but
            were retained for reference mining</p>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Included ADHD tests were not limited to a set of pre-specified
    tools; instead, the review documents all tools that have been
    evaluated in the scientific literature and for which diagnostic
    accuracy evidence exists. Studies had to compare to a clinical
    diagnosis made by a clinician in a formal diagnostic interview,
    typically enhanced by information from patient questionnaires. We
    searched databases from inception and we did not apply any
    publication date restrictions. Studies with data exclusively
    published in non-English language publications were excluded to
    ensure transparency. We obtained all published reports providing
    data on a study (a study is defined by the included participants),
    including trial records and multiple publications, and consolidated
    the information into one study record.</p>
        <sec id="screening-process">
          <title>Screening Process</title>
          <p>We used an online database designed for systematic reviews to
      screen the literature search output. The team designed detailed
      citation and full text screening forms to ensure a transparent,
      consistent, and unambiguous approach. All citations were screened
      by two independent literature reviewers. Citations found to be
      potentially relevant by at least one reviewer were obtained as
      full text. All citations were also screened by a DistillerSR
      software machine learning algorithm trained by the human reviewers
      to ensure that no relevant citation was missed. Any citations
      identified as potentially relevant by the algorithm that were not
      selected for full text publication review were rescreened for
      relevance by an independent literature reviewer.</p>
          <p>Full text screening applied the detailed eligibility criteria.
      Training ensured a shared understanding of all inclusion and
      exclusion criteria. Full text publications were screened by two
      independent reviewers to reduce errors and bias, and any
      discrepancy was resolved through discussion in the review team.
      The screening decisions and reasons for exclusion of publications
      were tracked in the online database and citation management
      software. These citations were shared with the technical expert
      panel and were documented with the review to ensure that the
      literature flow was transparent and objective.</p>
        </sec>
      </sec>
      <sec id="data-extraction-and-abstraction">
        <title>Data Extraction and Abstraction</title>
        <p>We captured detailed information about eligible studies. One
    literature reviewer extracted data and categorized information where
    relevant, and an experienced methodologist checked the data for
    accuracy and completeness. We designed and pilot tested a detailed
    form in the software DistillerSR to ensure accuracy and minimize
    ambiguity.</p>
        <p>The data abstraction documented the targeted population and
    characteristics of all included participants (participants with ADHD
    and those without). We documented the clinical setting, method of
    establishing the reference standard (a clinical ADHD diagnosis), and
    diagnostic tool characteristics (format, name of the tool, employed
    cut offs, use of a training and validation set). We collected data
    for a diagnostic meta-analysis where possible (i.e., number of false
    positives, number of false negatives) along with the summary
    diagnosis accuracy measures reported by the authors such as
    sensitivity, specificity, area under the curve, positive predictive
    value. We differentiated between the diagnostic accuracy to diagnose
    ADHD and the diagnostic accuracy to detect faking ADHD. For all
    studies reporting multiple results, we selected the best accuracy
    performance model (either based on the authors’ opinion, accuracy
    data, or trying to maximize sensitivity and specificity
    simultaneously).</p>
      </sec>
      <sec id="risk-of-bias-assessment">
        <title><named-content id="_Toc193750145" content-type="anchor"/>2.6
    Risk of Bias Assessment</title>
        <p>The critical appraisal for individual studies applied criteria
    consistent with QUADAS 2.<sup>43</sup> QUADAS-2 evaluates four
    domains: <italic>patient selection</italic>, <italic>index
    test</italic> characteristics, <italic>reference standard</italic>
    quality, as well as <italic>flow and timing:</italic></p>
        <list list-type="bullet">
          <list-item>
            <p>Patient selection: The domain addresses whether the selection
        of patients could have introduced bias, taking into account
        whether the study enrolled a consecutive or random sample,
        whether the data are not based on a retrospective case-control
        design, and whether the study avoided inappropriate or
        problematic exclusions from the patient pool.</p>
          </list-item>
          <list-item>
            <p>Index test: The domain evaluates whether the conduct or
        interpretation of the test could have introduced bias, taking
        into account whether the results of the test were interpreted
        without knowledge of the results of the reference standard and
        whether any thresholds or cut-offs were pre-specified (e.g.,
        instead of determined during the study to maximize diagnostic
        performance).</p>
          </list-item>
          <list-item>
            <p>Reference standard: The domain evaluates whether the
        reference standard, its conduct, or its interpretation may have
        introduced bias, taking into account the quality of the
        reference standard in correctly classifying the condition and
        whether the reference standard test results were interpreted
        without knowledge of the results of the index test.</p>
          </list-item>
          <list-item>
            <p>Flow and timing: The last domain evaluates whether the
        conduct of the study may have introduced bias. The assessment
        takes into account whether the interval between the test and the
        reference standard was appropriate, whether all patients
        received the reference standard and whether they received the
        same reference standard, and whether all patients were included
        in the analysis.</p>
          </list-item>
        </list>
        <p>For each domain, we assessed the potential risk of bias in the
    study to identify high risk of bias and low risk of bias studies.
    One literature reviewer assessed risk of bias, and a methodologist
    reviewed individual studies and rating across studies to ensure
    accuracy and consistency of ratings. As outlined in the
    applicability section, we also evaluated for each study and
    appraisal domain whether there were concerns regarding the
    applicability of the study results to the review question. This
    encompassed whether the patients included in the studies matched the
    review question; whether the test, its conduct, or interpretation
    differed from the review question; or whether the target condition
    as defined by the reference standard fully matched the review
    question. The information was incorporated into the strength of
    evidence assessment.</p>
      </sec>
      <sec id="assessing-applicability">
        <title>Assessing Applicability</title>
        <p>Results are based on the international literature and
    applicability ratings provided assessments regarding the
    generalizability of samples, settings, and tool results for U.S.
    clinical practice. For each study, we assessed the population
    included in the study to identify studies with narrow eligibility
    criteria (e.g., looking for a specific subgroup of ADHD participants
    only), studies that excluded participants with comorbidities, or
    studies that had more complex participants than typically seen in
    the community (e.g., dually diagnosed participants). We assessed
    whether studies described tools not used as recommended or commonly
    used in practice, the presence of highly trained test team or set up
    (e.g., analysis via complex machine learning models), or assessors
    that were not qualified for the assessment. We assessed whether the
    reference standard was ambiguous, different from standard clinical
    practice, or insufficiently described.</p>
      </sec>
      <sec id="data-synthesis-and-analysis">
        <title>Data Synthesis and Analysis</title>
        <p>We answered the key question with the available evidence. We
    broadly differentiated diagnostic tools as</p>
        <list list-type="bullet">
          <list-item>
            <p>Self-report questionnaires</p>
          </list-item>
          <list-item>
            <p>Peer report questionnaires</p>
          </list-item>
          <list-item>
            <p>Neuropsychological tests</p>
          </list-item>
          <list-item>
            <p>Neuroimaging</p>
          </list-item>
          <list-item>
            <p>EEG</p>
          </list-item>
          <list-item>
            <p>Biomarker</p>
          </list-item>
          <list-item>
            <p>Observational data</p>
          </list-item>
          <list-item>
            <p>Clinician tools</p>
          </list-item>
          <list-item>
            <p>Combination predictions using more than one modality</p>
          </list-item>
          <list-item>
            <p>Tests to detect feigning of ADHD</p>
          </list-item>
        </list>
        <p>We documented comparative effect results where studies compared
    the performance of more than one tool. In addition, we documented
    the range of results reported in studies within each tool category
    (e.g., self-reports). We documented the diagnostic accuracy results
    for all outcomes as reported by the authors in the individual
    studies. Sensitivity estimates were documented together with
    specificity estimates given that the estimates are not independent.
    A detailed evidence table displays key characteristics, the
    reference standard, psychometric properties and diagnostic accuracy
    outcomes for all included studies. In addition, we identified the
    number of true positives, true negatives, false positives, and false
    negatives where clearly reported for use in a diagnostic
    meta-analysis. All studies were considered for the narrative
    synthesis accompanying the summary of findings table.</p>
        <p>We documented the results for available diagnostic tools across
    studies in a comprehensive summary of findings table documenting all
    assessed outcomes related to the diagnostic accuracy, reliability,
    and impact of the tool. Key outcomes for the summary of findings
    table were determined with the help of the TEP:</p>
        <list list-type="bullet">
          <list-item>
            <p>Clinical misdiagnosis (risk of missed condition that can
        appear as ADHD)</p>
          </list-item>
          <list-item>
            <p>Sensitivity</p>
          </list-item>
          <list-item>
            <p>Specificity</p>
          </list-item>
          <list-item>
            <p>Administration and scoring time</p>
          </list-item>
          <list-item>
            <p>Inter-rater reliability</p>
          </list-item>
          <list-item>
            <p>Costs</p>
          </list-item>
          <list-item>
            <p>Diagnostic concordance of primary care provider with
        specialist</p>
          </list-item>
        </list>
        <p>The synthesis took study limitations and the risk of bias of
    individual studies contributing to estimates into account. We
    determined whether summary estimates corresponded to data reported
    in low risk of bias studies or were primarily based on high risk of
    studies.</p>
        <p>To address the sub-question, we reported on subgroup results for
    different clinical settings (differentiating general and specialty
    care settings), patient characteristics (differentiating sex, age,
    cultural background, and comorbidity groups), and ADHD presentation
    (differentiating predominantly inattentive, hyperactive-impulsive,
    combined). We assessed whether these variables can explain
    heterogeneity identified in results across studies.</p>
        <p>To address the contextual question, we documented the frequency
    of identified research for each individual tool. In addition, we
    summarized data sources that reported on the frequency of tool use
    in clinical practice with emphasis on the U.S. healthcare setting in
    the discussion.</p>
      </sec>
      <sec id="grading-the-strength-of-the-body-of-evidence">
        <title>Grading the Strength of the Body of Evidence</title>
        <p>We applied the EPC strength of evidence criteria to evaluate the
    body of evidence. In determining the quality of the body of
    evidence, the following domains were evaluated:</p>
        <list list-type="bullet">
          <list-item>
            <p>Study limitations: The extent to which studies reporting on a
        particular outcome for a specific test were likely to be
        protected from bias. The aggregate risk of bias across
        individual studies reporting an outcome was considered; graded
        as low, medium, or high level of study limitations.</p>
          </list-item>
          <list-item>
            <p>Inconsistency: The extent to which studies reported the same
        direction and/or magnitude of effects for a particular outcome;
        graded as consistent, inconsistent, or unknown (in the case of a
        single study or the absence of studies).</p>
          </list-item>
          <list-item>
            <p>Indirectness: Determines whether the test and the comparator
        were directly (i.e., within studies) or indirectly (e.g., across
        studies) compared. The domain was graded as direct or
        indirect.</p>
          </list-item>
          <list-item>
            <p>Imprecision: Describes the level of certainty of the estimate
        of effect for a particular outcome, where a precise estimate is
        one that allows a clinically useful conclusion. The domain was
        graded as precise or imprecise.</p>
          </list-item>
          <list-item>
            <p>Reporting bias: Publication bias, selective outcome
        reporting, and selective analysis reporting are types of
        reporting bias. Reporting bias is difficult to assess as
        systematic identification of unpublished evidence is
        challenging.</p>
          </list-item>
        </list>
        <p>A final strength of evidence grade for each evidence statement
    was assigned by evaluating and weighing the combined results of the
    above domains. We formulated comparative evidence statements based
    on direct comparisons of tests within studies. For all other tests,
    we evaluated the magnitude of the effects for the outcomes of
    interest. Given that most outcomes showed some variation and a
    precise pooled estimate was not available, we broadly characterized
    the magnitude as follows based on the observed performance and
    published suggestions:</p>
        <list list-type="bullet">
          <list-item>
            <p>Clinical misdiagnosis: low (&lt;5%), fair (&lt;20-5%),
        substantial (20-60%) rate</p>
          </list-item>
        </list>
        <list list-type="bullet">
          <list-item>
            <p>Sensitivity and specificity: limited (&lt;80%); poor
        (&lt;69%), fair (70-79%), acceptable (80-89%), good (90-95%),
        excellent (96-100%)</p>
          </list-item>
          <list-item>
            <p>Administration and scoring time: short (&lt;30 minutes)</p>
          </list-item>
          <list-item>
            <p>Rater agreement: limited (kappa &lt;0.8, correlations
        &lt;0.40)</p>
          </list-item>
          <list-item>
            <p>Costs and concordance: N/A</p>
          </list-item>
        </list>
        <p>We differentiated an overall grade of high, moderate, low, or
    insufficient according to a four-level scale:</p>
        <list list-type="bullet">
          <list-item>
            <p>High: We are very confident that the estimate of effect lies
        close to the true effect for this outcome. The body of evidence
        has few or no deficiencies. We believe that the findings are
        stable (i.e., another study would not change the
        conclusions).</p>
          </list-item>
          <list-item>
            <p>Moderate: We are moderately confident that the estimate of
        effect lies close to the true effect for this outcome. The body
        of evidence has some deficiencies. We believe that the findings
        are likely to be stable, but some doubt remains.</p>
          </list-item>
          <list-item>
            <p>Low: We have limited confidence that the estimate of effect
        lies close to the true effect for this outcome. The body of
        evidence has major or numerous deficiencies (or both). We
        believe that additional evidence is needed before concluding
        either that the findings are stable or that the estimate of
        effect is close to the true effect.</p>
          </list-item>
          <list-item>
            <p>Insufficient: We have no evidence, we are unable to estimate
        an effect, or we have no confidence in the estimate of effect
        for this outcome. No evidence is available, or the body of
        evidence has unacceptable deficiencies, precluding reaching a
        conclusion.</p>
          </list-item>
        </list>
        <p>The summary of findings table included the reasons for
    downgrading or upgrading the strength of evidence. The strength of
    evidence assessment documented uncertainty and communicated our
    confidence in the evidence statements that can be drawn from the
    literature.</p>
      </sec>
    </sec>
    <sec id="results">
      <title>Results</title>
      <p>The chapter is organized by the literature search results, the
  comparative diagnostic accuracy, results for individual tests,
  reporting on the diagnostic accuracy, unintended consequences, and
  information on the impact associated testing.</p>
      <sec id="results-of-literature-search">
        <title>Results of Literature Search</title>
        <disp-quote>
          <p>The flow diagram documents the literature flow of the
      systematic review.</p>
        </disp-quote>
        <p><named-content id="_Toc193981858" content-type="anchor"/>Figure
    2. Literature Flow Diagram</p>
        <p>We identified 117 studies meeting inclusion criteria reported in
    121 publications.<sup>44-164</sup> The earliest identified study was
    published in 1997.<sup>135</sup> Studies evaluated tools in Brazil,
    Canada, China, Denmark, Germany, Greece, India, Ireland, Israel,
    Korea, the Netherlands, Norway, Sweden, Switzerland, Turkey, UK,
    USA, or combined evaluations in multiple countries. Sample sizes
    varied widely, from a dozen participants to large samples with over
    a thousand participants.<sup>48, 121, 153</sup> Studies included
    participants diagnosed with ADHD and compared to different non-ADHD
    samples. These included neurotypical adults not diagnosed with ADHD,
    adults from a clinical sample evaluated or diagnosed for another
    clinical condition, and/or adults feigning ADHD. Half of the
    included studies (51%) incorporated a neurotypical group of adults
    that did not meet criteria for ADHD, and in some cases, were also
    selected specifically because they also never had a childhood
    diagnosis of ADHD. Many studies (40%) compared participants with a
    diagnosis of ADHD to a clinical sample of participants who were
    being evaluated for another clinical condition. In addition, two
    studies each (1%) compared to participants with
    autism,<sup>78, 122</sup> conduct disorder or anger
    dysregulation,<sup>88, 98</sup> or depression,<sup>119, 130</sup>
    respectively. A quarter (23%) of the identified studies included
    participants identified or specifically trained to pretend to have
    ADHD. Studies varied in whether they included an additional group
    (e.g., a neurotypical or clinical sample), but some studies included
    only participants feigning ADHD, which were compared to participants
    with a diagnosis of ADHD.<sup>44, 127, 133, 134</sup></p>
        <p>The risk of bias across studies is shown in figure 3.</p>
        <p><named-content id="_Toc193981859" content-type="anchor"/>Figure
    3. Risk of Bias</p>
        <p>Nearly half of the identified studies demonstrated high risk of
    bias in patient selection, indicating prevalent issues with how
    participants were recruited and selected across the evidence base.
    Almost two thirds of studies exhibited high risk of bias in the
    index test domain, indicating widespread concerns about how
    diagnostic tools were applied and interpreted. The reference
    standard domain showed the most favorable profile, with about 60
    percent of studies at low risk of bias and about 20 percent at high
    risk, suggesting relatively good quality in how the diagnostic “gold
    standard” was implemented. The flow and timing domain shows that
    nearly 60 percent of studies showed high risk of bias in flow and
    timing, indicating significant concerns about the sequence and
    intervals of test administration and analysis.</p>
        <p>The applicability assessment assessing the generalizability of
    study results identified in this review is summarized in figure
    4.</p>
        <p><named-content id="_Toc193981860" content-type="anchor"/>Figure
    4. Applicability to Routine Practice of Reported Results</p>
        <p>Few studies had no applicability concerns regarding population,
    with most studies having narrow eligibility criteria or including
    more complex patients than typical of community settings. Half the
    studies had no applicability concerns regarding the test, though
    many others used tests not common in current practice, or they
    employed highly selected teams not representative of typical
    clinical settings. About half of the studies had no applicability
    concerns for the reference standard, with the remaining studies
    showing unclear DSM-5 diagnostic criteria or other reference
    standard issues limiting generalizability. Half the studies
    indicated no applicability concerns regarding outcomes, with many
    others using surrogate outcomes that may not directly translate to
    clinical practice. Most studies had applicability concerns regarding
    setting, with the vast majority conducted in care levels different
    from community settings, limiting their generalizability to routine
    practice.</p>
        <p>Identified studies reported on self-report questionnaires, peer
    review tools, neuropsychological tests, neuroimaging,
    electroencephalogram (EEG), diverse biomarkers, clinician tools,
    combinations of modalities, and tools to identify feigning ADHD.
    Studies reported on the success of identifying ADHD, success in
    identifying feigning and exaggerating of ADHD symptoms, or both.</p>
        <p><named-content id="_Toc193750151" content-type="anchor"/>3.2
    Results of Key Question 1: What is the comparative diagnostic
    accuracy, unintended consequences, and impact of tools that can be
    used in the primary care practice setting or by specialists to
    diagnose ADHD among adults?</p>
        <p>We identified numerous studies that included multiple tools used
    alone or in combination. However, not all studies reported
    diagnostic performance for all tools and combinations, and only
    selected studies allowed direct comparisons.</p>
        <p>The 11 studies with head-to-head comparisons between modalities
    compared primarily self-report questionnaires with other modalities,
    including parent ratings,<sup>122</sup> peer
    reports,<sup>65, 98</sup> a combination of self and other
    ratings,<sup>65, 98, 154</sup> neuropsychological
    tests,<sup>98, 145</sup> a combination of self-report and
    EEG;<sup>132</sup> and clinician tools.<sup>98, 100</sup> Three
    studies compared neuropsychological test results to combinations of
    input;<sup>78, 119, 123</sup> one compared a neuropsychological test
    and one compared EEG data under Go/NoGo task conditions with task
    performance indicators.<sup>54</sup> Table 2 documents the results
    for key outcomes for the comparative studies.</p>
        <p><named-content id="_Toc193749730" content-type="anchor"/>Table
    2. Comparative Studies</p>
        <table-wrap>
          <table>
            <colgroup>
              <col width="11%"/>
              <col width="12%"/>
              <col width="18%"/>
              <col width="12%"/>
              <col width="14%"/>
              <col width="11%"/>
              <col width="18%"/>
            </colgroup>
            <thead>
              <tr>
                <th>
                  <p>
                    <bold>Study ID</bold>
                  </p>
                  <p>
                    <bold>Participants</bold>
                  </p>
                </th>
                <th>
                  <bold>Self-report</bold>
                </th>
                <th>
                  <bold>Peer rating</bold>
                </th>
                <th>
                  <bold>Combined prediction</bold>
                </th>
                <th>
                  <bold>Neuropsychological tests</bold>
                </th>
                <th>
                  <bold>EEG</bold>
                </th>
                <th>
                  <bold>Clinician interview</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <p>Biederman, 2017<sup>54</sup></p>
                  <p>N = 60</p>
                  <p>n ADHD = 36</p>
                  <p>Specialty care</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
                <td>
                  <p>Go/NoGo task errors, participants were seated in a
            dimly lit room at a distance of 70 cm from a 17-inch CRT
            screen; Go stimuli were white letters appearing in equal
            proportions, the NoGo stimulus was a white x symbol, stimuli
            were presented on the center of a black background computer
            screen for 150 ms and were located between 2 vertical white
            lines, 10 trial practice block, analyzed reaction time,
            error rates (commission and misses)</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>:N/A</p>
                  <p><bold>Specificity</bold>: N/A</p>
                  <p>AUC 0.67</p>
                  <p><bold>Admin time</bold>: 12 minutes across all tests.</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>Event-related potential data to analyze brain
            activity patterns during Go/NoGo task, Go condition</p>
                  <p><bold>Clinical misdiagnosis</bold>: 5%</p>
                  <p><bold>Sensitivity:</bold> Go condition 86%; NoGo
            condition: 76%; cross-validation data: NoGo 68%, Go 62%</p>
                  <p><bold>Specificity</bold>: Go condition 95%, NoGo
            condition: 91%; cross-validation data: NoGo 80%, Go 69%</p>
                  <p><bold>PPV</bold>: cross-validation data: NoGo 0.77, Go
            0.69</p>
                  <p><bold>NPV</bold>: cross-validation data: NoGo 0.72, Go
            0.65</p>
                  <p><bold>Admin time</bold>: 12 minutes across all tests.</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Dvorsky, 2016<sup>65</sup></p>
                  <p>N = 86 college studients with suspected or previously
            diagnosed ADHD and interested in special accommodations.</p>
                  <p>n ADHD = 59</p>
                  <p>n non-ADHD with internalizing disorder = 27</p>
                  <p>College</p>
                </td>
                <td>
                  <p>BAARS-IV (Barkley Adult ADHD Rating Scale-IV) for
            self-reported assessment of ADHD symptoms on a 4-point scale
            (0 = never or rarely to 3 = very often), cut off &gt; 3
            symptoms presence</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: 89%</p>
                  <p><bold>Specificity</bold>: 30%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: BAARS-IV self-report vs
            BAARS-IV parent ratings Parent ratings compared against
            student self-reports Current inattention ICC 0.43, current
            hyperactivity ICC</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>BAARS-IV (Barkley Adult ADHD Rating Scale-IV) parent
            report</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: 60%</p>
                  <p><bold>Specificity</bold>: 77%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: Parent ratings compared
            against student self-reports Current inattention ICC 0.43,
            current hyperactivity ICC 0.31, current impulsivity ICC
            0.32, retrospective children inattention ICC 0.42,
            retrospective childhood hyperactivity/impulsivity ICC
            0.37</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>Combination prediction model with BAARS parent and
            self rating of current and childhood ADHD diagnosis</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: 89</p>
                  <p><bold>Specificity</bold>: 63</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Groom, 2016<sup>78</sup></p>
                  <p>N = 57</p>
                  <p>n ADHD = 33</p>
                  <p>n ASD = 25</p>
                  <p>College</p>
                </td>
                <td>
                  <p>CAARS-E (Conners Adult ADHD Rating Scale-subscale
            E)</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>:</p>
                  <p><bold>Specificity</bold>:</p>
                  <p>AUC: 0.77</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>
                  <p>Integration of CAARS-E (Conners Adult ADHD Rating
            Scale - ADHD Index) with the AQ10 (Autism Quotient - 10),
            and the QbTest (computerized Continuous Performance Test
            with motion tracking)</p>
                  <p><bold>Clinical misdiagnosis</bold>: 16% in Autism
            Spectrum Disorder sample</p>
                  <p><bold>Sensitivity</bold>: 94%</p>
                  <p><bold>Specificity</bold>: 84%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>QbTest is a computerized continuous performance test
            with infra-red motion tracking system, designed to assess
            attention, impulsivity, and activity levels; participants
            respond to stimuli on a screen while their movements are
            tracked, and scores are calculated based on attention
            accuracy, reaction time, and movement data</p>
                  <p><bold>Clinical misdiagnosis</bold>: 20% in Autism
            Spectrum Disorder sample</p>
                  <p><bold>Sensitivity</bold>: 84%</p>
                  <p><bold>Specificity</bold>: 80%</p>
                  <p>UCC: 0.87</p>
                  <p><bold>Admin time</bold>: Approximately 20 minutes.</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Kingston, 2013<sup>98</sup></p>
                  <p>N = 120, all in a forensic evaluation, 53.8% in the
            criminal justice system</p>
                  <p>n ADHD = 59</p>
                  <p>no ADHD = 61</p>
                </td>
                <td>
                  <p>ASRS-v1.1 Part A, a scale based on nosological
            criteria and pertain to frequency, rather than severity, of
            ADHD symptoms; Part A comprises 6 screening questions and is
            considered to be the most predictive of symptoms consistent
            with ADHD; adminstered together with ASRS-v1.1 Part B, Brown
            ADD (attention deficit disorder) Scale, CAARS-Self ADHD
            Index (Connors Adult ADHD Rating Scale, Long Version,
            Self-Report), and WURS (Wender Utah Rating Scale)</p>
                  <p><bold>Clinical misdiagnosis</bold>: 16%</p>
                  <p><bold>Sensitivity</bold>: 76% ASRS-v1.1 Part B 66%, Brown
            ADD Scale 84%, CAARS-Self ADHD Index 63%, WURS 82%</p>
                  <p><bold>Specificity</bold>: 84% ASRS-v1.1 Part B 93%, Brown
            ADD Scale.73%, CAARS-Self ADHD Index.91%, WURS.69%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: rater agreement between
            self-report measures (ASRS-v1.1, CAARS-Self, WURS, and Brown
            ADD Scale) and observer-rated measures (CAARS-Observer) r
            0.51</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>CAARS-O ADHD Index (Observer), observer report</p>
                  <p><bold>Clinical misdiagnosis</bold>: 25%</p>
                  <p><bold>Sensitivity</bold>: 76%</p>
                  <p><bold>Specificity</bold>: 75%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>Integration of ASRS-v1, CAARS-Self and
            CAARS-Observer, Brown ADD scale, and WURS in a discriminant
            function</p>
                  <p><bold>Clinical misdiagnosis</bold>: 18%</p>
                  <p><bold>Sensitivity</bold>: 91%</p>
                  <p><bold>Specificity</bold>: 82%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>:</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>IVA + Plus FSRCQ (Integrated Visual and Auditory
            Continuous Performance Test Full Scale Response Control
            Quotient), a computerized continuous performance test
            utilizing visual and auditory stimuli to assess response
            control; constant and sustained attention is required, as
            participants respond or inhibit their response to 500
            counterbalanced trials; FSRCQ measures impulsivity and
            commission errors, normative quotient scores have a mean of
            100 and a standard deviation of 15</p>
                  <p><bold>Clinical misdiagnosis</bold>: 26%</p>
                  <p><bold>Sensitivity</bold>: 30% IVA + Plus (FSAQ): .39
            (.29–.54)</p>
                  <p><bold>Specificity</bold>: 74% IVA + Plus (FSAQ): .69
            (.53–.82)</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Kumar, 2011<sup>100</sup></p>
                  <p>N = 110 psychiatric inpatients</p>
                  <p>n ADHD = 6</p>
                  <p>n not ADHD = 104</p>
                </td>
                <td>
                  <p>CAARS-S:SV (Conners' Adult ADHD Rating Scales:
            Screening Version), 30-item self-report tool that screens
            for ADHD symptoms in adults, using a 4-point rating scale to
            assess the frequency of symptoms based on DSM-IV criteria,
            cut off point wasT score&gt;70</p>
                  <p><bold>Clinical misdiagnosis</bold>: 31%</p>
                  <p><bold>Sensitivity</bold>: 83%</p>
                  <p><bold>Specificity</bold>: 69%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: Correlation self-report
            CAARS-S:SV and MINI r 0.58</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
                <td>
                  <p>MINI (International Neuropsychiatric Interview), a
            short, structured diagnostic interview designed to assess a
            range of different mental health disorders</p>
                  <p><bold>Clinical misdiagnosis</bold>: 48%</p>
                  <p><bold>Sensitivity</bold>: 83%</p>
                  <p><bold>Specificity</bold>: 52%</p>
                  <p><bold>Admin time</bold>: 10-25 minutes</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>Nikolas, 2019<sup>119</sup></p>
                  <p>N = 246</p>
                  <p>n ADHD = 109</p>
                  <p>n Depression and no ADHD = 52</p>
                  <p>n controls with no ADHD or Depression = 85</p>
                  <p>Specialty care and community</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>
                  <p>Combination of self/informant symptom ratings
            (BAARS-IV), family history, and reactiontime variability
            from TOVA (Test of Variables of Attention)</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>:</p>
                  <p><bold>Specificity</bold>:</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>TOVA ommission errors, cutoff &lt;95 as part of a
            large battery with many exploratory analyses to
            differentiate ADHD and non-ADHD</p>
                  <p><bold>Clinical misdiagnosis</bold>: 15%</p>
                  <p><bold>Sensitivity</bold>: 50%</p>
                  <p><bold>Specificity</bold>: 85%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Palmer, 2023<sup>122</sup></p>
                  <p>N = 71 with Autism Spectrum Disorder</p>
                  <p>n ADHD and ASD = 40</p>
                  <p>n ASD but no ADHD = 31</p>
                  <p>Community</p>
                </td>
                <td>
                  <p>CAARS-S (Conners Adult ADHD Rating Scales
            Self-Report) ADHD Index assessed ADHD symptoms with a cutoff
            of ≥56; adminstered together with the SDQ (Strengths and
            Difficulties Questionnaire), cutoff of ≥9</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: CAARS 57%; SDQ&gt;9: 28%</p>
                  <p><bold>Specificity</bold>: CAARS 81%; SDQ&gt;9: 100%</p>
                  <p><bold>AUC</bold>: CAARS 0.70; SDQ&gt;9: 0.65</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>CAARS-P (Conners Adult ADHD Rating Scales Peer
            Report) parent report, ADHD Index cutoff &gt;56;
            administered together with ABC (Aberrant Behavior Checklist)
            Hyperactivity/Non-compliance subscale (a cutoff of ≥3)
            parent-report</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: 94% ABC scale: 91%</p>
                  <p><bold>Specificity</bold>: 57% ABC scale: 42%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Pettersson, 2018<sup>123</sup></p>
                  <p>N = 108 outpatients being evaluated for suspected
            ADHD</p>
                  <p>n ADHD = 60</p>
                  <p>n not ADHD = 48</p>
                  <p>Specialty care</p>
                </td>
                <td>
                  <p>ASRS Screener (Adult ADHD Slef-Report Scale
            Screener)</p>
                  <p><bold>Clinical misdiagnosis</bold>: 8%</p>
                  <p><bold>Sensitivity:</bold> 92%</p>
                  <p><bold>Specificity:</bold> 27%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>
                  <p>Model with DIVA report, QbTest cardinal variable
            Acticity, QbTest cardinal variable Inattention, and CpT II
            Commission errors, combining neuropsychological tests, DIVA
            clinician report, and self-report ASRS Screener</p>
                  <p><bold>Clinical misdiagnosis</bold>: 17%</p>
                  <p><bold>Sensitivity</bold>: 90%</p>
                  <p><bold>Specificity</bold>: 83%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>
                  <p>Model with CPT II Commission errors, QbTest cardinal
            variable Inattention, and QbTest cardinal variable
            Activity</p>
                  <p><bold>Clinical misdiagnosis</bold>: 33%</p>
                  <p><bold>Sensitivity</bold>: 80%; QBTest Act 77%; QBTest Ina
            58%; QBTest Omi 73%, QBTest RT Var 43%; PASAT tot 33%; CPT
            II Com 33%, CPT II Var 27%</p>
                  <p><bold>Specificity</bold>: 67%; QBTest Act 44%; QBTest Ina
            67%; QBTest Omi 56%, QBTest RT Var 75%; PASAT tot 77%; CPT
            II Com 92%, CPT II Var 85%</p>
                  <p><bold>Admin time</bold>: 20 minutes</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>
                  <p>DIVA (Diagnostic Interview for ADHD in Adults),
            dichotomized as ADHD if 6 or more symptom criteria in both
            adulthood and childhood, and in either or both of the
            domains Attention Deficit and Hyperactivity–Impulsivity, and
            as non-ADHD if fewer than 6 symptom criteria</p>
                  <p><bold>Clinical misdiagnosis</bold>: 27%</p>
                  <p><bold>Sensitivity</bold>: 90%</p>
                  <p><bold>Specificity</bold>: 73%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
              </tr>
              <tr>
                <td>
                  <p>Robeva, 2004<sup>132</sup></p>
                  <p>N = 12 all female</p>
                  <p>ADHD n = 6 taking medication</p>
                  <p>Not ADHD n = 6</p>
                  <p>College students</p>
                </td>
                <td>
                  <p>WURS (Wender Utah Rating Scale), a 61-item
            retrospective questionnaire witha cutoff score of 30 on the
            short form with higher cutoff values</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: N/A</p>
                  <p><bold>Specificity</bold>: N/A</p>
                  <p>Accuracy: classification &lt;85%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>
                  <p>Bayesian probability model integrated three
            diagnostic tools (WURS, ConsistencyIndex (EEG), Alpha
            Blockade Index (EEG)</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: 100%</p>
                  <p><bold>Specificity</bold>: 100%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>
                  <p>EEG-based physiological markers</p>
                  <p><bold>Clinical misdiagnosis</bold>: N/A</p>
                  <p><bold>Sensitivity</bold>: N/A</p>
                  <p><bold>Specificity</bold>: N/A</p>
                  <p>Accuracy: classification &lt;85%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Solanto, 2004<sup>145</sup></p>
                  <p>N = 93 evaluated for suspected ADHD</p>
                  <p>n = 44 combined-type ADHD</p>
                  <p>n = 26 inattentive ADHD</p>
                  <p>n=33 mood or anxiety disorder</p>
                  <p>Specialty care</p>
                </td>
                <td>
                  <p>BADDS (Brown Attention-Deficit Disorder Scale),
            assesses executive and adaptive functioning across five
            clusters (Activation, Attention, Effort, Affect, and
            Memory), cutoff 50</p>
                  <p><bold>Clinical misdiagnosis</bold>: 67%</p>
                  <p><bold>Sensitivity</bold>: 92%</p>
                  <p><bold>Specificity</bold>: 33%</p>
                  <p><bold>Accuracy</bold>: 74%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>
                  <p>C-CPT (Conners Continuous Performance Test), a
            14-minute computerized task where participants respond to
            non-target stimuli; most CPT scores were in the clinically
            normal range for all groups; fFor Hit Reaction Time
            Inter-Stimulus Interval Change in discriminating inattentive
            ADHD from combined type ADHD</p>
                  <p><bold>Clinical misdiagnosis</bold>: 14%</p>
                  <p><bold>Sensitivity</bold>: 47%</p>
                  <p><bold>Specificity</bold>: 86%</p>
                  <p><bold>Accuracy:</bold> 70%</p>
                  <p><bold>Admin time</bold>: 15 minutes</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>
                  <p>Van Voorhees, 2011<sup>154</sup></p>
                  <p>N = 269 evaluated for attnetion problems</p>
                  <p>n ADHD = 184 (n=71 Combined Type; n=89 Predominately
            Inattentive Type; n = 24 ADHD Not Otherwise Specified)</p>
                  <p>Specialty care</p>
                </td>
                <td>
                  <p>CAARS:S (Conners’ Adult ADHD Rating Scales, Self
            Rating, Long Version), 66-items rated on a 4-point scale (0
            to 3) to assess ADHD symptoms</p>
                  <p><bold>Clinical misdiagnosis</bold>: 39%</p>
                  <p><bold>Sensitivity</bold>: 65%</p>
                  <p><bold>Specificity</bold>: 61%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: Self-reports (CAARS-S)
            and observer reports (CAARS-O including ratings from
            friends, parents, and spouses) Ranged from r 0.24
            (“distractible”) through r 0.46 (“on the go/driven by a
            motor”)</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>
                  <p>CAARS-LV combining self-report CAARS:S and
            observer-report CAARS-O; T-Scores &gt;65 for Conners’
            index</p>
                  <p><bold>Clinical misdiagnosis</bold>: 17%</p>
                  <p><bold>Sensitivity</bold>: 43%</p>
                  <p><bold>Specificity</bold>: 83%</p>
                  <p><bold>Admin time</bold>: N/A</p>
                  <p><bold>Rater reliability</bold>: N/A</p>
                  <p><bold>Costs</bold>: N/A</p>
                  <p><bold>Concordance</bold>: N/A</p>
                </td>
                <td>N/A</td>
                <td>N/A</td>
                <td>N/A</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Notes: N/A not available, not applicable; N number of
    participants</p>
        <p>Several identified studies compared multiple tests, but not all
    reported results for all outcomes of interest for every test. Two
    studies compared self-reports versus a clinician interview tool,
    both reported a lower rate of clinical misdiagnoses for in the
    direct comparison.<sup>100, 123</sup> Two studies found no
    difference in sensitivity between self-report and a clinician
    tool.<sup>98, 100</sup> Two studies reported higher sensitivity for
    self-reports versus neuropsychological tests.<sup>98, 145</sup> Two
    studies reported higher specificity for self-reports over a
    clinician tool.<sup>98, 100</sup></p>
        <p>Three studies reported on sensitivity for combinations of input
    versus neuropsychological tests alone, all found higher values for
    the combination<sup>78, 98, 123</sup> One study compared a
    combination to EEG marker alone and also reported results in favor
    of the combination.<sup>132</sup> Four studies found higher
    specificity for combinations of input versus neuropsychological
    tests alone<sup>78, 98, 123</sup> or EEG marker
    alone.<sup>132</sup></p>
        <p>Evidence for all other comparisons was insufficient and we were
    not able to make comparative evidence statement for the outcomes
    administration time, inter-rater reliability, costs, or concordance
    between primary and specialty care diagnoses. All available
    comparative results across test modalities (e.g., combinations of
    variables vs neuropsychological test results alone) are documented
    in the summary of findings table (Table 3).</p>
        <sec id="combination">
          <title>Combination</title>
          <p>Eight studies reported on a combination of input from different
      modalities.<sup>57, 65, 78, 98, 119, 123, 132, 154</sup> Several
      included self and informant symptom ratings, and some also used
      demographic variables, neuropsychological assessment results, or
      EEG data. Studies varied in their complexity of the combination;
      one study, supported by machine learning, used 93
      variables.<sup>57</sup> The Appendix Table C.1 documents results
      for all studies that evaluated a combination.</p>
          <p>Reported clinical false positive rate ranged from 16 percent in
      a study combining self-ratings and QBTest data to distinguish ADHD
      from Asperger’s syndrome<sup>78</sup> to 18 percent in a study
      combining multiple self-reports and an observer report to
      distinguish from aggression.<sup>98</sup> As illustrated in Figure
      8, sensitivity was variable but mostly good, but not excellent.
      Reported sensitivity ranged from 94 percent (corresponding
      specificity 84%)<sup>78</sup> to 43 percent (corresponding
      specificity 83%)<sup>154</sup> in the identified studies.
      Specificity ranged from 84 percent (corresponding sensitivity
      94%)<sup>78</sup> to 82 percent (corresponding sensitivity
      91%).<sup>98</sup> We found no data for the outcomes
      administration time, inter-rater reliability, costs, or
      concordance between primary and specialty care diagnoses. The
      table shows the specific combinations used to diagnose ADHD.
      Results for key outcomes are synthesized in the Summary of
      Findings table (Table 3).</p>
          <p><named-content id="_Toc193750153" content-type="anchor"/>3.2.2
      Self-Report Questionnaires</p>
          <p>Forty-three studies reported at least one self-report measure
      evaluated for its performance in diagnosing ADHD. The studies
      reported on numerous self-report measures: ADHD Rating Scale, ADSA
      (Attention-Deficit Scales for Adults), AHA (Assessment of
      Hyperactivity and Attention), ALS-SF (Affective Lability
      Scale-Short Form), APQ (Adult Problem Questionnaire), ASRS (Adult
      ADHD Self-Report Scale), ASSET-BS (ADHD Symptom and Side Effect
      Tracking Baseline Scale), BAARS-IV Barkley Adult ADHD Rating
      Scale), BADDS (Brown Attention-Deficit Disorder Scale), CAARS
      (Conners Adult ADHD Rating Scale), CBS (Current Behavior Scale),
      EarlyDetect Questionnaire, IPDE-SQ (International Personality
      Disorder Examination screening questionnaire), PAI (Personality
      Assessment Inventory), PDI-4 (Provisional Diagnostic Instrument),
      SR-WRAADDS (Self-Report Wender-Reimherr Adult ADHD Scale), and
      WURS (Wender Utah Rating Scale). Nine studies reported on more
      than one
      questionnaire.<sup>62, 63, 92, 108, 111, 120, 130, 135, 142</sup>
      The Appendix Table C.2 documents results for all studies that
      evaluated a written self-report for the diagnosis of ADHD.</p>
          <p>Performance for clinical misdiagnosis varied across studies but
      was generally substantial: reported false positive rates in
      clinical samples ranged from 12 percent differentiating from
      depression or generalized anxiety using the WURS<sup>130</sup> to
      90 percent in students with academic or psychological difficulties
      using the CAARS-S.<sup>101</sup> The ability to detect ADHD varied
      but was good for many questionnaires as illustrated in Figure
      5.</p>
          <p><named-content id="_Toc201103279" content-type="anchor"/>Figure
      5. Reported Sensitivity and Specificity of ADHD Self-Report
      Questionnaires in Adults Across Studies</p>
          <p>Notes: ADSA (Attention-Deficit Scales for Adults), AHA
      (Assessment of Hyperactivity and Attention), ALS-SF (Affective
      Lability Scale-Short Form), APQ (Adult Problem Questionnaire),
      ASRS (Adult ADHD Self-Report Scale), ASSET-BS (ADHD Symptom and
      Side Effect Tracking Baseline Scale), BAARS-IV Barkley Adult ADHD
      Rating Scale), BADDS (Brown Attention-Deficit Disorder Scale),
      CAARS (Conners Adult ADHD Rating Scale), CBS (Current Behavior
      Scale), EarlyDetect Questionnaire, IPDE-SQ (International
      Personality Disorder Examination screening questionnaire), PAI
      (Personality Assessment Inventory), PDI-4 (Provisional Diagnostic
      Instrument), SR-WRAADDS (Self-Report Wender-Reimherr Adult ADHD
      Scale), and WURS (Wender Utah Rating Scale)</p>
          <p>Neurotypical only = true indicates that the study
      differentiated ADHD from neurotypical adults, neurotypical only =
      false indicates that the study differentiated ADHD from other
      clinical conditions or a combination of neurotypical adults and
      adults with other clinical conditions</p>
          <p>Figure 5 represents each study that reported on a self-report
      with one questionnaire, selecting the scale with the highest
      sensitivity and specificity where more than one tool was
      evaluated. In the individual studies sensitivity ranged from 100
      percent at the expense of low specificity (CAARS-S corresponding
      specificity 10%<sup>101</sup> or ASRS-v1.1 with specificity not
      reported)<sup>58</sup> to only 14 percent (CAARS-S, corresponding
      specificity 92%).<sup>86</sup> The ability of self reports to
      correctly rule out ADHD was good in many cases but also rarely
      excellent: Specificity ranged from 99 percent (CBS corresponding
      sensitivity 90%)<sup>71</sup> to as low as 10 percent (CAARS-S,
      corresponding sensitivity 100%).<sup>101</sup> Only one study
      explicitly reported on the administration time for the
      questionnaire, indicating short administration.<sup>105</sup>
      Rater agreement was reported in multiple studies, with most
      studies indicating limited agreement between different
      raters.<sup>50, 65, 98, 100, 108, 109, 154, 163</sup> We did not
      identify data on cost or correspondence between primary and
      specialty care. Results for key outcomes are synthesized in the
      Summary of Findings table (Table 3).</p>
        </sec>
        <sec id="peer-report-questionnaires">
          <title><named-content id="_Toc193750154" content-type="anchor"/>3.2.3
      Peer Report Questionnaires</title>
          <p>Three studies evaluated peer reports.<sup>65, 122, 124</sup>
      One of the studies asked parents to rate their young adults with
      autism using the CAARS-P and the ABC (Aberrant Behavior
      Checklist).<sup>122</sup> Another study included parent ratings of
      undergraduates using the BAARS-IV (Barkley Adult ADHD Rating
      Scale-IV).<sup>65</sup> In both studies, the peer report was a
      parent rating of young adults. One study in a forensic outpatient
      clinic reported on CAARS-Observer ratings but did not state who
      served as the rater.<sup>98</sup> The Appendix Table C.3 documents
      all results for the small number of studies that evaluated a
      written peer report for the diagnosis of ADHD.</p>
          <p>Evidence for clinical misdiagnosis was determined to be
      insufficient due to lack of information on the observers in the
      single clinical sample. Sensitivity was determined to be
      insufficient due to the wide reported range (from poor to good).
      Specificity was limited and ranged from fair to poor (77% for
      BAARS-IV, corresponding sensitivity 60%,<sup>65</sup> 57% for
      CAARS-P, corresponding sensitivity 60%);<sup>122</sup> both
      illustrated in Figure 8. For rater agreement, only one study
      reported results and none of the studies reported on costs,
      administration time, or concordance between primary and specialty
      care. Results for key outcomes are synthesized in the Summary of
      Findings table (Table 3).</p>
          <p><named-content id="_Toc193981779" content-type="anchor"/>3.2.4
      Neuropsychological Assessment</p>
          <p>Twenty-seven studies reported on the performance of
      neuropsychological assessment to diagnose ADHD. Studies evaluated
      test batteries such as AQT, BQSS, C-CPT, DII, IVA, MOXO-dCPT,
      QbTest, SCWT, SNST, or the performance of individual tasks such as
      the Go-NoGo task or WAIS-IV Processing Speed Index. Five studies
      reported diagnostic accuracy data for multiple tests and
      tasks.<sup>59, 107, 140, 151, 160</sup> The Appendix Table C.4
      documents results for all neuropsychological tests evaluated to
      diagnose ADHD. The index test description shows the evaluated test
      selection that showed the best performance, together with all
      administered tests.</p>
          <p>Performance for clinical misdiagnoses showed a substantial
      false positive rate in most studies. Reported results ranged from
      11 percent in a study using Stroop test variables for participants
      referred for neuropsychological evaluation<sup>95</sup> to 60
      percent in a model based on QbTest with motion tracking
      variables,<sup>144</sup> Sensitivity was acceptable in most
      studies as illustrated in Figure 6, but reported sensitivity
      showed a wide range from 93 percent (corresponding specificity
      100%) integrating AQT variables<sup>118</sup> to 17 percent for an
      individual subtest of the C-CPT (corresponding specificity
      90%).<sup>146</sup></p>
          <p><named-content id="_Toc201103280" content-type="anchor"/>Figure
      6. Reported Sensitivity and Specificity of Neuropsychological
      Tests for ADHD in Adults across Studies</p>
          <p>Notes: AQT A Quick Test of Cognitive Speed; BQSS Boston
      Qualityative Scoring System for the Rey-Osterrieth Complex Figure;
      C-CPT Conners Continuous Performance Test; IVA Integrated Visual
      And Auditory Continuous Performance Test Full Scale Response
      Control Quotient; QbTest quantified behavioral test; SCWT Stroop
      Color and Word Test; TOVA Test of Variables of Attention</p>
          <p>Figure 6 shows the different specific evaluated tests as well
      as the substantial number of studies that did not evaluate a
      specific tool but used variables in a test battery to develop a
      models that maximizes the ability to discriminate between ADHD and
      comparator characteristics. The figure also shows the wide
      variation in specificity, with some studies reporting excellent
      specificity, but most studies were characterized by acceptable or
      even poor specificity. Reported specificity ranged from 100
      percent (corresponding sensitivity 93%) integrating AQT
      variables<sup>118</sup> to 40 percent for a model integrating
      QbTest Plus variables (corresponding sensitivity
      88%).<sup>144</sup></p>
          <p>There was some variation, but 7 studies estimated the duration
      of the neuropsychological test administration to be about 20
      minutes.<sup>45, 55, 66, 69, 78, 123, 144</sup> None of the
      studies reported on rater agreement, costs, or concordance between
      diagnostic settings. Results for key outcomes are synthesized in
      the Summary of Findings table (Table 3).</p>
          <p><named-content id="_Toc193750156" content-type="anchor"/>3.2.5
      Neuroimaging</p>
          <p>Five studies evaluated
      neuroimaging.<sup>48, 56, 136, 157, 161</sup> Studies used brain
      perfusion single-photon emission computed tomography
      (SPECT),<sup>48</sup> 3-D SPECT,<sup>136</sup> structural magnetic
      resonance imaging (MRI) and diffusion tensor imaging,<sup>56</sup>
      and resting state functional MRI.<sup>157, 161</sup> The Appendix
      Table C.5 documents results of studies that evaluated neuroimaging
      for the diagnosis of ADHD. The table provides details on the final
      selection model where reported.</p>
          <p>Reported clinical misdiagnoses rates varied from a low three
      percent in a brain perfusion SPECT study analyzing a large
      psychiatric database<sup>48</sup> to a substantial 24 percent
      false positive rate in a sample with various psychiatric and
      neuropsychiatric disorders using 3D thresholded
      SPECT.<sup>136</sup> Studies reported sensitivity ranges from
      excellent to poor, but it was acceptable in most studies.
      Performance ranged from 100 percent in a large retrospective
      cohort study using brain perfusion SPECT (corresponding
      specificity 97%)<sup>48</sup> to 54 percent in a clinical sample
      (SPECT, corresponding specificity 76%). Similarly, reported
      specificity ranged from 97 percent (SPECT, corresponding
      sensitivity 100%)<sup>48</sup> to 65 percent (functional MRI,
      corresponding sensitivity 91%),<sup>161</sup> but most studies
      reported acceptable specificity as illustrated in Figure 8.
      Studies varied in how much detail the often machine-learning
      generated discriminant function that achieved the best diagnostic
      performance was documented. Only one study reported on
      administration time; the study reported a procedure duration of 15
      to 20 minutes.<sup>136</sup> One study evaluated rater agreement,
      the study reported a kappa coefficient of 0.79 for agreement in
      visual interpretation of neuroimaging scans.<sup>48</sup> None of
      the studies reported on costs or concordance of diagnostic results
      between different clinical settings. Results for key outcomes are
      synthesized in the Summary of Findings table (Table 3).</p>
          <p><named-content id="_Toc193750157" content-type="anchor"/>3.2.6
      EEG</p>
          <p>Twelve studies evaluated EEG (electroencephalogram) data used
      to distinguish ADHD from other clinical conditions or neurotypical
      developing
      adults.<sup>54, 80, 89, 91, 96, 97, 115, 116, 125, 126, 132, 139</sup>
      Studies tested the diagnostic performance for very different
      conditions, ranging from analyzing resting state
      EEG,<sup>96, 125</sup> and event-related potentials during
      neuropsychological tasks,<sup>54, 115</sup> to EEG recording
      during transcranial magnetic stimulation.<sup>80</sup> The
      Appendix Table C.6 documents results for the studies that
      evaluated the use of EEG data for the diagnosis of ADHD.</p>
          <p>Only one study reported on misdiagnosis in a clinical sample;
      the study reported a low false positive rate of 3.8 percent using
      auditory brainstem response profiling test.<sup>89</sup> Most
      studies were conducted in academic samples and did not involve
      clinical samples. Reported sensitivity results ranged from 100
      percent achieved in a machine-learning assisted diagnostic study
      that utilized phase space reconstruction of brain signals during a
      continuous performance test (corresponding specificity
      87%)<sup>91</sup> to only 67 percent (resting state EEG,
      corresponding specificity 83%)<sup>125</sup> with overall
      acceptable results. Specificity showed an even wider range from
      excellent to poor performance: Reported specificity ranged from 95
      percent (event-related potential, corresponding sensitivity
      86%)<sup>54</sup> to 37 percent (resting state EEG, corresponding
      sensitivity 73%)<sup>96</sup> but was generally good in identified
      studies. Reported session duration ranged from six
      minutes<sup>96</sup> to 26 minutes<sup>116</sup> with no
      information about the scoring or interpretation time. Studies did
      not report on rater agreement, costs, or concordance with
      diagnoses from other settings. Results for key outcomes are
      synthesized in the Summary of Findings table (Table 3).</p>
          <p><named-content id="_Toc193750158" content-type="anchor"/>3.2.7
      Biomarker</p>
          <p>Five studies evaluated biomarkers other than EEG or
      neuroimaging-based indicators.<sup>49, 79, 88, 138, 150</sup>
      Studies evaluated very different markers, including genetic
      marker,<sup>79</sup> eye tracking results,<sup>88</sup> blood
      oxidative status,<sup>138</sup> physiological data from a wearable
      device,<sup>49</sup> or used MFNU (Motor Function Neurological
      Assessment)<sup>150</sup> to diagnose ADHD. None of the same
      modality or type of biomarker was evaluated in more than one
      study. The Appendix Table C.7 documents all results for the small
      number of studies that evaluated the use of biomarkers other than
      neuroimaging or EEG to aid in the diagnosis of ADHD.</p>
          <p>The clinical misdiagnosis rate varied widely: one study
      reported a false positive rate of 17 percent in an eye tracker
      study in sample of participants with conduct
      disorder,<sup>88</sup> another study reported a false positive
      rate of 75 percent in a MFNU assessment in a psychiatric
      outpatient clinic where some patients were considered to have
      subthreshold ADHD.<sup>150</sup> Sensitivity was acceptable in
      most studies and showed a range of 98 percent for MFNU
      (corresponding specificity 25%)<sup>150</sup> to 80 percent in an
      eye tracker study (corresponding specificity 83%).<sup>88</sup>
      Specificity varied widely, from 83 percent in the eye tracker
      study (corresponding sensitivity 80%)<sup>88</sup> to only 25
      percent in the MFNU assessment (corresponding sensitivity 98%).
      Only one study reported on the administration time, the study
      reported that the eye tracking task took about 15
      minutes;<sup>88</sup> none of the studies reported on test result
      processing, evaluation, or interpretation time. Studies did not
      report on rater agreement in interpreting the variables, costs, or
      concordance between settings. Results for key outcomes are
      synthesized in the Summary of Findings table (Table 3).</p>
          <p><named-content id="_Toc193750159" content-type="anchor"/>3.2.8
      Clinician Tool</p>
          <p>Three studies reported on a clinician interview or
      questionnaire that was assessed for congruence with an external
      reference standard.<sup>100, 121, 123</sup> Studies evaluated the
      DIVA (Diagnostic Interview for ADHD in Adults),<sup>123</sup> MINI
      (Mini-International Neuropsychiatric Interview),<sup>100</sup> the
      MINI-Plus<sup>121</sup> which were used by clinicians in clinical
      samples. The reference standards used to evaluate the diagnostic
      performance of the clinician tools were assessments from trained
      clinicians,<sup>121</sup> the recorded chart
      diagnosis,<sup>100</sup> or clinical case
      conferences.<sup>123</sup> The Appendix Table C.8 documents study
      and participant details, and presents all reported results for
      these studies.</p>
          <p>The results reported in the identified studies varied widely
      for the clinical misdiagnosis: false positive rates ranged from
      nine percent for the MINI-Plus in an addiction treatment center
      study<sup>121</sup> to 48 percent in an inpatient psychiatric
      hospital unit for the CAARS-O.<sup>100</sup> The sensitivity was
      acceptable, performance ranged from 83 percent (corresponding
      specificity 52%) to 73 percent (corresponding specificity
      90%).<sup>123</sup> Specificity showed a wider range, reported
      results included good as well as poor sensitivity: performance
      ranged from 91 percent (corresponding sensitivity
      75%)<sup>121</sup> to 52 percent (corresponding sensitivity
      83%).<sup>100</sup> The identified studies did not report on
      administration time, rater agreement, costs, or concordance with
      specialty care. Results for key outcomes are synthesized in the
      Summary of Findings table (Table 3).</p>
          <p><named-content id="_Toc193981784" content-type="anchor"/>3.2.9
      Key Question 1a: How does the comparative diagnostic accuracy of
      these tools vary by clinical setting, including primary care or
      specialty clinic, or patient characteristics, including age, sex,
      cultural background, and risk factors associated with ADHD?</p>
          <p>Because raw data for diagnostic accuracy were often not
      reported, we were not able to detect effect modifiers in
      meta-regressions by adding variables to the meta-analytic model.
      Results are based on subgroups as reported by the authors and
      analyses conducted within the original studies.</p>
          <p><bold>Clinical setting</bold>: Half of the identified studies
      were conducted in specialty care (n=55). The next most frequent
      setting was college (n=37). Very few studies were conducted in
      primary care (n=2). In addition, none of the identified studies
      analyzed the effect of the setting on the diagnostic process.
      Hence the question which tests should be used in primary care is
      difficult to answer. However, several studies addressed the effect
      of the reference standard and comparator sample, i.e., study
      characteristics. In addition, several studies addressed the effect
      of comorbidities. Although primarily a patient characteristic,
      participants evaluated for other clinical conditions was more
      typical of a specialty care clinical setting.</p>
          <p><bold>Reference standard and comparator sample</bold>: Three
      studies addressed the effect of the method of establishing a
      clinical ADHD diagnosis, but all addressed different aspects. One
      study comparing self-reported and neuropsychological tests
      highlighted that diagnostic accuracy measures were high when
      comparing ADHD-diagnosed participants to the general population
      but were less effective when distinguishing ADHD from other
      psychiatric conditions, with overlapping scores noted for anxiety
      and depression.<sup>145</sup> Similarly, a self report study
      reported a high false-positive rate in patients with
      depression.<sup>64</sup> Another study evaluating a self-report
      measure reported that comorbidities such as anxiety and depression
      were associated with elevated scores on scales which may overlap
      with ADHD symptoms and potentially contribute to misclassification
      and highlighted the importance of considering comorbid conditions
      during assessment.<sup>102</sup> One study evaluating
      neuromuscular assessment reported that they found several patients
      with subthreshold ADHD in a clinical sample suggesting possible
      diagnostic overlap and the need for further
      evaluation.<sup>150</sup></p>
          <p>Figure 7 differentiates two diagnostic accuracy measures,
      overall accuracy and the area under the curve (AUC), for all
      diagnostic modalities. The figure stratifies studies by samples
      that identified ADHD in a sample of neurotypical adults, in a
      clinical sample, or in samples that included neurotypical adults,
      adults with other clinical conditions such as autism spectrum
      disorder, and/or adults feigning ADHD.</p>
          <p><named-content id="_Toc201103281" content-type="anchor"/>Figure
      7. Reported Accuracy and Area Under the Curve (AUC) Across
      Tools</p>
          <p>Figure 7 visualizes a trend toward higher diagnostic accuracy
      when tools distinguish between people with ADHD and neurotypical
      adults: diagnostic performance exceeded that of results in
      clinical samples in five out of six studies reporting on overall
      accuracy and in three out of four test modalities in studies that
      reported on AUC.</p>
          <p><bold>ADHD presentation</bold>: Four studies addressed
      diagnosis in different presentations of ADHD with some conflicting
      results. One-self-report study reported that diagnostic accuracy
      did not significantly vary across ADHD presentations/subtypes
      (inattentive, hyperactive-impulsive, and combined) but noted that
      combined type ADHD was the most frequently identified subtype,
      which could influence overall sensitivity and specificity
      estimates.<sup>141</sup> Similarly, another study reported that
      sensitivity and specificity were consistent across ADHD
      presentation types (inattentive, hyperactive, and combined), but
      noted that misdiagnosis rates were slightly higher for the
      inattentive subtype in self reports compared to clinician
      diagnoses, and inter-rater reliability between self-reported and
      clinical ratings was fair, with higher concordance for combined
      presentation.<sup>70</sup> Another self report study highlighted
      that sensitivity for the inattentive subtype was 100 percent on
      the Inattentive Symptoms subscale, with specificity at 25
      percent.<sup>101</sup> One self report study pointed out that
      inattention symptoms were more predictive of ADHD persistence into
      adulthood than hyperactivity-impulsivity symptoms; and individuals
      with the combined-type ADHD in childhood were more likely to
      retain a diagnosis in adulthood, whereas hyperactive-impulsive
      presentations were more likely to remit.<sup>94</sup></p>
          <p><bold>Participant age</bold>: Several studies reported on the
      effect of the age of the participants or specifically on the age
      at diagnosis, but studies focused on different aspects. A
      self-report study reported that executive functioning impairments
      were more predictive of ADHD persistence in older adults, while
      hyperactivity-impulsivity symptoms were more prevalent in younger
      adults, suggesting age-related shifts in symptom expression and
      diagnostic criteria applicability; sensitivity and specificity of
      ADHD diagnoses were higher in younger adults (18–30 years)
      compared to older adults (31–44 years), likely due to better
      recall of childhood symptoms and reduced cognitive decline in
      memory-based reporting.<sup>94</sup> A self report and
      neuropsychological test study reported that age was inversely
      correlated with scores on scales for attention and effort,
      suggesting that older participants exhibited fewer ADHD-related
      symptoms, potentially reflecting developmental improvements in
      executive functioning.<sup>145</sup> One study did not comment on
      differential effects on the diagnosis, but suggested that a
      potential biomarker, oxidative stress, may increase with the
      duration of the disease.<sup>138</sup> Another study found that
      age represented as independent variable in a multiple regression
      did not significantly influence parameters measured by the
      QbTest.<sup>55</sup> A further study reported that ADHD diagnosis
      based on CAARS-S or MINI were not correlated with
      age.<sup>100</sup></p>
          <p><bold>Participant sex</bold>: Several studies reported on the
      effect of the sex of the participants on the diagnostic
      performance, but studies reported conflicting results. One EEG
      study reported lower sensitivity in females compared to
      males.<sup>89</sup> A neuroimaging study noted that classification
      performance was higher in the male-only subgroup compared to the
      mixed-gender subgroup, suggesting that male ADHD patients may have
      more significant neuroanatomical deviations from
      controls.<sup>56</sup> A self-report study did not find lower
      sensitivity but lower specificity in females versus
      males.<sup>155</sup> One study concluded that sex did not
      influence parameters of the neuropsychological test.<sup>55</sup>
      A self-report study did not detect differences in sensitivity and
      specificity between sexes.<sup>163</sup> A study reporting on a
      self-report and a clinician interview noted that ADHD diagnosis
      based on the tests were not correlated with sex.<sup>100</sup></p>
          <p><bold>Participant ethnicity</bold>: None of the studies
      stratified diagnostic performance by race or ethnicity.</p>
          <p><bold>Comorbidities</bold>: Multiple studies reported on the
      effect of comorbidities in participants with ADHD on diagnostic
      performance, but results and conclusions differed. One college
      study reported that comorbidities contributed to challenges in
      specificity but not sensitivity and that functional impairment was
      higher in participants with comorbid conditions.<sup>101</sup>
      Similarly, a study in addiction centers reported on variability in
      specificity values across subgroups while sensitivity remained
      similar.<sup>153</sup> Another study reported reduced specificity
      in participants with overlapping symptoms of borderline
      personality disorder and bipolar disorder in neuropsychiatric
      clinics.<sup>66</sup> One study reported lower sensitivity and
      higher specificity in participants with comorbidity in a mental
      health center.<sup>106</sup> Two studies in outpatient centers
      reported that diagnostic performance was unaffected by
      comorbidities.<sup>55, 102</sup> Some studies pointed out the high
      prevalence of comorbid conditions such as depression and
      anxiety.<sup>77, 94, 135, 141</sup> One study suggested that
      participants with ADHD and depression reported higher levels of
      anxiety.<sup>64</sup></p>
          <p><named-content id="_Toc193750161" content-type="anchor"/>3.2.10
      Key Question 1 Summary of Findings</p>
          <p>Despite the large number of studies, many did not report on the
      exact number of true positives, true negatives etc. The most
      common metrics were the author reported sensitivity. Given that
      sensitivity and specificity are not independent of each other, we
      plotted both for all reported tests in Figure 8. The tool
      indicates also whether studies differentiate adults with ADHD from
      neurotypical adults or adults with another clinical diagnosis.</p>
          <p><named-content id="_Toc193981861" content-type="anchor"/>Figure
      8. Sensitivity and Specificity of ADHD Tests in Adults across
      Studies</p>
          <p>Figure 8 visualizes the much larger evidence base for
      self-reports compared to all other modalities. The figure also
      illustrates the wide variability reported in the individual
      studies for the same modality. In addition, the visualization
      shows that tests were sometimes able to maximize sensitivity or
      specificity, but not both. Finally, with few exceptions, the
      evaluated tests were limited in their success of detecting a
      clinical diagnosis of ADHD.</p>
          <p>The summary of findings table (Table 3) provides a synthesis of
      the results for the key outcomes. Direct comparisons between test
      modalities are shown first, followed by the test performance for
      individual tests, and the summary of the subquestion. The summary
      of findings table shows results for the key outcomes for which at
      least one study with data was identified. The clinical
      misdiagnosis results were limited to studies reporting on clinical
      samples and/or studies comparing to another clinical condition
      such as anxiety. We downgraded by one or by two, depending on the
      impact of the reasons for downgrading on our confidence in the
      summary estimate and resulting evidence statements. Results of
      individual studies for all abstracted outcomes beyond the key
      outcomes are shown in the evidence tables in Appendix C.</p>
          <p><named-content id="_Toc193749731" content-type="anchor"/>Table
      3. Summary of Findings Table Comparative Performance, Performance
      of Combinations, and Performance of Individual Tools against a
      Reference Standard</p>
          <table-wrap>
            <table>
              <colgroup>
                <col width="7%"/>
                <col width="64%"/>
                <col width="15%"/>
                <col width="6%"/>
                <col width="7%"/>
              </colgroup>
              <thead>
                <tr>
                  <th>
                    <p>
                      <bold>Key question</bold>
                    </p>
                    <p>
                      <bold>Outcome</bold>
                    </p>
                    <p>
                      <bold>Comparison or Test</bold>
                    </p>
                  </th>
                  <th>
                    <bold>Contributing studies</bold>
                  </th>
                  <th>
                    <bold>Results of the primary studies</bold>
                  </th>
                  <th>
                    <bold>Reasons for downgrading</bold>
                  </th>
                  <th>
                    <bold>Strength of Evidence and Conclusion</bold>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative clinical misdiagnosis</p>
                    <p>Combinations vs self-report</p>
                  </td>
                  <td>2 studies<sup>98, 154</sup></td>
                  <td>Conflicting results: 1 study reported a 16%
              misdiagnosis rate for the ASRS compared to 18% for a
              combination of variables,<sup>98</sup> while 1 study
              reported a misdiagnosis rate of 39% for the CAARS-S
              compared to 17% for a combination of self and observer
              reports<sup>154</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative clinical misdiagnosis</p>
                    <p>Combinations vs neuropsychological tests</p>
                  </td>
                  <td>1 study<sup>123</sup></td>
                  <td>Favors combination: 1 study reported a clinical
              misdiagnosis rate of 17% for a combination from multiple
              sources compared to 33% for a neuropsychological
              test<sup>123</sup></td>
                  <td>Inconsistency (no replication)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative clinical misdiagnosis</p>
                    <p>Self-report vs clinician tools</p>
                  </td>
                  <td>2 studies<sup>98, 100</sup></td>
                  <td>Favors self-reports: 1 study reported a 16% clinical
              misdiagnosis rate for the ASRS compared to 25% for
              clinician rating tool;<sup>98</sup> another study reported
              a 31% misdiagnosis rate for the CAARS-S compared to 48%
              for the MINI<sup>100</sup></td>
                  <td>Study limitation (studies assessed different
              tests)</td>
                  <td>Low for lower clinical misdiagnosis rate in
              self-report compared to clinician tool</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative clinical misdiagnosis</p>
                    <p>Self-report vs neuropsychological tests</p>
                  </td>
                  <td>2 studies<sup>98, 145</sup></td>
                  <td>Conflicting results: 1 study reported a 16%
              misdiagnosis rate for the ASRS compared to 26% for a
              CPT;<sup>98</sup> 1 study reported a 47% misdiagnosis rate
              for the BADDS compared to 14% for the
              C-CPT<sup>100</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative sensitivity</p>
                    <p>Combination vs self-report</p>
                  </td>
                  <td>2 studies<sup>98, 154</sup></td>
                  <td>Conflicting results: 1 study reported a sensitivity of
              a combination of 91% (corresponding specificity 82%) vs
              76% for the ASRS (corresponding specificity
              84%),<sup>98</sup> 1 study reported a sensitivity of a
              combination of 43% (corresponding specificity 83%) vs 65%
              for the CAARS-S (corresponding specificity
              61%);<sup>154</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative sensitivity</p>
                    <p>Combination vs neuropsychological tests</p>
                  </td>
                  <td>3 studies<sup>78, 98, 123</sup></td>
                  <td>Favors combination: Estimates ranged for a combination
              from 94% (corresponding specificity 84%) vs QbTest 84%
              (corresponding specificity 80%)<sup>78</sup> to 90% for a
              combination (corresponding specificity 83%) vs a CPT test
              with 80% (corresponding specificity
              67%)<sup>123</sup></td>
                  <td>Study limitation (compared different tests and
              combinations)</td>
                  <td>Low for higher sensitivity when using combinations of
              tests compared to neuropsychological tests</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative sensitivity</p>
                    <p>Self vs parent report</p>
                  </td>
                  <td>2 studies<sup>65, 122</sup></td>
                  <td>Conflicting results: 1 study reported a sensitivity of
              89% for the BAARS (corresponding specificity 30%) vs BAARS
              parent rating 60% (corresponding specificity
              77%);<sup>65</sup> 1 study reported a sensitivity of 57%
              for CAARS-S (corresponding specificity 81%) vs 94% for a
              parent rating (corresponding specificity
              57%)<sup>122</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative sensitivity</p>
                    <p>Self-report vs neuropsychological tests</p>
                  </td>
                  <td>2 studies<sup>98, 145</sup></td>
                  <td>Favors self-report: 1 study reported a sensitivity of
              92% for the BADDS (corresponding specificity 33%) vs 47%
              for the C-CPT (corresponding specificity
              86%);<sup>145</sup> 1 study reported 76% for the ASRS
              (corresponding specificity 84%) vs 30% for a CPT
              (corresponding specificity 74%)<sup>98</sup></td>
                  <td>Study limitation (compared different tests and
              combinations)</td>
                  <td>Low for higher sensitivity for self-reports compared
              to neuropsychological tests</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative sensitivity</p>
                    <p>Self-report vs clinician tool</p>
                  </td>
                  <td>2 studies<sup>98, 100</sup></td>
                  <td>No difference: 1 study reported a sensitivity of 83%
              for CAARS-S (corresponding specificity 69%) vs 83% for
              MINI (corresponding specificity 52%);<sup>100</sup> 1
              study reported 76% for the ASRS (corresponding specificity
              84%) vs CAARS-O sensitivity of 76% (corresponding
              specificity 75%)<sup>98</sup></td>
                  <td>Study limitation (compared different tests and
              combinations)</td>
                  <td>Low for no difference in sensitivity between
              self-reports and clinician tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative specificity</p>
                    <p>Combination vs self-report</p>
                  </td>
                  <td>2 studies<sup>98, 154</sup></td>
                  <td>Conflicting results: 1 study reported a specificity of
              83% for a combination (corresponding sensitivity 43%) vs
              61% for the CAARS-S (corresponding sensitivity
              65%);<sup>154</sup> 1 study reported a specificity of 82%
              for a combination (corresponding sensitivity 91%) vs 84%
              for the ASRS (corresponding sensitivity
              76%)<sup>98</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative specificity</p>
                    <p>Combination vs neuropsychological tests</p>
                  </td>
                  <td>3 studies<sup>78, 98, 123</sup></td>
                  <td>Favors combination: Estimates ranged from 84% for a
              combination (corresponding sensitivity 94%) vs 80% for the
              QbTest (corresponding sensitivity 84%)<sup>78</sup> to 83%
              for a combination (corresponding sensitivity 90%
              (corresponding sensitivity 80%) vs 67% for
              CPT<sup>123</sup></td>
                  <td>Study limitation (compared different tests and
              combinations)</td>
                  <td>Low for higher specificity in combination tests
              compared to neuropsychological tests</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative specificity</p>
                    <p>Self vs parent report</p>
                  </td>
                  <td>2 studies<sup>65, 122</sup></td>
                  <td>Conflicting results: 1 study reported a specificity of
              81% for the CAARS-S (corresponding sensitivity 57%) vs 57%
              for the CAARS-P (corresponding sensitivity
              94%);<sup>122</sup> 1 study reported a specificity of 30%
              for the BAARS self-report (corresponding sensitivity 89%)
              vs 77% for the BAARS parent report (corresponding
              sensitivity 60%)<sup>65</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative specificity</p>
                    <p>Self-report vs neuropsychological tests</p>
                  </td>
                  <td>2 studies<sup>98, 145</sup></td>
                  <td>Conflicting results: 1 study reported a specificity of
              84% for the ASRS (corresponding sensitivity 76%) vs 74%
              for a CPT (corresponding sensitivity 30%);<sup>98</sup> 1
              study reported a specificity of 33% for the BADDS
              (corresponding sensitivity 92%) vs 86% for the C-CPT
              (corresponding sensitivity 47%)<sup>145</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative specificity</p>
                    <p>Self-report vs clinician tool</p>
                  </td>
                  <td>2 studies<sup>98, 100</sup></td>
                  <td>Favors self-report: 1 study reported specificity of
              84% for the ASRS (corresponding sensitivity 76%) vs 75%
              for the CAARS-O (corresponding sensitivity
              76%);<sup>98</sup> 1 study reported a specificity of 69%
              for the CAARS-S (corresponding sensitivity 83%) vs 52% for
              the MINI (corresponding sensitivity
              83%)<sup>100</sup></td>
                  <td>Study limitation (compared different tests and
              combinations)</td>
                  <td>Low for favoring self-reports over clinician
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative administration and scoring time</p>
                  </td>
                  <td>0 studies</td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative inter-rater reliability</p>
                  </td>
                  <td>0 studies</td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative costs</p>
                  </td>
                  <td>0 studies</td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Comparative diagnostic concordance of primary care
              provider with specialist</p>
                  </td>
                  <td>0 studies</td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Insufficient for comparative statements between
              tools</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Combination</p>
                    <p>Combining self and informant symptom ratings,
              demographic variables, neuropsychological assessments
              and/or EEG data to diagnose ADHD</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>3 studies<sup>78, 98, 123</sup></td>
                  <td>Reported clinical false positive rate ranged from 16%
              in a study combining self-ratings and QbTest data to
              distinguish ADHD from Asperger’s syndrome<sup>78</sup> to
              18% in a study combining multiple self-reports and an
              observer report to distinguish from
              aggression<sup>98</sup></td>
                  <td>Study limitation (cannot be replicated based on
              reported detail)</td>
                  <td>Low for fair clinical false positive rate</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Combination</p>
                    <p>Combining self and informant symptom ratings,
              demographic variables, neuropsychological assessments
              and/or EEG data to diagnose ADHD</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>6 studies<sup>65, 78, 98, 123, 132, 154</sup></td>
                  <td>Sensitivity ranged from 100% using a Bayesian
              probability model integrating 3 diagnostic tools (WURS and
              EEG variables, corresponding specificity 100%,
              n=12)<sup>132</sup> to 43% combining CAARS self and
              observer reports (corresponding specificity
              83%)<sup>154</sup> with the majority of studies reporting
              good sensitivity</td>
                  <td>Imprecision</td>
                  <td>Low for good sensitivity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Combination</p>
                    <p>Combining self and informant symptom ratings,
              demographic variables, neuropsychological assessments
              and/or EEG data to diagnose ADHD</p>
                    <p>Specificity</p>
                  </td>
                  <td>6 studies<sup>65, 78, 98, 123, 132, 154</sup></td>
                  <td>Specificity ranged from 100% using a Bayesian
              probability model integrating 3 diagnostic tools (WURS and
              EEG variables, corresponding sensitivity 100%,
              n=12)<sup>132</sup> to 63% in a prediction model that
              combined BAARS parent and self-ratings of current and
              childhood ADHD diagnosis (corresponding specificity
              89%)<sup>65</sup> with the majority of studies reporting
              acceptable sensitivity</td>
                  <td>Imprecision</td>
                  <td>Low for acceptable specificity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Self-report</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>23
              studies<sup>46, 50, 51, 62, 77, 87, 98, 100-102, 106, 108, 109, 111, 112, 122, 123, 130, 131, 141, 145, 153, 163</sup></td>
                  <td>Reported clinical false positive rates ranged from 12%
              differentiating from depression or generalized anxiety
              using the WURS<sup>130</sup> to 90% in students with
              academic or psychological difficulties using the
              CAARS-S<sup>101</sup></td>
                  <td>Imprecision (values ranged widely)</td>
                  <td>Low for substantial clinical false positive rate</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Self-report</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>40
              studies<sup>46, 50, 51, 58, 62-65, 70, 71, 77, 86, 87, 92, 94, 98, 100-102, 105, 106, 108, 109, 111, 112, 122, 123, 130, 131, 135, 141, 142, 145, 152-155, 159, 163, 164</sup></td>
                  <td>Sensitivity ranged from 100% (CAARS-S corresponding
              specificity 10%<sup>101</sup> or ASRS-v1.1 with
              specificity not reported)<sup>58</sup> to 14% (CAARS-S,
              corresponding specificity 92%)<sup>86</sup></td>
                  <td>Imprecision (range from excellent to poor)</td>
                  <td>Low for good sensitivity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Self-report</p>
                    <p>Specificity</p>
                  </td>
                  <td>37
              studies<sup>50, 51, 62-65, 70, 71, 77, 86, 87, 92, 94, 98, 100-102, 105, 106, 108, 109, 111, 112, 122, 123, 130, 131, 141, 142, 145, 152-155, 159, 163, 164</sup></td>
                  <td>Specificity ranged from 99% (CBS corresponding
              specificity 90%)<sup>71</sup> to 10% (CAARS-S,
              corresponding specificity 100%)<sup>101</sup></td>
                  <td>Imprecision (range from excellent to poor)</td>
                  <td>Low for good specificity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Self-report</p>
                    <p>Administration and scoring time</p>
                  </td>
                  <td>1 study<sup>105</sup></td>
                  <td>1 study explicitly stated that the newly developed
              ADHD rating scale took about 15 minutes to
              complete<sup>105</sup></td>
                  <td>Inconsistency (no replication)</td>
                  <td>Low for short administration and scoring time</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Self-report</p>
                    <p>Rater agreement</p>
                  </td>
                  <td>8
              studies<sup>50, 65, 98, 100, 108, 109, 154, 163</sup></td>
                  <td>
                    <p>1 study reported on kappa and found 0.006 agreement
              between WURS-brief vs DIVA rating;<sup>50</sup> 1 study
              reported 89% agreement between self and informant
              report;<sup>108</sup></p>
                    <p>1 study reported an ICC of 0.43 for self vs parent
              BAARS-IV ratings;<sup>65</sup> 6 studies reporting Pearson
              self-observer correlations reported ranges from r 0.24 for
              a CAARS subscale<sup>154</sup> to r 0.58 for CAARS-S:SV vs
              MINI report<sup>100</sup></p>
                  </td>
                  <td>Inconsistency (reporting on different measures and
              questionnaires)</td>
                  <td>Moderate for limited rater agreement</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Peer report</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>1 study<sup>98</sup></td>
                  <td>Reported clinical false positive rates was 48% in an
              inpatient psychiatric hospital unit for the
              CAARS-O<sup>98</sup></td>
                  <td>Inconsistency (no replication)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Peer report</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>3 studies<sup>65, 98, 122</sup></td>
                  <td>Sensitivity varied widely from 94% (CAARS:P,
              corresponding specificity 57%)<sup>122</sup> to 60%
              (BAARS-IV, corresponding specificity
              77%)<sup>65</sup></td>
                  <td>Inconsistency (reporting on different questionnaires),
              imprecision (range from excellent to poor)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Peer report</p>
                    <p>Specificity</p>
                  </td>
                  <td>3 studies<sup>65, 98, 122</sup></td>
                  <td>Specificity ranged from 77% (BAARS-IV, corresponding
              sensitivity 60%)<sup>65</sup> to 57% sensitivity (CAARS:P,
              corresponding sensitivity 94%)<sup>122</sup></td>
                  <td>Inconsistency (reporting on different questionnaires),
              imprecision (range from fair to poor)</td>
                  <td>Low for limited specificity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Peer report</p>
                    <p>Rater agreement</p>
                  </td>
                  <td>1 study<sup>65</sup></td>
                  <td>1 study reported ICCs ranging from 0.43 to0.31 for
              BAARS-IV subscales<sup>65</sup></td>
                  <td>Inconsistency (no replication), study limitation
              (subscales only)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuropsychological tests</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>9
              Studies<sup>45, 55, 78, 95, 98, 119, 123, 140, 145</sup></td>
                  <td>Reported clinical false positive rates ranged from 11%
              in a study using Stroop test variables for participants
              referred for neuropsychological evaluation<sup>95</sup> to
              60% in a model based on QbTest with motion tracking
              variables<sup>144</sup></td>
                  <td>Inconsistency (studies used different combinations of
              variables), Study limitation (unclear if conditions can be
              replicated</td>
                  <td>Low for substantial clinical false positive rate</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuropsychological tests</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>21
              studies<sup>45, 55, 59, 66, 68, 69, 78, 95, 98, 104, 114, 118, 119, 123, 134, 137, 140, 144-146, 158</sup></td>
                  <td>Reported sensitivity ranged from 93% (corresponding
              specificity 100%) integrating AQT variables<sup>118</sup>
              to 17% for an individual subtest of the C-CPT
              (corresponding specificity 90%)<sup>146</sup></td>
                  <td>Imprecision (wide range of results)</td>
                  <td>Low for acceptable sensitivity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuropsychological tests</p>
                    <p>Specificity</p>
                  </td>
                  <td>21
              studies<sup>45, 55, 59, 66, 68, 69, 78, 95, 98, 104, 114, 118, 119, 123, 134, 137, 140, 144-146, 158</sup></td>
                  <td>Reported specificity ranged from 100% (corresponding
              sensitivity 93%) integrating AQT variables<sup>118</sup>
              to 40% for a model integrating QbTest Plus variables
              (corresponding sensitivity 88%)<sup>144</sup></td>
                  <td>Imprecision (wide range of results)</td>
                  <td>Low for acceptable specificity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuropsychological tests</p>
                    <p>Administration and scoring time</p>
                  </td>
                  <td>15
              studies<sup>45, 55, 59, 66, 68, 69, 75, 78, 99, 104, 114, 123, 144, 145, 151</sup></td>
                  <td>There was some variation, but 7 studies estimated the
              duration of the test to be 20
              minutes<sup>45, 55, 66, 69, 78, 123, 144</sup></td>
                  <td>Study limitation (scoring / data interpretation not
              mentioned)</td>
                  <td>Low for short administration time</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuroimaging</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>2 studies<sup>48, 136</sup></td>
                  <td>1 study reported a 3% clinical false positive rate for
              a large psychiatric database;<sup>48</sup> 1 study
              reported a 24% rate in a sample with various psychiatric
              and neuropsychiatric disorders using 3D thresholded
              SPECT<sup>136</sup></td>
                  <td>Imprecision (range from low to substantial)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuroimaging</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>5 studies<sup>48, 56, 136, 157, 161</sup></td>
                  <td>Performance ranged from 100% (SPECT, corresponding
              specificity 97%)<sup>48</sup> to 54% in a clinical sample
              (SPECT, corresponding specificity 76%)<sup>136</sup></td>
                  <td>Imprecision (wide range of values)</td>
                  <td>Low for acceptable sensitivity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuroimaging</p>
                    <p>Specificity</p>
                  </td>
                  <td>5 studies<sup>48, 56, 136, 157, 161</sup></td>
                  <td>Performance ranged from 97% (SPECT, corresponding
              sensitivity 100%)<sup>48</sup> to 65% (functional MRI,
              corresponding sensitivity 91%)<sup>161</sup></td>
                  <td>Imprecision (wide range of values)</td>
                  <td>Low for acceptable specificity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuroimaging</p>
                    <p>Administration and scoring time</p>
                  </td>
                  <td>1 study<sup>136</sup></td>
                  <td>1 study reported a procedure duration of 15-20
              minutes<sup>136</sup></td>
                  <td>Inconsistency (no replication, very specific
              test)</td>
                  <td>Low for short duration</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Neuroimaging</p>
                    <p>Rater agreement</p>
                  </td>
                  <td>1 study<sup>48</sup></td>
                  <td>1 study reported kappa 0.79 for agreement in visual
              interpretation of scans<sup>48</sup></td>
                  <td>Inconsistency (no replication, very specific
              task)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>EEG</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>1 study<sup>89</sup></td>
                  <td>1 study reported a clinical false positive rate of
              3.8% using auditory brainstem response profiling
              test<sup>89</sup></td>
                  <td>Inconsistency (no replication, very specific
              test)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>EEG</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>10
              studies<sup>54, 80, 96, 97, 115, 116, 125, 126, 135, 139</sup></td>
                  <td>Reported sensitivity ranged from 100% (machine
              learning assisted, corresponding specificity
              87%)<sup>91</sup> to 67% (resting state EEG, corresponding
              specificity 83%)<sup>125</sup></td>
                  <td>Imprecision (values ranged widely)</td>
                  <td>Low for acceptable sensitivity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>EEG</p>
                    <p>Specificity</p>
                  </td>
                  <td>10
              studies<sup>54, 80, 96, 97, 115, 116, 125, 126, 135, 139</sup></td>
                  <td>Reported specificity ranged from 95% (event-related
              potential, corresponding specificity 86%)<sup>54</sup> to
              37% (resting state EEG, corresponding specificity
              73%)<sup>96</sup></td>
                  <td>Imprecision (values ranged widely)</td>
                  <td>Low for good specificity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>EEG</p>
                    <p>Administration and scoring time</p>
                  </td>
                  <td>6 studies<sup>54, 91, 96, 97, 116, 125</sup></td>
                  <td>Reported session duration ranged from 6
              minutes<sup>96</sup> to 26 minutes<sup>116</sup></td>
                  <td>Imprecision (substantial variation)</td>
                  <td>Low for short duration</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Biomarkers</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>2 studies<sup>88, 150</sup></td>
                  <td>1 study reported a clinical false positive rate of 17%
              in an eye tracker study in sample of participants with
              conduct disorder;<sup>88</sup> 1 study reported a rate of
              75% in a MFNU study in a psychiatric outpatient clinic
              (some participants had subthreshold
              ADHD)<sup>150</sup></td>
                  <td>Imprecision (value ranged widely), Inconsistency (very
              different biomarkers, only 1 study each)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Biomarkers</p>
                  </td>
                  <td>4 studies<sup>49, 79, 88, 150</sup></td>
                  <td>Performance ranged from 98% (MFNU, corresponding
              specificity 25%)<sup>150</sup> to 80% (eye tracker,
              corresponding specificity 83%)<sup>88</sup></td>
                  <td>Imprecision (values varied), Inconsistency (no
              replication of the same marker)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Biomarker</p>
                    <p>Specificity</p>
                  </td>
                  <td>4 studies<sup>49, 79, 88, 150</sup></td>
                  <td>Performance ranged from 83% (eye tracker,
              corresponding sensitivity 80%)<sup>88</sup> to 25% (MFNU,
              corresponding sensitivity 98%)<sup>150</sup></td>
                  <td>Imprecision (values ranged from acceptable to
              poor)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Biomarker</p>
                    <p>Administration and scoring time</p>
                  </td>
                  <td>1 study<sup>88</sup></td>
                  <td>1 study reported that the eye tracking task took about
              15 minutes<sup>88</sup></td>
                  <td>Inconsistency (no replication, very specific
              task)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Clinician tools</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>3 studies<sup>100, 121, 123</sup></td>
                  <td>Reported clinical false positive rates ranged from 9%
              for the MINI-Plus in an addiction treatment
              center<sup>121</sup> to 48% for the
              MINI<sup>100</sup></td>
                  <td>Inconsistency (different tools), Imprecision (values
              ranged widely), Study limitation (likely dependent on
              specific patient population)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Clinician tool</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>3 studies<sup>100, 121, 123</sup></td>
                  <td>Performance ranged from 83% (corresponding specificity
              52%)<sup>100</sup> to 73% (corresponding specificity
              90%)<sup>123</sup></td>
                  <td>Imprecision (values varied), Inconsistency (different
              tools), Study limitation (likely dependent on patient
              population)</td>
                  <td>Low for fair sensitivity</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>Clinician tool</p>
                    <p>Specificity</p>
                  </td>
                  <td>3 studies<sup>100, 121, 123</sup></td>
                  <td>Performance ranged from 91% (corresponding sensitivity
              75%)<sup>121</sup> to 52% (corresponding sensitivity
              83%)<sup>100</sup></td>
                  <td>Imprecision (values varied), Inconsistency (different
              tools), Study limitation (likely dependent on specific
              patient population)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>All tests</p>
                    <p>Costs</p>
                  </td>
                  <td>0 studies</td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1</p>
                    <p>All tests</p>
                    <p>Concordance primary care and specialty</p>
                  </td>
                  <td>0 studies</td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of clinical setting</p>
                    <p>All outcomes</p>
                  </td>
                  <td>N/A</td>
                  <td>N/A</td>
                  <td>Inconsistency (lack of primary care studies)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of comparator sample</p>
                    <p>Clinical misdiagnosis</p>
                  </td>
                  <td>N/A</td>
                  <td>4 studies noted that tests were less effective when
              distinguishing ADHD from other clinical conditions (rather
              than the general population) due to overlapping
              symptoms<sup>64, 102, 145, 150</sup></td>
                  <td>Study limitation (not all tests addressed)</td>
                  <td>Low for higher risk of clinical misdiagnosis in
              clinical samples*</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of ADHD presentation</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>N/A</td>
                  <td>Conflicting results across 4
              studies<sup>70, 94, 101, 141</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of age of participants and age at diagnosis</p>
                    <p>Sensitivity and specificity</p>
                  </td>
                  <td>N/A</td>
                  <td>1 study reported that sensitivity and specificity were
              higher in younger adults (18-44) compared to older adults
              (31-44)<sup>94</sup></td>
                  <td>Inconsistency (no replication)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of participant sex</p>
                    <p>Sensitivity and specificity</p>
                  </td>
                  <td>N/A</td>
                  <td>Conflicting results across 5
              studies<sup>55, 56, 89, 100, 155, 163</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of comorbidities</p>
                    <p>Sensitivity</p>
                  </td>
                  <td>N/A</td>
                  <td>Conflicting results: while 2 studies reported no
              effect of comorbidities on sensitivity,<sup>101, 153</sup>
              1 study reported lower sensitivity,<sup>106</sup> and 2
              studies reported that diagnostic performance was
              unaffected by comorbidities<sup>55, 102</sup></td>
                  <td>Inconsistency (conflicting results)</td>
                  <td>Insufficient</td>
                </tr>
                <tr>
                  <td>
                    <p>KQ1a</p>
                    <p>Effect of comorbidities</p>
                    <p>Specificity</p>
                  </td>
                  <td>N/A</td>
                  <td>3 studies reported challenges for
              specificity,<sup>66, 101, 153</sup> 1 study reported
              higher specificity in participants with
              comorbidities,<sup>106</sup> 2 studies reported that
              diagnostic performance was unaffected by
              comorbidities;<sup>55, 102</sup> 4studies pointed out the
              high prevalence of comorbid conditions such as depression
              and anxiety.<sup>77, 94, 135, 141</sup></td>
                  <td>Study limitation (not all tests addressed)</td>
                  <td>Low for lower specificity in participants with
              comorbidities</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
          <p>Notes: We broadly categorized performance as follows: low
      (&lt;5%), fair (&lt;20-5%), substantial (20-60%) clinical
      misdiagnosis rate; limited (&lt;80%), poor (&lt;69%), fair
      (70-79%), acceptable (80-89%), good (90-95%), excellent (96-100%)
      sensitivity and specificity; short (&lt;30 minutes) administration
      and scoring time; limited rater agreement (kappa &lt;0.8,
      correlations &lt;0.40); *clinical samples defined as composed of
      participants undergoing diagnostic workup (as opposed to general,
      unselected, and/or neurotypical participant samples)</p>
          <p>Abbreviations: ADHD Attention-Deficit/Hyperactivity Disorder;
      AQT Adult ADHD Quick Test; ASRS Adult ADHD Self-Report Scale;
      BAARS Barkley Adult ADHD Rating Scale; BADDS Brown
      Attention-Deficit Disorder Scales; C-CPT Conners continuous
      performance test; CAARS-O Conners Adult ADHD Rating
      Scale-Observer-Report; CAARS-P Conners Adult ADHD Rating
      Scale-Peer-Report; CAARS-S Conners Adult ADHD Rating
      Scale-Self-Report; CBS Current Behavior Scale; CPT continuous
      performance test; DIVA Diagnostic Interview for ADHD in Adults;
      EEG electroencephalogram; ICC intra-class correlation; GRADE
      Grading of Recommendations Assessment, Development and Evaluation;
      KQ key question, MINI Mini-International Neuropsychiatric
      Interview; MFNU Motor Function Neurological Assessment; MRI
      magnetic resonance imaging; N/A not applicable or not available;
      QbTest quantified behavioral test; SPECT single photon emission
      computed tomography; vs versus; WURS Wender Utah Rating Scale</p>
          <p>The included studies did not report on the impact for
      participants of being correctly or incorrectly diagnosed. Studies
      reported only on the performance of the tests but not the effect a
      diagnosis (or a misdiagnosis) had on participants or similar.</p>
          <p>None of the included studies reported on unintended
      consequences, adverse events, adverse effects, or side effects of
      the diagnostic tools, including blood-based biomarker, EEG,
      neuroimaging, and neuropsychological test studies.</p>
          <p>Finally, we identified numerous studies reporting on the
      performance of tests for detecting feigning ADHD. All studies also
      reporting also on the diagnostic performance of diagnosing ADHD
      are included in the respective test sections earlier in this
      chapter and the evidence tables C1 to C8. Studies used subjective
      tests such as self-report questionnaires as well as objective
      tests such as neuropsychological test batteries. Results of all
      studies reporting on feigning ADHD are shown in the evidence table
      in the appendix (Appendix Table C9).</p>
        </sec>
      </sec>
    </sec>
    <sec id="discussion">
      <title>Discussion</title>
      <p>This evidence report synthesizes the results of evaluations of
  available tools for diagnosing attention deficit/hyperactivity
  disorder in adults. The systematic review reveals a complex landscape
  with varying levels of evidence across assessment approaches. We
  identified over 100 studies evaluating the diagnostic performance of
  self-report questionnaires, peer review questionnaires,
  neuropsychological tests, neuroimaging, electroencephalogram (EEG),
  diverse biomarkers, clinician tools, combinations of modalities, and
  tools to identify feigning ADHD. Despite the research volume, direct
  comparisons between tests were limited, often resulting in
  insufficient strength of evidence for definitive evidence
  statements.</p>
      <p>As part of the review, we also addressed a context question
  regarding the relative frequency of use of tools, given that the use
  of tools in routine care can be quite different from the scientific
  research literature. The current frequency of use of the various tools
  for diagnosing ADHD in adults by primary care and specialty mental
  health clinicians is unknown. Nevertheless, some published reports
  suggest that their use is common and widespread. For example, the
  American Academy of Family Practitioners recommend obtaining rating
  scales for ADHD from both the patient and significant others in the
  patient’s life (spouse, a close relative, employer, or colleague).
  Likewise, the American Psychiatric Association advises the use of ADHD
  rating scales in addition an in-depth clinical interview for the ADHD
  diagnosis.<sup>165</sup></p>
      <p>Large surveys suggest that primary care physicians, psychiatrists,
  and psychologists commonly, but nurse practitioners less often, rely
  on one or more of these tools when diagnosing ADHD. An online survey
  of 1,924 U.S. physicians completed a survey about care of adults for
  ADHD; 83 percent of primary care physicians and 97 percent of
  psychiatrists screened for adult ADHD in adults who complained of
  typical ADHD symptoms, with 64 percent of primary care physicians and
  57 percent of psychiatrists using an ADHD rating scale to aid their
  screening.<sup>166</sup> However, only 20 percent of primary care
  physicians and 25 percent of psychiatrists conducted an extended
  interview to confirm the diagnosis. Once initiating stimulant
  treatment, however, 69 percent reported using a rating scale to help
  titrate the dose. Another survey of 400 primary care physicians
  surveyed indicated that 85 percent would take a more active role in
  making an ADHD diagnosis if they had a screening tool that was
  appropriately developed and validated and both easy to use and quickly
  administered.<sup>167</sup> Studies of diagnostic reports submitted by
  young adults who were seeking academic accommodations at postsecondary
  schools or on medical licensing exams showed that most relied
  primarily or exclusively on current self-reported symptoms on rating
  scales, suggesting their widespread use by psychologists. Those
  studies also reported, however, that the clinicians failed to obtain
  collateral reports, confirm childhood onset, establish functional
  impairment, or rule out other potential causes for the reported
  symptoms.<sup>168-171</sup> A survey mailed to 262 nurse practitioners
  in Alaska indicated that only 12 percent were likely to diagnose ADHD
  in practice; 38 percent of the 68 who responded to a question about
  methods used to diagnose ADHD in adults reported using a diagnostic
  screening tool.<sup>172</sup></p>
      <p>Neuropsychological test measures and specialized rating scales are
  also commonly used for both diagnostic and clinical assessment of ADHD
  in adults. This is particularly true with the recent promulgation of
  commercial, computer-based platforms for administering various
  versions of the Continuous Performance Task (CPT), such as the QB
  test, that claim diagnostic utility for adults with ADHD. An indirect
  indication of the frequency of use of these tests, at least by
  psychologists and neuropsychologists, is a Delphi consensus study
  published in 2019. The study surveyed 27 clinician researchers from
  around the world who were experienced in working with adults who have
  ADHD and asked them to rate, over four rounds of questioning that
  progressively honed a list of most highly prioritized tests, the
  importance of neuropsychological functions in assessing adults who
  have ADHD, with the aim of composing a list of the most relevant
  neuropsychological functions to assess and the corresponding tools to
  assess them.<sup>173</sup> The top five domains identified and the
  tools recommended to assess them with strong group consensus were: (1)
  sustained attention (assessed using Conners Continuous Performance
  Test III), (2) distractibility (Conners CPT III), (3) inhibitory
  control (Go/NoGo test), (4) task planning and organization (the BRIEF
  self-report survey), (5) working memory (digit span test). ADHD
  symptoms identified to assess included impulsivity and hyperactivity.
  The assessments were not considered to be diagnostic per se, because
  poor scores on the measures can have multiple causes. The tools were
  instead recommended for clinical assessment to characterize
  neuropsychological functioning in adults already diagnosed with
  ADHD.</p>
      <p><named-content id="_Toc201103574" content-type="anchor"/>4.1
  Comparative diagnostic performance of tools to diagnose ADHD among
  adults</p>
      <p>We identified over 100 studies that assessed putative tools to aid
  the diagnosis of ADHD in adults. Although this is a substantial number
  of studies, we deemed the strength of evidence for the reported
  performance measures across each of categories of diagnostic tools to
  be generally low because of large performance variability across
  studies, the use of widely varying non-ADHD comparison populations,
  reporting practices that precluded meta-analyses across studies, and
  statistical analyses that were often exploratory across a large number
  of variables.</p>
      <p><named-content id="_Toc201103575" content-type="anchor"/>4.1.1
  Measures Reported for Diagnostic Performance</p>
      <p>As outlined in detail in the introduction, diagnosing Adult ADHD is
  complex and in addition to issues surrounding the reference standard,
  this review also highlighted limitations associated with reported
  measures. Most studies reported sensitivity (true positive rate),
  specificity (true negative rate), and diagnostic accuracy (how many
  are correctly diagnosed). Although these are standard performance
  statistics for diagnostic classification, they have the important
  limitation of being dependent on an arbitrary threshold that is
  applied to scores from a diagnostic tool that defines whether
  individual participants do or do not have ADHD – for example, the
  percent of symptoms endorsed, the numerical score on a rating of
  symptom severity or measure of cognitive performance, or the power in
  an EEG frequency band. Studies that use the same diagnostic tool often
  apply different thresholds to the scores from that tool, which will
  necessarily alter the reported sensitivities and specificities.
  Comparing sensitivities and specificities across studies that use
  differing thresholds is therefore like comparing apples and
  oranges.</p>
      <p>Moreover, sensitivity and specificity, because of how they are
  defined and calculated, inherently have an inverse relationship to one
  another, such that raising the diagnostic threshold for a score on a
  tool will reduce sensitivity (i.e., it will identify fewer people who
  truly have ADHD) but increase specificity (i.e., falsely identify
  fewer people as having ADHD who do not in fact have it), and vice
  versa for lowering the diagnostic threshold. This inherent trade-off
  between sensitivity and specificity establishes an operational limit
  for plots of sensitive versus specific as shown in the figures along
  the y = -x line, i.e., from the upper left to lower right corner of
  the plot, which would identify diagnostic tests that perform at no
  better than chance. Tools in the upper right quadrant of that plot
  improve in overall performance as they approach the upper right
  corner, or perfect accuracy (100% true positives and 100% true
  negatives). Identified research shows that, for categories of tools
  such as rating scales and neuropsychological test measures that have
  the most data points, many studies perform little better than chance
  (they lie close to the y = -x line; studies that lie to the left of it
  perform worse than chance) and, moreover, because they lie on or near
  the diagonal, the findings suggest that variability in performance
  likely derives from differences in the thresholds applied to the
  scores from the diagnostic tools. Unfortunately, adjusting sensitivity
  and specificity through use of the same diagnostic threshold is
  impossible without having the scores from the tool for each study
  participant. Reports of diagnostic accuracy suffer the same limitation
  of depending inherently on the diagnostic threshold applied to the
  tool’s score.</p>
      <p>One index of diagnostic performance that addresses these
  limitations of sensitivity and specificity metrics is AUC (area under
  the curve), a measure from receiver operating characteristic (ROC)
  curves that was first developed by engineers during World War II to
  detect enemy objects in the battlefield. An ROC curve is a plot of
  sensitivity vs specificity across the entire range of possible
  diagnostic thresholds. The area under this ROC curve provides a
  single, overall index of performance that is independent of diagnostic
  threshold. AUC values range of 0.5 (corresponding to the y=x line)
  indicate that the tool provides no information above chance for
  diagnostic classification. Values of 1.0 (corresponding to the
  vertical x=0 line) indicate that the tests performs perfectly,
  correctly classifying all participants who have ADHD as having it and
  all non-ADHD participants as not having it. Intermediate AUC values of
  90 to 100 are commonly classified as <italic>excellent</italic>
  performance; 80 to 90 as <italic>good</italic>; 70 to 80
  <italic>fair</italic>; 60 to 70 <italic>poor</italic>; and 50 to 60 as
  <italic>failed</italic>. Studies of diagnostic tools are increasingly
  reporting performance in terms of AUC, in addition to the more
  traditional measures of sensitivity and specificity.</p>
      <p>A minority of studies reported other measures of diagnostic
  performance, including positive predictive value (PPV) and negative
  predictive value (NPV). They are calculated as PPV = True Positives /
  (True Positives + False Positives), and NPV = True Negatives / (True
  Negatives + False Negatives). PPV is the probability that a person
  with a positive test result has the condition; NPV is the probability
  that a person with a negative test result does not have the condition.
  False positives will increase and false negatives will decline with
  lower base rates in the population – if no one has the condition, all
  positive results are false, and all negative results are correct then
  PPV will decrease to 0.00 (no one with a positive test result has the
  condition) and NPV will increase to 1.00 - everyone with a negative
  test result does not have the condition (and the reverse is true if
  everyone has the condition). Thus, these metrics represent the utility
  of diagnostic tools in a particular setting that has a specific base
  rate of ADHD in population sampled. They will differ across varying
  diagnostic settings because the base rates of ADHD differ across those
  settings (the base rate may be, for example, 60-70% in a clinic where
  patients assessed for suspected ADHD, it may be 50% in a study
  designed to have equal numbers of ADHD and healthy control
  participants, or it may be 5% in an epidemiological sample of the
  general population). Very few studies that we identified for inclusion
  reported PPV and NPV values, generally without providing accurate and
  independent estimates of the base rates of ADHD in the study’s
  specific diagnostic setting.</p>
      <p><named-content id="_Toc201103576" content-type="anchor"/>4.1.2
  The Importance of the Comparator Sample</p>
      <p>Measures of diagnostic accuracy will vary with the characteristics
  of the non-ADHD participants from which the diagnostic tool is
  attempting to discriminate the study’s ADHD participants. For example,
  if the non-ADHD participants are patients who have more symptoms that
  overlap those of ADHD, as occurs commonly with patients who have
  autism, depression, or anxiety, false positives will tend to be higher
  than in studies where the non-ADHD participants have few or no
  symptoms that overlap, as happens when the comparator group is a
  sample of neurotypical controls.</p>
      <p>In real-world clinical practice, clinicians rarely if ever need to
  determine whether a patient has ADHD or is healthy and symptom-free
  (the clinical equivalent of a neurotypical control in many research
  studies). The patient has presented to the clinician with some kind of
  clinical problem, or they would not be seeing the clinician. That
  problem likely has symptoms that overlap those of ADHD, or ADHD would
  not be considered as a clinical possibility. For these reasons, the
  much more clinically relevant studies of performance for tools that
  aid the diagnosis of ADHD are those that employ a comparator group of
  participants who have mental health problems and symptoms that may
  overlap those of ADHD. The
  <italic><underline>most</underline></italic> clinically relevant
  comparison are from studies in which all participants were presenting
  for evaluation of possible ADHD, because real-world clinicians are
  asked to diagnose ADHD in patients who are presenting for an ADHD
  assessment.<sup>33</sup> These comparator samples will tend to produce
  more false positives in diagnostic testing, thus lowering specificity
  metrics.<sup>168</sup></p>
      <p><named-content id="_Toc201103577" content-type="anchor"/>4.1.3
  Rating Scales</p>
      <p>Numerous studies reported on performance for at least one
  self-report measure in diagnosing ADHD (Figure 5). The number of
  different scales was large (17), but the most commonly reported
  measures were the CAARS, ASRS, and WURS. Studies that used the same
  measure often applied different diagnostic cut-offs to the score the
  measure generates. Self-reports were generally able to correctly rule
  out ADHD, with good but rarely excellent performance and substantial
  variation across studies.<sup>71, 86, 101</sup></p>
      <p>Examination of the plotted sensitivity versus specificity suggests
  that sensitivity and specificity measures are similarly distributed
  around the y=x line, indicating that self-rating scales are similarly
  likely to under-identify individuals who truly have ADHD (reflecting
  sensitivity) and to over-identify individuals who do not have ADHD
  (reflecting specificity).<sup>168</sup> Closer examination also
  suggests that the measures of CAARS performance tended to lie along
  the y = -x line or close to it, suggesting poorer performance
  independent of the specific diagnostic threshold used. Measures of the
  ASRS tended to cluster closer to the upper right corner, suggesting
  overall better performance, independent of the diagnostic threshold
  used. Only three studies reported performance for peer ratings, but
  the characteristics of the studies preclude interpretation.</p>
      <p><named-content id="_Toc201103578" content-type="anchor"/>4.1.4
  Neuropsychological Tests</p>
      <p>A considerable number of studies have been published that report on
  the performance of various neuropsychological tests to diagnose ADHD
  in adults. Most of these studies assessed performance of a wide range
  of measures in a highly exploratory way, without specific hypotheses
  for which measures would perform best. All the studies reported on
  performance of some form of CPT, but the CPT, like most of the
  individual neuropsychological tests, itself generates many measures,
  and which of those measures was reported and performed best varied
  widely across studies. These approaches to the analysis and reporting
  of results greatly complicate comparison of performance across studies
  and the interpretation and generalization of findings. The best
  performing of the neuropsychological tests are reported here, which
  risks a positive bias for assessing overall performance of
  neuropsychological tests, but which nevertheless seems to be the most
  efficient way to report findings.</p>
      <p>With all these caveats, results indicated a substantial false
  negative rate in most studies.<sup>95, 144</sup> Sensitivity varied
  widely, from excellent for the AQT<sup>118</sup> to very
  poor,<sup>146</sup> with most sensitivity measures in the fair range
  or poorer, indicating that neuropsychological tests often missed the
  diagnosis in those who truly had ADHD. Specificity likewise varied
  widely, from perfect specificity for the AQT<sup>118</sup> to poor
  specificity for QbTest Plus variables,<sup>144</sup> though in
  general, specificity was fair at best, indicating that tests often
  incorrectly identified non-ADHD controls as having ADHD.</p>
      <p>Comparing sensitivity and specificity measures across categories of
  diagnostic tools, neuropsychological tests do not seem to perform
  better than self-report measures (self-report measures have more
  frequent clusters near the upper right corner of the plots, indicating
  better combinations of sensitivity and specificity). Recent systematic
  reviews of the diagnostic utility of continuous performance measures
  for adults with ADHD have concluded that these tests are vulnerable to
  practice effects and the feigning of symptoms, and they alone do not
  sufficiently dis­criminate persons who have ADHD from clinical
  controls.<sup>38, 39</sup></p>
      <p><named-content id="_Toc201103579" content-type="anchor"/>4.1.5
  Other Diagnostic Tools</p>
      <p>With a couple of exceptions, overall diagnostic performance of EEG
  measures was fair to good for the dozen studies that reported them,
  although, similar to the limitations of neuropsychological test
  studies, the EEG measures varied widely across studies and were often
  highly exploratory in assessing performance across many measures.
  Measures, for example, ranged from resting state
  EEG,<sup>96, 125</sup> to event-related potentials during
  neuropsychological tasks,<sup>54, 115</sup> to EEG recordings during
  transcranial magnetic stimulation.<sup>80</sup> Several of the studies
  used machine learning or other techniques to combine various EEG
  measures into a highly complex test measure that would be difficult or
  impossible to replicate in future studies. Most employed a
  non-clinical comparator sample, which likely contributed to the
  reasonable performance measures. Sensitivities ranged from perfect
  performance during a CPT and using machine learning-derived EEG
  measure<sup>91</sup> to fair performance using resting state EEG
  measures.<sup>125</sup> Specificity showed an even wider range from
  excellent for event-related potential<sup>54</sup> to poor performance
  in a study evaluating resting state EEG<sup>96</sup> but was generally
  good in identified studies. Most clinical practices and even research
  centers do not have EEG capability, let alone under the complex
  testing conditions employed in these studies. The real-world
  applicability of these measures is therefore currently extremely
  limited.</p>
      <p>The studies that assessed diagnostic performance for neuroimaging
  measures used a wide range of imaging technologies, including
  SPECT,<sup>48</sup> 3-D SPECT,<sup>136</sup> structural MRI,
  DTI,<sup>56</sup> and resting state fMRI.<sup>157, 161</sup>
  Limitations of these studies are similar to those for EEG measures,
  with diagnostic test measures highly ad hoc and complex, precluding
  generalizability and opportunities for replication. Comparator samples
  were often non-clinical, and analyses were often exploratory across
  multiple test measures. Sensitivities ranged from perfect in a large
  retrospective cohort SPECT study<sup>48</sup> to poor in a SPECT
  study<sup>136</sup> with a clinical comparator sample. Specificities
  ranged from excellent in the retrospective SPECT study<sup>48</sup> to
  fair in an fMRI study).<sup>161</sup> Also similar to EEG, the
  real-world applicability of using neuroimaging methods to aid
  diagnosis is limited by the practical challenges in acquiring the
  imaging measures.</p>
      <p>Five studies reported on performance of putative biomarkers in
  diagnosing ADHD. Each used a different technology, including a genetic
  marker,<sup>79</sup> eye tracking,<sup>88</sup> blood oxidative
  status,<sup>138</sup> physiological data from a wearable
  device,<sup>49</sup> and Motor Function Neurological Assessment
  (MFNU).<sup>150</sup></p>
      <p><named-content id="_Toc201103580" content-type="anchor"/>4.2
  Direct Comparisons of Diagnostic Performance</p>
      <p>Because measures of diagnostic performance, especially measures of
  sensitivity and specificity, vary with the diagnostic threshold
  applied to the score that the diagnostic tool generates, as well as
  sample characteristics, interpreting differences in measures of
  diagnostic performance across studies is exceedingly difficult. All
  these differences in study characteristics undoubtedly contributed to
  the scatter of data points in the plots of sensitivity versus
  specificity shown in the figures; disentangling all of these effects
  on measures of diagnostic performance across studies is
  impossible.</p>
      <p>For these reasons, studies that directly compare measures of
  performance across diagnostic tools in the same sample of participants
  are most valuable to identify better performing tools. We identified
  11 such studies. Of those, two had only six participants each who had
  ADHD<sup>100, 132</sup> and preclude interpretation. One study
  reported performance metrics only for EEG measures.<sup>54</sup> Of
  the remaining studies, seven were discriminating participants with
  ADHD from participants with other clinical
  conditions<sup>65, 78, 98, 122, 123, 145, 154</sup> and one was
  discriminating from participants with a mix of patients and
  neurotypical controls.<sup>119</sup> They all assessed performance of
  self-rating scales for ADHD symptoms. Those that attempted to make
  very difficult clinical discriminations reported the poorest
  performance (e.g., ADHD+ASD vs ASD alone: sensitivity 57%, specificity
  81%;<sup>122</sup> combined type ADHD vs predominantly Inattentive
  ADHD: sensitivity 65%, specificity 61%).<sup>154</sup> The other
  studies generally reported sensitivities ranging from the mid-70’s to
  low 90’s, but those with the highest sensitivities had the lowest
  specificities, in the high 20’s and low 30’s, as expected given the
  inherent trade-off between sensitivity and specificity that depends on
  the diagnostic threshold applied to scores from the rating scale. Peer
  ratings were also assessed in three of the
  studies:<sup>65, 98, 122</sup> one reported substantially lower
  sensitivities but higher specificities than for the
  self-ratings;<sup>65</sup> one reported performance comparable to
  self-ratings; <sup>98</sup> and one reported substantially higher
  sensitivity and specificity when using both an ADHD scale and an ASD
  scale in discriminating ASD+ASD from ASD alone.<sup>122</sup>
  Combining the self-ratings and peer ratings in two of these studies
  yielded comparable sensitivity in one study,<sup>65</sup> improved
  sensitivity in the other,<sup>98</sup> and improved specificity in
  both, compared with self-ratings alone.</p>
      <p>Neuropsychological measures were assessed in five of these
  studies.<sup>78, 98, 119, 123, 145</sup> Sensitivities ranged from 30
  percent (corresponding specificity 74%) <sup>98</sup>to 84 percent
  (corresponding specificity 80%),<sup>78</sup> and specificities ranged
  from 56 percent (corresponding sensitivity 73.3%)<sup>123</sup> to 86
  percent (corresponding sensitivity 47%).<sup>145</sup> Generally,
  however, performance of these as stand-alone measures was poorer than
  for self-ratings, and studies were inconsistent in identifying which
  of the numerous measures from the continuous performance measurement
  (e.g., omission errors, commission errors, reaction time variability)
  provided the best performance. Three of these studies assessed
  diagnostic performance when combining self-ratings with continuous
  performance measures.<sup>78, 119, 123</sup> One found substantially
  better sensitivity than for the neuropsychological test alone and
  better specificity than for the self-rating alone, one found better
  sensitivity and specificity than for the continuous performance test
  alone,<sup>78</sup> and one did not report sensitivity or specificity
  for the combination.<sup>119</sup></p>
      <p>These findings from head-to-head comparisons, taken together,
  suggest that the combination of self-ratings, peer ratings, and
  continuous performance test scores may one day prove more useful than
  either measure alone in accurately diagnosing ADHD. Currently,
  however, self-ratings combined with peer ratings offer the best
  evidence for improving diagnostic performance over either rating
  alone.</p>
      <p><named-content id="_Toc193750164" content-type="anchor"/>4.3
  Implications</p>
      <p>Self-report scales are easy to use tools to aid the diagnosis of
  ADHD in both primary and specialty care settings. They are prone,
  however, to both false positive and false negative findings,
  especially when used in a setting where adults present for evaluation
  of suspected ADHD. A negative test is reassuring but not conclusive,
  and it likely prompts in a patient complaining about ADHD symptoms an
  assessment of current symptoms, as well as retrospective assessment of
  symptoms earlier in childhood (when symptom expression may have been
  more complete) from other sources – including spouses, significant
  others, parents, siblings, and teacher comments in school records. A
  negative test also prompts questions about other mental health
  problems whose symptoms overlap those of ADHD, especially depression,
  anxiety, substance abuse, stress, and trauma.</p>
      <p>Self-report scales are also prone to false positives, most often
  from the presence of one or more of these conditions with overlapping
  symptoms. Therefore, assessing the validity of positive responses to
  questions on the scale helps in deciding how likely the test result is
  to be a true positive. Thus, patients with a positive test results
  should elaborate on experiences of symptoms in their own words, noting
  when the symptoms first began to discern if they were present in
  childhood, reviewing the trajectory of the symptoms over time, the
  settings or experiences that exacerbate them, and what kind of
  functional impairment they produce, if any.<sup>16</sup> ADHD symptoms
  in childhood can be assessed by asking patients and parents to
  complete retrospective symptom reports on standard checklists, such as
  the ADHD rating scale<sup>174</sup> or the Conners 3 rating
  scale.<sup>175</sup> Similar to a negative test, positive tests also
  raise questions about overlapping symptoms from other conditions.
  Assessing symptoms of other conditions that can overlap with ADHD
  symptoms can be done even in a busy clinical practice through the use
  of existing scales for depression and anxiety (such as the
  PHQ-9<sup>176</sup> and GAD-7<sup>177</sup>). It is critical to assess
  whether positive responses truly represent ADHD or instead the
  symptoms of another clinical condition.<sup>16</sup></p>
      <p>Neuropsychological tests, including the CPT, are not routine in
  diagnosing ADHD in adults, and both sensitivity and specificity for
  these tests are on average lower than for self-report measures.
  Certainly, the long and expensive batteries of traditional
  neuropsychological testing will not aid diagnosis of ADHD, though they
  may serve other clinical purposes. Prior reviews of CPT performance as
  a diagnostic tool in adults with ADHD have yielded these same
  conclusions.<sup>38, 39</sup> Whether the combination of a CPT with
  self-report measures can improve diagnostic performance is at present
  unclear. In addition, symptom validity tests and performance validity
  tests can detect some invalid presentations in self-reports and
  inadequate effort in neuropsychological tests and many experts have
  recommended the use of these tools as part of a comprehensive
  assessment of ADHD in adults.<sup>178-184</sup> Identified studies
  varied regarding the inclusion of validity tests. In addition, an
  individual’s effort during testing can fluctuate significantly over
  the course of an assessment, and individuals differ in what cognitive
  abilities they choose to exaggerate or feign
  deficits.<sup>110, 185</sup></p>
      <p>Finally, the quality of evidence for objective tests that are not
  vulnerable to impression management such as EEG, neuroimaging, and
  biomarkers, as tools to diagnose ADHD in adults is low. None of the
  performance findings have been replicated, and no clinical
  effectiveness studies have been conducted to assess use of these tools
  in the real world to diagnose ADHD. From a practical perspective, very
  few primary care or specialty mental health clinicians have access to
  these technologies. Thus, these tools are not even remotely close to
  being ready for clinical application to aid diagnosis, even though the
  FDA has approved one EEG measure as a purported diagnostic
  aid.<sup>186, 187</sup></p>
      <p><named-content id="_Toc193981789" content-type="anchor"/>4.4
  Strengths, Limitations, and Applicability</p>
      <p>A strength of this review is its scope and inclusiveness -
  publications did not have date restrictions, and they were not limited
  to use of any pre-specified tools, which led to inclusion of novel
  EEG, neuroimaging, and biomarker studies in the diagnosis of ADHD.
  Nonetheless, this review was limited to diagnostic accuracy studies
  and did not focus on psychometric considerations such as the validity
  of symptoms supporting a diagnosis. In addition, we restricted the
  review to English-language studies, which will have missed some tools
  used locally outside of the U.S. and other English-speaking
  countries.</p>
      <p>The conclusions of this review are limited by the poor quality of
  evidence for performance of every category of diagnostic tool and by
  the paucity of reporting findings that would support meta-analysis
  across studies, including AUCs, false positive and negative rates, and
  the thresholds applied to scores from the diagnostic tools.
  Furthermore, limiting to studies reporting on a reference standard
  added focus to the review, but given the issues surrounding a clinical
  diagnosis of ADHD in adults also needs to acknowledge that there is no
  true and universally accepted gold standard in this research area.</p>
      <p>Finally, several included studies reported multiple exclusions for
  eligible participants, which hinders the generalizability of the
  findings to patients seen in routine practice, in particular in
  primary care. Furthermore, some studies used sophisticated and
  resource-intense assessment methods, as well as advanced analytic
  procedures to optimize diagnostic performance. Hence, diagnostic
  performance may not translate from the favorable effects shown in the
  documented research to real world practice and likely represent a
  best-case scenario.</p>
      <p><named-content id="_Toc193981790" content-type="anchor"/>4.5
  Next Steps</p>
      <p>Despite the limitations of studies thus far, it seems clear from
  their findings that no single rating scale or neuropsychological test,
  and probably no single neuroimaging algorithm or biomarker, will
  provide the desired combination of high sensitivity and high
  specificity in diagnosing adults who have ADHD in real-world settings,
  where the clinical question is whether a given individual who is
  suspected of having ADHD actually has it. The relatively few studies
  that have directly compared the performance of diagnostic tools with
  one another provide some early indication that the combination of
  tools may yield may improve both sensitivity and specificity in
  diagnosing ADHD compared with the use of any single tool alone. Future
  studies should compare the performance of tools within and across
  categories, both singly and in combination. The methods for optimally
  combining measures across different tools should be made explicit and
  have a clear rationale. Algorithms for combining measures that are
  based on machine learning, neural networks, or other similar “black
  box” technologies should be made publicly available to facilitate
  validation, replication, and dissemination. Much more research is
  needed to determine how to combine data optimally across informants or
  tools.<sup>16, 33</sup></p>
      <p>Future studies should move past the use of neurotypical comparator
  groups, which have little or no real-world clinical relevance, and
  instead assess diagnostic performance only in clinical samples.
  Further, future studies should assess diagnostic performance in
  clinically important participant subgroups, including subgroups
  defined by age, sex, race, ethnicity, and the presence of disorders
  that commonly co-occur with ADHD, if only to be able to say with more
  confidence that there are no differences. We cannot assume that the
  absence of research equates to the absence of evidence and we had to
  note several times that the evidence was simply insufficient for more
  concrete evidence statements. Because the diagnosis of ADHD requires
  childhood onset, studies are needed to assess how best to assess and
  validate the presence of symptoms in childhood.<sup>168</sup> It is
  often difficult to obtain childhood educational and medical records
  and adults’ recall of childhood symptoms is
  limited.<sup>16, 168, 169, 188-193</sup> More research is also needed
  on measures to detect invalid responses in completing self-report ADHD
  rating scales and inadequate effort on neuropsychological
  tests.<sup>33</sup></p>
      <p>Future studies of diagnostic tools should report their findings in
  much more detail to support meta-analyses across studies. This would
  include reporting false positive and negative rates, the thresholds
  applied to scores from the diagnostic tools, and any data manipulation
  used to produce the finding. Studies should also report ROC analyses
  to support comparisons of test performance across studies that are
  independent of diagnostic thresholds. Studies should also make
  available their individual-level data in public repositories to
  support future efforts at replication, synthesis, and new
  discovery.</p>
      <p>Although currently available “objective” measures of neurocognitive
  performance are not likely to be useful tools in diagnosing ADHD in
  adults, continued search for and development of better objective,
  performance-based measures is warranted. Candidate tools will need to
  overcome the limitations identified for prior continuous performance
  tests and other neuropsychological tests. New, better-performing tools
  will need to correlated better with ADHD symptom ratings, have better
  test-retest reliability, have fewer ceiling effects that likely
  contribute to false negative diagnoses, and have greater ecological
  validity – i.e., better simulate the effects of external and
  environmental distractions that disrupt attention in everyday life.
  <sup>33, 38, 39, 173</sup></p>
      <p>Finally, studies are needed to assess the consequences of being
  correctly or incorrectly diagnosed as having ADHD and any unintended
  consequences and adverse effects of diagnostic tools.</p>
      <p><named-content id="_Toc193750167" content-type="anchor"/>References</p>
      <p>1. Weiss G, Hechtman LT. Hyperactive Children Grown Up, Second
  Edition: ADHD in Children, Adolescents, and Adults: Guilford
  Publications; 1993.</p>
      <p>2. Mannuzza S, Klein RG, Bessler A, et al. Adult psychiatric status
  of hyperactive boys grown up. Am J Psychiatry. 1998 Apr;155(4):493-8.
  doi: 10.1176/ajp.155.4.493. PMID: 9545994.</p>
      <p>3. Biederman J, Mick E, Faraone SV. Age-dependent decline of
  symptoms of attention deficit hyperactivity disorder: impact of
  remission definition and symptom type. Am J Psychiatry. 2000
  May;157(5):816-8. doi: 10.1176/appi.ajp.157.5.816. PMID: 10784477.</p>
      <p>4. Wilens TE, Biederman J, Spencer TJ. Attention
  deficit/hyperactivity disorder across the lifespan. Annu Rev Med.
  2002;53:113-31. doi: 10.1146/annurev.med.53.082901.103945. PMID:
  11818466.</p>
      <p>5. Mannuzza S, Klein RG, Bessler A, et al. Adult outcome of
  hyperactive boys. Educational achievement, occupational rank, and
  psychiatric status. Arch Gen Psychiatry. 1993 Jul;50(7):565-76. doi:
  10.1001/archpsyc.1993.01820190067007. PMID: 8317950.</p>
      <p>6. Center for Disease Control and Prevention. Data and Statistics
  About ADHD.
  <ext-link ext-link-type="uri" xlink:href="https://www.cdcgov/ncbddd/adhd/datahtml">https://www.cdcgov/ncbddd/adhd/datahtml</ext-link>.
  Accessed on June 10, 2024.</p>
      <p>7. Caci HM, Morin AJ, Tran A. Prevalence and correlates of
  attention deficit hyperactivity disorder in adults from a French
  community sample. J Nerv Ment Dis. 2014 Apr;202(4):324-32. doi:
  10.1097/nmd.0000000000000126. PMID: 24647218.</p>
      <p>8. Das D, Cherbuin N, Butterworth P, et al. A population-based
  study of attention deficit/hyperactivity disorder symptoms and
  associated impairment in middle-aged adults. PLoS One.
  2012;7(2):e31500. doi: 10.1371/journal.pone.0031500. PMID:
  22347487.</p>
      <p>9. Estevez N, Eich-Hochli D, Dey M, et al. Prevalence of and
  associated factors for adult attention deficit hyperactivity disorder
  in young Swiss men. PLoS One. 2014;9(2):e89298. doi:
  10.1371/journal.pone.0089298. PMID: 24586672.</p>
      <p>10. Moulin F, Chollet A, Ramos-Quiroga JA, et al. Prevalence and
  Psychosocial Correlates of ADHD Symptoms in Young Adulthood: A French
  Population-Based Study. J Atten Disord. 2018 Jan;22(2):167-81. doi:
  10.1177/1087054717706758. PMID: 28490216.</p>
      <p>11. Asherson P, Akehurst R, Kooij JJ, et al. Under diagnosis of
  adult ADHD: cultural influences and societal burden. J Atten Disord.
  2012 Jul;16(5 Suppl):20s-38s. doi: 10.1177/1087054711435360. PMID:
  22377849.</p>
      <p>12. Cook J, Knight E, Hume I, et al. The self-esteem of adults
  diagnosed with attention-deficit/hyperactivity disorder (ADHD): a
  systematic review of the literature. Atten Defic Hyperact Disord. 2014
  Dec;6(4):249-68. doi: 10.1007/s12402-014-0133-2. PMID: 24668198.</p>
      <p>13. Faraone SV, Biederman J, Mick E. The age-dependent decline of
  attention deficit hyperactivity disorder: a meta-analysis of follow-up
  studies. Psychol Med. 2006 Feb;36(2):159-65. doi:
  10.1017/S003329170500471X. PMID: 16420712.</p>
      <p>14. Kooij SJ, Bejerot S, Blackwell A, et al. European consensus
  statement on diagnosis and treatment of adult ADHD: The European
  Network Adult ADHD. BMC Psychiatry. 2010 Sep 3;10:67. doi:
  10.1186/1471-244X-10-67. PMID: 20815868.</p>
      <p>15. Sibley MH, Swanson JM, Arnold LE, et al. Defining ADHD symptom
  persistence in adulthood: optimizing sensitivity and specificity. J
  Child Psychol Psychiatry. 2017 Jun;58(6):655-62. doi:
  10.1111/jcpp.12620. PMID: 27642116.</p>
      <p>16. Sibley MH. Empirically-informed guidelines for first-time adult
  ADHD diagnosis. J Clin Exp Neuropsychol. 2021 May;43(4):340-51. doi:
  10.1080/13803395.2021.1923665. PMID: 33949916.</p>
      <p>17. Benson K, Flory K, Humphreys KL, et al. Misuse of Stimulant
  Medication Among College Students: A Comprehensive Review and
  Meta-analysis. Clinical Child and Family Psychology Review. 2015
  2015/03/01;18(1):50-76. doi: 10.1007/s10567-014-0177-z.</p>
      <p>18. Agay N, Yechiam E, Carmel Z, et al. Methylphenidate enhances
  cognitive performance in adults with poor baseline capacities
  regardless of attention-deficit/hyperactivity disorder diagnosis. J
  Clin Psychopharmacol. 2014 Apr;34(2):261-5. doi:
  10.1097/jcp.0000000000000076. PMID: 24525641.</p>
      <p>19. Hester R, Nandam LS, O'Connell RG, et al. Neurochemical
  enhancement of conscious error awareness. J Neurosci. 2012 Feb
  22;32(8):2619-27. doi: 10.1523/jneurosci.4052-11.2012. PMID:
  22357846.</p>
      <p>20. Rapoport JL, Buchsbaum MS, Weingartner H, et
  al. Dextroamphetamine. Its cognitive and behavioral effects in normal
  and hyperactive boys and normal men. Arch Gen Psychiatry. 1980
  Aug;37(8):933-43. doi: 10.1001/archpsyc.1980.01780210091010. PMID:
  7406657.</p>
      <p>21. Rapoport JL, Buchsbaum MS, Zahn TP, et al. Dextroamphetamine:
  cognitive and behavioral effects in normal prepubertal boys. Science.
  1978 Feb 3;199(4328):560-3. doi: 10.1126/science.341313. PMID:
  341313.</p>
      <p>22. Turner DC, Robbins TW, Clark L, et al. Cognitive enhancing
  effects of modafinil in healthy volunteers. Psychopharmacology (Berl).
  2003 Jan;165(3):260-9. doi: 10.1007/s00213-002-1250-8. PMID:
  12417966.</p>
      <p>23. Taylor A, Deb S, Unwin G. Scales for the identification of
  adults with attention deficit hyperactivity disorder (ADHD): a
  systematic review. Res Dev Disabil. 2011 May-Jun;32(3):924-38. doi:
  10.1016/j.ridd.2010.12.036. PMID: 21316190.</p>
      <p>24. Peterson BS, Trampush J, Brown M, et al. Tools for the
  Diagnosis of ADHD in Children and Adolescents: A Systematic Review.
  Pediatrics. 2024 Apr 1;153(4). doi: 10.1542/peds.2024-065854. PMID:
  38523599.</p>
      <p>25. Plumber N, Majeed M, Ziff S, et al. Stimulant Usage by Medical
  Students for Cognitive Enhancement: A Systematic Review. Cureus. 2021
  May 22;13(5):e15163. doi: 10.7759/cureus.15163. PMID: 34178492.</p>
      <p>26. Sharif S, Guirguis A, Fergus S, et al. The Use and Impact of
  Cognitive Enhancers among University Students: A Systematic Review.
  Brain Sci. 2021 Mar 10;11(3). doi: 10.3390/brainsci11030355. PMID:
  33802176.</p>
      <p>27. Chandra S, Biederman J, Faraone SV. Assessing the Validity of
  the Age at Onset Criterion for Diagnosing ADHD in DSM-5. J Atten
  Disord. 2021 Jan;25(2):143-53. doi: 10.1177/1087054716629717. PMID:
  26922806.</p>
      <p>28. Caye A, Rocha TB, Anselmi L, et
  al. Attention-Deficit/Hyperactivity Disorder Trajectories From
  Childhood to Young Adulthood: Evidence From a Birth Cohort Supporting
  a Late-Onset Syndrome. JAMA Psychiatry. 2016 Jul 1;73(7):705-12. doi:
  10.1001/jamapsychiatry.2016.0383. PMID: 27192050.</p>
      <p>29. Agnew-Blais JC, Polanczyk GV, Danese A, et al. Evaluation of
  the Persistence, Remission, and Emergence of
  Attention-Deficit/Hyperactivity Disorder in Young Adulthood. JAMA
  Psychiatry. 2016 Jul 1;73(7):713-20. doi:
  10.1001/jamapsychiatry.2016.0465. PMID: 27192174.</p>
      <p>30. Asherson P, Buitelaar J, Faraone SV, et al. ADHD Management in
  Adolescents Transitioning to Adulthood: Challenges and Opportunities.
  Postgraduate Medicine. 2016;128(8):774-83.</p>
      <p>31. Moffitt TE, Houts R, Asherson P, et al. Is Adult ADHD a
  Childhood-Onset Neurodevelopmental Disorder? Evidence From a
  Four-Decade Longitudinal Cohort Study. Am J Psychiatry. 2015
  Oct;172(10):967-77. doi: 10.1176/appi.ajp.2015.14101266. PMID:
  25998281.</p>
      <p>32. Epstein JN, Kollins SH. Psychometric properties of an adult
  ADHD diagnostic interview. J Atten Disord. 2006 Feb;9(3):504-14. doi:
  10.1177/1087054705283575. PMID: 16481667.</p>
      <p>33. Marshall P, Hoelzle J, Nikolas M. Diagnosing
  Attention-Deficit/Hyperactivity Disorder (ADHD) in young adults: A
  qualitative review of the utility of assessment measures and
  recommendations for improving the diagnostic process. Clin
  Neuropsychol. 2021 Jan;35(1):165-98. doi:
  10.1080/13854046.2019.1696409. PMID: 31791193.</p>
      <p>34. Gorlin EI, Dalrymple K, Chelminski I, et al. Reliability and
  validity of a semi-structured DSM-based diagnostic interview module
  for the assessment of Attention Deficit Hyperactivity Disorder in
  adult psychiatric outpatients. Psychiatry Res. 2016 Aug 30;242:46-53.
  doi: 10.1016/j.psychres.2016.05.020. PMID: 27259136.</p>
      <p>35. Wilens TE, Adler LA, Adams J, et al. Misuse and diversion of
  stimulants prescribed for ADHD: a systematic review of the literature.
  J Am Acad Child Adolesc Psychiatry. 2008 Jan;47(1):21-31. doi:
  10.1097/chi.0b013e31815a56f1. PMID: 18174822.</p>
      <p>36. Staley BS, Robinson LR, Claussen AH, et al.
  Attention-Deficit/Hyperactivity Disorder Diagnosis, Treatment, and
  Telehealth Use in Adults - National Center for Health Statistics Rapid
  Surveys System, United States, October-November 2023. MMWR Morb Mortal
  Wkly Rep. 2024 Oct 10;73(40):890-5. doi: 10.15585/mmwr.mm7340a1. PMID:
  39388378.</p>
      <p>37. Adler LA, Faraone SV, Spencer TJ, et al. The reliability and
  validity of self- and investigator ratings of ADHD in adults. J Atten
  Disord. 2008 May;11(6):711-9. doi: 10.1177/1087054707308503. PMID:
  18025250.</p>
      <p>38. Pagán AF, Huizar YP, Schmidt AT. Conner's Continuous
  Performance Test and Adult ADHD: A Systematic Literature Review. J
  Atten Disord. 2023 Feb;27(3):231-49. doi: 10.1177/10870547221142455.
  PMID: 36495125.</p>
      <p>39. Varela JL, Magnante AT, Miskey HM, et al. A systematic review
  of the utility of continuous performance tests among adults with ADHD.
  Clin Neuropsychol. 2024 Feb 29:1-62. doi:
  10.1080/13854046.2024.2315740. PMID: 38424025.</p>
      <p>40. APSARD. U.S. Based Guidelines for Adults with ADHD. n.d.
  <ext-link ext-link-type="uri" xlink:href="https://apsard.org/us-guidelines-for-adults-with-adhd/">https://apsard.org/us-guidelines-for-adults-with-adhd/</ext-link>.
  Accessed on November 10, 2024.</p>
      <p>41. Diagnosis of Attention-Deficit/Hyperactivity Disorder in
  Adults: A Systematic Review. Rockville, MD: Agency for Healthcare
  Research and Quality; February 2025.
  <ext-link ext-link-type="uri" xlink:href="https://effectivehealthcare.ahrq.gov/products/hyperactivity-disorder/protocol">https://effectivehealthcare.ahrq.gov/products/hyperactivity-disorder/protocol</ext-link>.
  Accessed on March 7, 2025.</p>
      <p>42. Methods Guide for Effectiveness and Comparative Effectiveness
  Reviews. Rockville, MD Effective Health Care Program, Agency for
  Healthcare Research and Quality.
  <ext-link ext-link-type="uri" xlink:href="https://effectivehealthcare.ahrq.gov/products/collections/cer-methods-guide">https://effectivehealthcare.ahrq.gov/products/collections/cer-methods-guide</ext-link>.
  Accessed on October 7, 2024.</p>
      <p>43. Whiting PF, Rutjes AW, Westwood ME, et al. QUADAS-2: a revised
  tool for the quality assessment of diagnostic accuracy studies. Ann
  Intern Med. 2011 Oct 18;155(8):529-36. doi:
  10.7326/0003-4819-155-8-201110180-00009. PMID: 22007046.</p>
      <p>44. Abramson DA, White DJ, Rhoads T, et al. Cross-validating the
  Dot Counting Test Among an Adult ADHD Clinical Sample and Analyzing
  the Effect of ADHD Subtype and Comorbid Psychopathology. Assessment.
  2023 Mar;30(2):264-73. doi: 10.1177/10731911211050895. PMID:
  34643101.</p>
      <p>45. Adamou M, Jones SL, Marks L, et al. Efficacy of Continuous
  Performance Testing in Adult ADHD in a Clinical Sample Using QbTest. J
  Atten Disord. 2022 Sep;26(11):1483-91. doi: 10.1177/10870547221079798.
  PMID: 35255743.</p>
      <p>46. Aita SL, Sofko CA, Hill BD, et al. Utility of the Personality
  Assessment Inventory in detecting feigned
  Attention-Deficit/Hyperactivity Disorder (ADHD): The Feigned Adult
  ADHD index. Arch Clin Neuropsychol. 2018 Nov 1;33(7):832-44. doi:
  10.1093/arclin/acx113. PMID: 29186287.</p>
      <p>47. Amen DG, Hanks C, Prunella J. Preliminary evidence
  differentiating ADHD using brain SPECT imaging in older patients. J
  Psychoactive Drugs. 2008 Jun;40(2):139-46. doi:
  10.1080/02791072.2008.10400623. PMID: 18720662.</p>
      <p>48. Amen DG, Henderson TA, Newberg A. SPECT Functional Neuroimaging
  Distinguishes Adult Attention Deficit Hyperactivity Disorder From
  Healthy Controls in Big Data Imaging Cohorts. Front Psychiatry.
  2021;12:725788. doi: 10.3389/fpsyt.2021.725788. PMID: 34899414.</p>
      <p>49. Andrikopoulos D, Vassiliou G, Fatouros P, et al. Machine
  learning-enabled detection of attention-deficit/hyperactivity disorder
  with multimodal physiological data: a case-control study. BMC
  Psychiatry. 2024;24(1). doi: 10.1186/s12888-024-05987-7.</p>
      <p>50. Bakare B, Jordanova V. Psychometric Properties of a Brief
  Screening Measure for ADHD in Adults. Int J Psychol Res (Medellin).
  2020 Jul-Dec;13(2):78-88. doi: 10.21500/20112084.4511. PMID:
  33329880.</p>
      <p>51. Bastiaens L, Galus J. Comparison of the Adult ADHD Self Report
  Scale Screener for DSM-IV and DSM-5 in a Dually Diagnosed Correctional
  Population. Psychiatr Q. 2018 Jun;89(2):505-10. doi:
  10.1007/s11126-017-9553-4. PMID: 29270886.</p>
      <p>52. Becke M, Tucha L, Butzbach M, et al. Feigning Adult ADHD on a
  Comprehensive Neuropsychological Test Battery: An Analogue Study. Int
  J Environ Res Public Health. 2023 Feb 24;20(5). doi:
  10.3390/ijerph20054070. PMID: 36901080.</p>
      <p>53. Berger C, Lev A, Braw Y, et al. Detection of Feigned ADHD Using
  the MOXO-d-CPT. J Atten Disord. 2021 May;25(7):1032-47. doi:
  10.1177/1087054719864656. PMID: 31364437.</p>
      <p>54. Biederman J, Hammerness P, Sadeh B, et al. Diagnostic utility
  of brain activity flow patterns analysis in attention deficit
  hyperactivity disorder. Psychol Med. 2017 May;47(7):1259-70. doi:
  10.1017/s0033291716003329. PMID: 28065167.</p>
      <p>55. Brunkhorst-Kanaan N, Verdenhalven M, Kittel-Schneider S, et
  al. The Quantified Behavioral Test-A Confirmatory Test in the
  Diagnostic Process of Adult ADHD? Front Psychiatry. 2020;11:216. doi:
  10.3389/fpsyt.2020.00216. PMID: 32265761.</p>
      <p>56. Chaim-Avancini TM, Doshi J, Zanetti MV, et al. Neurobiological
  support to the diagnosis of ADHD in stimulant-naïve adults: pattern
  recognition analyses of MRI data. Acta Psychiatr Scand. 2017
  Dec;136(6):623-36. doi: 10.1111/acps.12824. PMID: 29080396.</p>
      <p>57. Chen T, Antoniou G, Adamou M, et al. Automatic diagnosis of
  attention deficit hyperactivity disorder using machine learning.
  Applied Artificial Intelligence. 2021;35(9):657-69. doi:
  10.1080/08839514.2021.1933761.</p>
      <p>58. Chiasson JP, Stavro K, Rizkallah É, et al. Questioning the
  specificity of ASRS-v1.1 to accurately detect ADHD in substance
  abusing populations. J Atten Disord. 2012 Nov;16(8):661-3. doi:
  10.1177/1087054711425768. PMID: 22049481.</p>
      <p>59. Cohen AL, Shapiro SK. Exploring the performance differences on
  the flicker task and the conners' continuous performance test in
  adults with ADHD. J Atten Disord. 2007 Jul;11(1):49-63. doi:
  10.1177/1087054706292162. PMID: 17606772.</p>
      <p>60. Cook CM, Bolinger E, Suhr J. Further Validation of the Conner's
  Adult Attention Deficit/Hyperactivity Rating Scale Infrequency Index
  (CII) for Detection of Non-Credible Report of Attention
  Deficit/Hyperactivity Disorder Symptoms. Arch Clin Neuropsychol. 2016
  Jun;31(4):358-64. doi: 10.1093/arclin/acw015. PMID: 27193367.</p>
      <p>61. Courrégé SC, Skeel RL, Feder AH, et al. The ADHD Symptom
  Infrequency Scale (ASIS): A novel measure designed to detect adult
  ADHD simulators. Psychol Assess. 2019 Jul;31(7):851-60. doi:
  10.1037/pas0000706. PMID: 30802120.</p>
      <p>62. Dakwar E, Mahony A, Pavlicova M, et al. The utility of
  attention-deficit/hyperactivity disorder screening instruments in
  individuals seeking treatment for substance use disorders. J Clin
  Psychiatry. 2012 Nov;73(11):e1372-8. doi: 10.4088/JCP.12m07895. PMID:
  23218166.</p>
      <p>63. De QUIROS GB, Kinsbourne M. Adult ADHD: Analysis of
  Self‐ratings on a Behavior Questionnaire. Annals of the New York
  Academy of Sciences. 2001;931(1):140-7.</p>
      <p>64. Dunlop BW, Wu R, Helms K. Performance of the Adult ADHD
  Self-Report Scale-v1.1 in Adults with Major Depressive Disorder. Behav
  Sci (Basel). 2018 Mar 29;8(4). doi: 10.3390/bs8040037. PMID:
  29596328.</p>
      <p>65. Dvorsky MR, Langberg JM, Molitor SJ, et al. Clinical utility
  and predictive validity of parent and college student symptom ratings
  in predicting an ADHD diagnosis. Journal of Clinical Psychology.
  2016;72(4):401-18.</p>
      <p>66. Edebol H, Helldin L, Norlander T. Objective Measures of
  Behavior Manifestations in Adult ADHD and Differentiation from
  Participants with Bipolar II Disorder, Borderline Personality
  Disorder, Participants with Disconfirmed ADHD as Well as Normative
  Participants. Clin Pract Epidemiol Ment Health. 2012;8:134-43. doi:
  10.2174/1745017901208010134. PMID: 23166565.</p>
      <p>67. Edebol H, Helldin L, Norlander T. Measuring adult Attention
  Deficit Hyperactivity Disorder using the Quantified Behavior Test
  Plus. Psych J. 2013 Apr;2(1):48-62. doi: 10.1002/pchj.17. PMID:
  24294490.</p>
      <p>68. Elbaum T, Braw Y, Lev A, et al. Attention-Deficit/Hyperactivity
  Disorder (ADHD): Integrating the MOXO-dCPT with an Eye Tracker
  Enhances Diagnostic Precision. Sensors (Basel). 2020 Nov 9;20(21).
  doi: 10.3390/s20216386. PMID: 33182303.</p>
      <p>69. Emser TS, Johnston BA, Steele JD, et al. Assessing ADHD
  symptoms in children and adults: evaluating the role of objective
  measures. Behav Brain Funct. 2018 May 18;14(1):11. doi:
  10.1186/s12993-018-0143-x. PMID: 29776429.</p>
      <p>70. Erhardt D, Epstein JN, Conners CK, et al. Self-ratings of ADHD
  symptoms in adults: II. Reliability, validity, and diagnostic
  sensitivity. Journal of Attention Disorders. 1999;3(3):153-8. doi:
  10.1177/108705479900300304.</p>
      <p>71. Faraone S, Biederman J, Spencer T. Diagnostic efficiency of
  symptom items for identifying adult ADHD. Journal of ADHD &amp;
  Related Disorders. 2010;1:38-48.</p>
      <p>72. Finley JA, Brooks JM, Nili AN, et al. Multivariate examination
  of embedded indicators of performance validity for ADHD evaluations: A
  targeted approach. Appl Neuropsychol Adult. 2023 Sep 13:1-14. doi:
  10.1080/23279095.2023.2256440. PMID: 37703401.</p>
      <p>73. Finley JA, Cerny BM, Brooks JM, et al. Cross-validating the
  Clinical Assessment of Attention Deficit-Adult symptom validity scales
  for assessment of attention deficit/hyperactivity disorder in adults.
  J Clin Exp Neuropsychol. 2024 Mar;46(2):111-23. doi:
  10.1080/13803395.2023.2283940. PMID: 37994688.</p>
      <p>74. Fuermaier ABM, Tucha O, Koerts J, et al. The development of an
  embedded figures test for the detection of feigned attention deficit
  hyperactivity disorder in adulthood. PLoS ONE. 2016;11(10). doi:
  10.1371/journal.pone.0164297.</p>
      <p>75. Galloway-Long H, Huang-Pollock C, Neely K. Ahead of the (ROC)
  Curve: A Statistical Approach to Utilizing Ex-Gaussian Parameters of
  Reaction Time in Diagnosing ADHD Across Three Developmental Periods. J
  Int Neuropsychol Soc. 2022 Sep;28(8):821-34. doi:
  10.1017/s1355617721000990. PMID: 34488917.</p>
      <p>76. Gift TE, Reimherr ML, Marchant BK, et al. Wender Utah Rating
  Scale: Psychometrics, clinical utility and implications regarding the
  elements of ADHD. J Psychiatr Res. 2021 Mar;135:181-8. doi:
  10.1016/j.jpsychires.2021.01.013. PMID: 33493947.</p>
      <p>77. Grogan K, Gormley CI, Rooney B, et al. Differential diagnosis
  and comorbidity of ADHD and anxiety in adults. Br J Clin Psychol. 2018
  Mar;57(1):99-115. doi: 10.1111/bjc.12156. PMID: 28895146.</p>
      <p>78. Groom MJ, Young Z, Hall CL, et al. The incremental validity of
  a computerised assessment added to clinical rating scales to
  differentiate adult ADHD from autism spectrum disorder. Psychiatry
  Res. 2016 Sep 30;243:168-73. doi: 10.1016/j.psychres.2016.06.042.
  PMID: 27400220.</p>
      <p>79. Grünblatt E, Geissler J, Jacob CP, et al. Pilot study:
  potential transcription markers for adult attention-deficit
  hyperactivity disorder in whole blood. Atten Defic Hyperact Disord.
  2012 Jun;4(2):77-84. doi: 10.1007/s12402-012-0074-6. PMID:
  22562805.</p>
      <p>80. Hadas I, Hadar A, Lazarovits A, et al. Right prefrontal
  activation predicts ADHD and its severity: A TMS-EEG study in young
  adults. Prog Neuropsychopharmacol Biol Psychiatry. 2021 Dec
  20;111:110340. doi: 10.1016/j.pnpbp.2021.110340. PMID: 33957168.</p>
      <p>81. Harp J, Jasinski L, Shandera-Ochsner A, et al. Detection of
  Malingered ADHD Using the MMPI2RF. Psychological Injury and Law. 2011
  03/01;4:32-43. doi: 10.1007/s12207-011-9100-9.</p>
      <p>82. Harrison AG, Armstrong IT. Development of a symptom validity
  index to assist in identifying ADHD symptom exaggeration or feigning.
  Clin Neuropsychol. 2016 Feb;30(2):265-83. doi:
  10.1080/13854046.2016.1154188. PMID: 26954905.</p>
      <p>83. Harrison AG, Armstrong IT. Differences in performance on the
  test of variables of attention between credible vs. noncredible
  individuals being screened for attention deficit hyperactivity
  disorder. Appl Neuropsychol Child. 2020 Oct-Dec;9(4):314-22. doi:
  10.1080/21622965.2020.1750115. PMID: 32301339.</p>
      <p>84. Harrison AG, Edwards MJ, Parker KC. Identifying students faking
  ADHD: Preliminary findings and strategies for detection. Arch Clin
  Neuropsychol. 2007 Jun;22(5):577-88. doi: 10.1016/j.acn.2007.03.008.
  PMID: 17507198.</p>
      <p>85. Harrison AG, Harrison KA, Armstrong IT. Discriminating
  malingered attention Deficit Hyperactivity Disorder from genuine
  symptom reporting using novel Personality Assessment Inventory
  validity measures. Appl Neuropsychol Adult. 2022 Jan-Feb;29(1):10-22.
  doi: 10.1080/23279095.2019.1702043. PMID: 31852281.</p>
      <p>86. Harrison AG, Nay S, Armstrong IT. Diagnostic Accuracy of the
  Conners' Adult ADHD Rating Scale in a Postsecondary Population. J
  Atten Disord. 2019 Dec;23(14):1829-37. doi: 10.1177/1087054715625299.
  PMID: 26794674.</p>
      <p>87. Houston JP, Kroenke K, Faries DE, et al. A provisional
  screening instrument for four common mental disorders in adult primary
  care patients. Psychosomatics. 2011 Jan-Feb;52(1):48-55. doi:
  10.1016/j.psym.2010.11.011. PMID: 21300195.</p>
      <p>88. Jiménez EC, Avella-Garcia C, Kustow J, et al. Eye Vergence
  Responses During an Attention Task in Adults With ADHD and Clinical
  Controls. J Atten Disord. 2021 Jul;25(9):1302-10. doi:
  10.1177/1087054719897806. PMID: 31959011.</p>
      <p>89. Juselius Baghdassarian E, Nilsson Markhed M, Lindström E, et
  al. Auditory brainstem response (ABR) profiling tests as diagnostic
  support for schizophrenia and adult attention-deficit hyperactivity
  disorder (ADHD). Acta Neuropsychiatr. 2018 Jun;30(3):137-47. doi:
  10.1017/neu.2017.24. PMID: 28803577.</p>
      <p>90. Katz LJ, Wood DS, Goldstein G, et al. The utility of
  neuropsychological tests in evaluation of Attention-Deficit/
  Hyperactivity Disorder (ADHD) versus depression in adults. Assessment.
  1998 Mar;5(1):45-52. doi: 10.1177/107319119800500107. PMID:
  9458341.</p>
      <p>91. Kaur S, Singh S, Arun P, et al. Phase Space Reconstruction of
  EEG Signals for Classification of ADHD and Control Adults. Clin EEG
  Neurosci. 2020 Mar;51(2):102-13. doi: 10.1177/1550059419876525. PMID:
  31533446.</p>
      <p>92. Kessler RC, Adler L, Ames M, et al. The World Health
  Organization Adult ADHD Self-Report Scale (ASRS): a short screening
  scale for use in the general population. Psychol Med. 2005
  Feb;35(2):245-56. doi: 10.1017/s0033291704002892. PMID: 15841682.</p>
      <p>93. Kessler RC, Adler LA, Gruber MJ, et al. Validity of the World
  Health Organization Adult ADHD Self-Report Scale (ASRS) Screener in a
  representative sample of health plan members. Int J Methods Psychiatr
  Res. 2007;16(2):52-65. doi: 10.1002/mpr.208. PMID: 17623385.</p>
      <p>94. Kessler RC, Green JG, Adler LA, et al. Structure and diagnosis
  of adult attention-deficit/hyperactivity disorder: analysis of
  expanded symptom criteria from the Adult ADHD Clinical Diagnostic
  Scale. Arch Gen Psychiatry. 2010 Nov;67(11):1168-78. doi:
  10.1001/archgenpsychiatry.2010.146. PMID: 21041618.</p>
      <p>95. Khan H, Rauch AA, Obolsky MA, et al. A comparison of embedded
  validity indicators from the Stroop Color and Word Test among adults
  referred for clinical evaluation of suspected or confirmed
  attention-deficit/hyperactivity disorder. Psychol Assess. 2022
  Jul;34(7):697-703. doi: 10.1037/pas0001137. PMID: 35357873.</p>
      <p>96. Kiiski H, Rueda-Delgado LM, Bennett M, et al. Functional EEG
  connectivity is a neuromarker for adult attention deficit
  hyperactivity disorder symptoms. Clin Neurophysiol. 2020
  Jan;131(1):330-42. doi: 10.1016/j.clinph.2019.08.010. PMID:
  31506235.</p>
      <p>97. Kim S, Baek JH, Kwon YJ, et al. Machine-learning-based
  diagnosis of drug-naive adult patients with attention-deficit
  hyperactivity disorder using mismatch negativity. Transl Psychiatry.
  2021 Sep 18;11(1):484. doi: 10.1038/s41398-021-01604-3. PMID:
  34537812.</p>
      <p>98. Kingston DA, Ahmed AG, Gray J, et al. The assessment and
  diagnosis of attention deficit hyperactivity disorder in adult
  forensic psychiatric outpatients. Journal of Psychopathology and
  Behavioral Assessment. 2013;35(3):293-300. doi:
  10.1007/s10862-013-9346-5.</p>
      <p>99. Kovner R, Budman C, Frank Y, et al. Neuropsychological testing
  in adult attention deficit hyperactivity disorder: a pilot study. Int
  J Neurosci. 1998 Dec;96(3-4):225-35. doi: 10.3109/00207459808986470.
  PMID: 10069622.</p>
      <p>100. Kumar G, Faden J, Steer RA. Screening for
  attention-deficit/hyperactivity disorder in adult inpatients with
  psychiatric disorders. Psychol Rep. 2011 Jun;108(3):815-24. doi:
  10.2466/03.05.09.13.15.Pr0.108.3.815-824. PMID: 21879629.</p>
      <p>101. Kwan D, Davin N, Harrison AG, et al. Determining cutoff scores
  on the Conners' adult ADHD rating scales that can definitively rule
  out the presence of ADHD in a clinical sample. Appl Neuropsychol
  Adult. 2024 Apr 3:1-11. doi: 10.1080/23279095.2024.2336204. PMID:
  38569190.</p>
      <p>102. Lancaster A, Liljequist L. Cross-validation of PAI scales for
  the detection of suspected ADHD in adults. J Clin Psychol. 2018
  Oct;74(10):1710-8. doi: 10.1002/jclp.22620. PMID: 29574728.</p>
      <p>103. Lee Booksh R, Pella RD, Singh AN, et al. Ability of college
  students to simulate ADHD on objective measures of attention. J Atten
  Disord. 2010 Jan;13(4):325-38. doi: 10.1177/1087054708329927. PMID:
  19439760.</p>
      <p>104. Lev A, Braw Y, Elbaum T, et al. Eye Tracking During a
  Continuous Performance Test: Utility for Assessing ADHD Patients. J
  Atten Disord. 2022 Jan;26(2):245-55. doi: 10.1177/1087054720972786.
  PMID: 33238787.</p>
      <p>105. Lewandowski LJ, Lovett BJ, Codding RS, et al. Symptoms of ADHD
  and academic concerns in college students with and without ADHD
  diagnoses. J Atten Disord. 2008 Sep;12(2):156-61. doi:
  10.1177/1087054707310882. PMID: 18192625.</p>
      <p>106. Liu YS, Cao B, Chokka PR. Screening for Adulthood ADHD and
  Comorbidities in a Tertiary Mental Health Center Using EarlyDetect: A
  Machine Learning-Based Pilot Study. J Atten Disord. 2023
  Feb;27(3):324-31. doi: 10.1177/10870547221136228. PMID: 36367134.</p>
      <p>107. Lovejoy DW, Ball JD, Keats M, et al. Neuropsychological
  performance of adults with attention deficit hyperactivity disorder
  (ADHD): diagnostic classification estimates for measures of frontal
  lobe/executive functioning. J Int Neuropsychol Soc. 1999
  Mar;5(3):222-33. doi: 10.1017/s1355617799533055. PMID: 10217922.</p>
      <p>108. Luty J, Rajagopal Arokiadass SM, Sarkhel A, et al. Validation
  of self-report instruments to assess attention deficit hyperactivity
  disorder symptoms in adults attending community drug and alcohol
  services. J Addict Med. 2009 Sep;3(3):151-4. doi:
  10.1097/ADM.0b013e31819343d0. PMID: 21769011.</p>
      <p>109. Marchant BK, Reimherr FW, Wender PH, et al. Psychometric
  properties of the Self-Report Wender-Reimherr Adult Attention Deficit
  Disorder Scale. Ann Clin Psychiatry. 2015 Nov;27(4):267-77; quiz
  78-82. PMID: 26554368.</p>
      <p>110. Marshall P, Schroeder R, O'Brien J, et al. Effectiveness of
  symptom validity measures in identifying cognitive and behavioral
  symptom exaggeration in adult attention deficit hyperactivity
  disorder. Clin Neuropsychol. 2010 Oct;24(7):1204-37. doi:
  10.1080/13854046.2010.514290. PMID: 20845231.</p>
      <p>111. McCann BS, Roy-Byrne P. Screening and diagnostic utility of
  self-report attention deficit hyperactivity disorder scales in adults.
  Compr Psychiatry. 2004 May-Jun;45(3):175-83. doi:
  10.1016/j.comppsych.2004.02.006. PMID: 15124147.</p>
      <p>112. Mehringer AM, Downey KK, Schuh LM, et al. The Assessment of
  Hyperactivity and Attention (AHA): development and preliminary
  validation of a brief self-assessment of adult ADHD. J Atten Disord.
  2002 Mar;5(4):223-31. doi: 10.1177/108705470100500404. PMID:
  11967478.</p>
      <p>113. Morey LC. Examining a novel performance validity task for the
  detection of feigned attentional problems. Appl Neuropsychol Adult.
  2019 May-Jun;26(3):255-67. doi: 10.1080/23279095.2017.1409749. PMID:
  29251998.</p>
      <p>114. Mostert JC, Onnink AMH, Klein M, et al. Cognitive
  heterogeneity in adult attention deficit/hyperactivity disorder: A
  systematic analysis of neuropsychological measurements. Eur
  Neuropsychopharmacol. 2015 Nov;25(11):2062-74. doi:
  10.1016/j.euroneuro.2015.08.010. PMID: 26336867.</p>
      <p>115. Mueller A, Candrian G, Grane VA, et al. Discriminating between
  ADHD adults and controls using independent ERP components and a
  support vector machine: a validation study. Nonlinear Biomed Phys.
  2011 Jul 19;5:5. doi: 10.1186/1753-4631-5-5. PMID: 21771289.</p>
      <p>116. Müller A, Vetsch S, Pershin I, et al. EEG/ERP-based
  biomarker/neuroalgorithms in adults with ADHD: Development,
  reliability, and application in clinical practice. World J Biol
  Psychiatry. 2020 Mar;21(3):172-82. doi: 10.1080/15622975.2019.1605198.
  PMID: 30990349.</p>
      <p>117. Musso MW, Hill BD, Barker AA, et al. Utility of the
  Personality Assessment Inventory for Detecting Malingered ADHD in
  College Students. J Atten Disord. 2016 Sep;20(9):763-74. doi:
  10.1177/1087054714548031. PMID: 25204276.</p>
      <p>118. Nielsen NP, Wiig EH. AQT cognitive speed and processing
  efficiency differentiate adults with and without ADHD: a preliminary
  study. Int J Psychiatry Clin Pract. 2011 Sep;15(3):219-27. doi:
  10.3109/13651501.2011.582538. PMID: 22121933.</p>
      <p>119. Nikolas MA, Marshall P, Hoelzle JB. The role of neurocognitive
  tests in the assessment of adult attention-deficit/hyperactivity
  disorder. Psychological assessment. 2019;31(5):685.</p>
      <p>120. Notzon DP, Pavlicova M, Glass A, et al. ADHD Is Highly
  Prevalent in Patients Seeking Treatment for Cannabis Use Disorders. J
  Atten Disord. 2020 Sep;24(11):1487-92. doi: 10.1177/1087054716640109.
  PMID: 27033880.</p>
      <p>121. Palma-Álvarez RF, Barta C, Carpentier PJ, et al. Validity of
  the ADHD module of the Mini International Neuropsychiatric Interview
  PLUS for screening of adult ADHD in treatment seeking substance use
  disorder patients: ADHD screening with MINI-Plus. Span J Psychiatry
  Ment Health. 2023 Jan-Mar;16(1):11-5. doi: 10.1016/j.rpsm.2020.04.013.
  PMID: 32561156.</p>
      <p>122. Palmer M, Fang Z, Hollocks MJ, et al. Screening for Attention
  Deficit Hyperactivity Disorder in Young Autistic Adults: The
  Diagnostic Accuracy of Three Commonly Used Questionnaires. J Autism
  Dev Disord. 2023 Oct 28. doi: 10.1007/s10803-023-06146-9. PMID:
  37898580.</p>
      <p>123. Pettersson R, Söderström S, Nilsson KW. Diagnosing ADHD in
  Adults: An Examination of the Discriminative Validity of
  Neuropsychological Tests and Diagnostic Assessment Instruments. J
  Atten Disord. 2018 Sep;22(11):1019-31. doi: 10.1177/1087054715618788.
  PMID: 26681530.</p>
      <p>124. Phillips MS, Wisinger AM, Lapitan-Moore FT, et al.
  Cross-validation of multiple embedded performance validity indices in
  the Rey Auditory Verbal Learning Test and Brief Visuospatial Memory
  Test‑Revised in an adult attention deficit/hyperactivity disorder
  clinical sample. Psychological Injury and Law. 2023;16(1):27-35. doi:
  10.1007/s12207-022-09443-3.</p>
      <p>125. Poil SS, Bollmann S, Ghisleni C, et al. Age dependent
  electroencephalographic changes in attention-deficit/hyperactivity
  disorder (ADHD). Clin Neurophysiol. 2014 Aug;125(8):1626-38. doi:
  10.1016/j.clinph.2013.12.118. PMID: 24582383.</p>
      <p>126. Ponomarev VA, Mueller A, Candrian G, et al. Group Independent
  Component Analysis (gICA) and Current Source Density (CSD) in the
  study of EEG in ADHD adults. Clin Neurophysiol. 2014 Jan;125(1):83-97.
  doi: 10.1016/j.clinph.2013.06.015. PMID: 23871197.</p>
      <p>127. Potts HE, Lewandowski LJ, Lovett BJ. Identifying Feigned ADHD
  in College Students: Comparing the Multidimensional ADHD Rating Scale
  to Established Validity Measures. J Atten Disord. 2022
  Oct;26(12):1622-30. doi: 10.1177/10870547221092095. PMID:
  35466735.</p>
      <p>128. Quinn CA. Detection of malingering in assessment of adult
  ADHD. Arch Clin Neuropsychol. 2003 May;18(4):379-95. PMID:
  14591453.</p>
      <p>129. Ramachandran S, Holmes ER, Rosenthal M, et al. Development of
  the Subtle ADHD Malingering Screener. Assessment. 2019
  Apr;26(3):524-34. doi: 10.1177/1073191118773881. PMID: 29749255.</p>
      <p>130. Reimherr FW, Marchant BK, Gift TE, et al. Psychometric data
  and versions of the Wender Utah Rating Scale including the WURS-25
  &amp; WURS-45. Data Brief. 2021 Aug;37:107232. doi:
  10.1016/j.dib.2021.107232. PMID: 34235235.</p>
      <p>131. Reyes MM, Schneekloth TD, Hitschfeld MJ, et al. The Clinical
  Utility of ASRS-v1.1 for Identifying ADHD in Alcoholics Using PRISM as
  the Reference Standard. J Atten Disord. 2019 Aug;23(10):1119-25. doi:
  10.1177/1087054716646450. PMID: 27138328.</p>
      <p>132. Robeva R, Penberthy JK, Loboschefski T, et al. Combined
  psychophysiological assessment of ADHD: A pilot study of Bayesian
  probability approach illustrated by appraisal of ADHD in female
  college students. Applied Psychophysiology and Biofeedback.
  2004;29:1-18.</p>
      <p>133. Robinson A, Reed C, Davis K, et al. Settling the Score: Can
  CPT-3 Embedded Validity Indicators Distinguish Between Credible and
  Non-Credible Responders Referred for ADHD and/or SLD? J Atten Disord.
  2023 Jan;27(1):80-8. doi: 10.1177/10870547221121781. PMID:
  36113024.</p>
      <p>134. Rogers R, Velsor SF, Donnelly JW, 2nd, et al. Embedded WAIS-IV
  Detection Strategies and Feigned Cognitive Impairment: An
  Investigation of Malingered ADHD. Assessment. 2021 Jan;28(1):44-56.
  doi: 10.1177/1073191120927788. PMID: 32495690.</p>
      <p>135. Roy-Byrne P, Scheele L, Brinkley J, et al. Adult
  attention-deficit hyperactivity disorder: assessment guidelines based
  on clinical presentation to a specialty clinic. Compr Psychiatry. 1997
  May-Jun;38(3):133-40. doi: 10.1016/s0010-440x(97)90065-1. PMID:
  9154368.</p>
      <p>136. Schneider H, Thornton JF, Freeman MA, et al. Conventional
  SPECT Versus 3D Thresholded SPECT Imaging in the Diagnosis of ADHD: A
  Retrospective Study. J Neuropsychiatry Clin Neurosci. 2014
  Fall;26(4):335-43. doi: 10.1176/appi.neuropsych.12110280. PMID:
  26037855.</p>
      <p>137. Schreiber HE, Javorsky DJ, Robinson JE, et al. Rey-Osterrieth
  Complex Figure performance in adults with attention deficit
  hyperactivity disorder: a validation study of the Boston Qualitative
  Scoring System. Clin Neuropsychol. 1999 Nov;13(4):509-20. doi:
  10.1076/1385-4046(199911)13:04;1-y;ft509. PMID: 10806464.</p>
      <p>138. Selek S, Bulut M, Ocak AR, et al. Evaluation of total
  oxidative status in adult attention deficit hyperactivity disorder and
  its diagnostic implications. J Psychiatr Res. 2012 Apr;46(4):451-5.
  doi: 10.1016/j.jpsychires.2011.12.007. PMID: 22257388.</p>
      <p>139. Shahaf G, Reches A, Pinchuk N, et al. Introducing a novel
  approach of network oriented analysis of ERPs, demonstrated on adult
  attention deficit hyperactivity disorder. Clin Neurophysiol. 2012
  Aug;123(8):1568-80. doi: 10.1016/j.clinph.2011.12.010. PMID:
  22261156.</p>
      <p>140. Shepler DK, Callan PD. Differences in executive functioning
  between adults with ADHD and those diagnosed with other psychiatric
  diagnoses: Utility of the CTMT and the WAIS-IV. Appl Neuropsychol
  Adult. 2024 Sep-Oct;31(5):984-93. doi: 10.1080/23279095.2022.2102923.
  PMID: 35894662.</p>
      <p>141. Singh P, White S, Saleem K, et al. Identifying ADHD in adults
  using the international personality disorder examination screening
  questionnaire. J Ment Health. 2015 Aug;24(4):236-41. doi:
  10.3109/09638237.2015.1057331. PMID: 26445014.</p>
      <p>142. Skirrow C, Asherson P. Emotional lability, comorbidity and
  impairment in adults with attention-deficit hyperactivity disorder.
  Journal of affective disorders. 2013;147(1-3):80-6.</p>
      <p>143. Smith ST, Cox J, Mowle EN, et al. Intentional inattention:
  Detecting feigned attention-deficit/hyperactivity disorder on the
  Personality Assessment Inventory. Psychol Assess. 2017
  Dec;29(12):1447-57. doi: 10.1037/pas0000435. PMID: 29227126.</p>
      <p>144. Söderström S, Pettersson R, Nilsson KW. Quantitative and
  subjective behavioural aspects in the assessment of attention-deficit
  hyperactivity disorder (ADHD) in adults. Nord J Psychiatry. 2014
  Jan;68(1):30-7. doi: 10.3109/08039488.2012.762940. PMID: 23527787.</p>
      <p>145. Solanto MV, Etefia K, Marks DJ. The utility of self-report
  measures and the continuous performance test in the diagnosis of ADHD
  in adults. CNS Spectr. 2004 Sep;9(9):649-59. doi:
  10.1017/s1092852900001929. PMID: 15337862.</p>
      <p>146. Sollman MJ, Ranseen JD, Berry DT. Detection of feigned ADHD in
  college students. Psychol Assess. 2010 Jun;22(2):325-35. doi:
  10.1037/a0018857. PMID: 20528060.</p>
      <p>147. Spenceley LM, Wood WLM, Lovett BJ. Using the Woodcock-Johnson
  IV tests of cognitive abilities to detect feigned ADHD. Appl
  Neuropsychol Adult. 2022 May-Jun;29(3):324-32. doi:
  10.1080/23279095.2020.1748631. PMID: 32320323.</p>
      <p>148. Suhr J, Hammers D, Dobbins-Buckland K, et al. The relationship
  of malingering test failure to self-reported symptoms and
  neuropsychological findings in adults referred for ADHD evaluation.
  Arch Clin Neuropsychol. 2008 Sep;23(5):521-30. doi:
  10.1016/j.acn.2008.05.003. PMID: 18562158.</p>
      <p>149. Suhr JA, Buelow M, Riddle T. Development of an infrequency
  index for the CAARS. Journal of Psychoeducational Assessment.
  2011;29(2):160-70. doi: 10.1177/0734282910380190.</p>
      <p>150. Udal ABH, Stray LL, Pripp AH, et al. The Utility of
  Neuromuscular Assessment to Identify ADHD Among Patients with a
  Complex Symptom Picture. Journal of attention disorders.
  2024;28(12):1577-88. doi: 10.1177/10870547241273102.</p>
      <p>151. Unal M, O'Mahony E, Dunne C, et al. The clinical utility of
  three visual attention tests to distinguish adults with ADHD from
  normal controls. Riv Psichiatr. 2019 Sep-Oct;54(5):211-7. doi:
  10.1708/3249.32185. PMID: 31657805.</p>
      <p>152. Ustun B, Adler LA, Rudin C, et al. The World Health
  Organization Adult Attention-Deficit/Hyperactivity Disorder
  Self-Report Screening Scale for DSM-5. JAMA Psychiatry. 2017 May
  1;74(5):520-7. doi: 10.1001/jamapsychiatry.2017.0298. PMID:
  28384801.</p>
      <p>153. van de Glind G, van den Brink W, Koeter MW, et al. Validity of
  the Adult ADHD Self-Report Scale (ASRS) as a screener for adult ADHD
  in treatment seeking substance use disorder patients. Drug Alcohol
  Depend. 2013 Oct 1;132(3):587-96. doi:
  10.1016/j.drugalcdep.2013.04.010. PMID: 23660242.</p>
      <p>154. Van Voorhees EE, Hardy KK, Kollins SH. Reliability and
  validity of self- and other-ratings of symptoms of ADHD in adults. J
  Atten Disord. 2011 Apr;15(3):224-34. doi: 10.1177/1087054709356163.
  PMID: 20424007.</p>
      <p>155. Vizgaitis AL, Bottini S, Polizzi CP, et al. Self-Reported
  Adult ADHD Symptoms: Evidence Supporting Cautious Use in an
  Assessment-Seeking Sample. J Atten Disord. 2023 Aug;27(10):1156-66.
  doi: 10.1177/10870547231172764. PMID: 37158158.</p>
      <p>156. Walls BD, Wallace ER, Brothers SL, et al. Utility of the
  Conners' Adult ADHD Rating Scale validity scales in identifying
  simulated attention-deficit hyperactivity disorder and random
  responding. Psychol Assess. 2017 Dec;29(12):1437-46. doi:
  10.1037/pas0000530. PMID: 29227125.</p>
      <p>157. Wang X, Jiao Y, Tang T, et al. Altered regional homogeneity
  patterns in adults with attention-deficit hyperactivity disorder. Eur
  J Radiol. 2013 Sep;82(9):1552-7. doi: 10.1016/j.ejrad.2013.04.009.
  PMID: 23684384.</p>
      <p>158. Wiig EH, Nielsen NP. A quick test of cognitive speed for
  comparing processing speed to differentiate adult psychiatric
  referrals with and without attention-deficit/hyperactivity disorders.
  Prim Care Companion CNS Disord. 2012;14(2). doi: 10.4088/PCC.11m01273.
  PMID: 22943032.</p>
      <p>159. Williamson KD, Combs HL, Berry DT, et al. Discriminating among
  ADHD alone, ADHD with a comorbid psychological disorder, and feigned
  ADHD in a college sample. Clin Neuropsychol. 2014;28(7):1182-96. doi:
  10.1080/13854046.2014.956674. PMID: 25225947.</p>
      <p>160. Woods SP, Lovejoy DW, Stutts ML, et al. Comparative efficiency
  of a discrepancy analysis for the classification of
  Attention-Deficit/Hyperactivity Disorder in adults. Arch Clin
  Neuropsychol. 2002 May;17(4):351-69. PMID: 14589720.</p>
      <p>161. Yao D, Guo X, Zhao Q, et al. Discriminating ADHD From Healthy
  Controls Using a Novel Feature Selection Method Based on Relative
  Importance and Ensemble Learning. Annu Int Conf IEEE Eng Med Biol Soc.
  2018 Jul;2018:4632-5. doi: 10.1109/embc.2018.8513155. PMID:
  30441383.</p>
      <p>162. Young JC, Gross AM. Detection of response bias and noncredible
  performance in adult attention-deficit/hyperactivity disorder. Arch
  Clin Neuropsychol. 2011 Apr;26(3):165-75. doi: 10.1093/arclin/acr013.
  PMID: 21441258.</p>
      <p>163. Young JL, Powell RN, Zabel C, et al. Development and
  validation of the ADHD Symptom and Side Effect Tracking - Baseline
  Scale (ASSET-BS): a novel short screening measure for ADHD in clinical
  populations. BMC Psychiatry. 2023 Nov 6;23(1):806. doi:
  10.1186/s12888-023-05295-6. PMID: 37932675.</p>
      <p>164. Young S, González RA, Mutch L, et al. Diagnostic accuracy of a
  brief screening tool for attention deficit hyperactivity disorder in
  UK prison inmates. Psychol Med. 2016 May;46(7):1449-58. doi:
  10.1017/s0033291716000039. PMID: 26867860.</p>
      <p>165. Hauk L. AAP releases guideline on diagnosis, evaluation, and
  treatment of ADHD. Am Fam Physician. 2013 Jan 1;87(1):61-2. PMID:
  23317027.</p>
      <p>166. Goodman DW, Surman CB, Scherer PB, et al. Assessment of
  physician practices in adult attention-deficit/hyperactivity disorder.
  Prim Care Companion CNS Disord. 2012;14(4). doi: 10.4088/PCC.11m01312.
  PMID: 23251858.</p>
      <p>167. Adler L, Shaw D, Sitt D, et al. Issues in the diagnosis and
  treatment of adult ADHD by primary care physicians. Primary
  Psychiatry. 2009;16(5):57-63.</p>
      <p>168. Harrison AG, Edwards MJ. The Ability of Self-Report Methods to
  Accurately Diagnose Attention Deficit Hyperactivity Disorder: A
  Systematic Review. J Atten Disord. 2023 Oct;27(12):1343-59. doi:
  10.1177/10870547231177470. PMID: 37366274.</p>
      <p>169. Weis R, Till CH, Erickson CP. ADHD assessment in college
  students: Psychologists’ adherence to DSM-5 criteria and
  multi-method/multi-informant assessment. Journal of Psychoeducational
  Assessment. 2019;37(2):209-25. doi: 10.1177/0734282917735152.</p>
      <p>170. Joy JA, Julius RJ, Akter R, et al. Assessment of ADHD
  documentation from candidates requesting Americans With Disabilities
  Act (ADA) accommodations for the National Board of Osteopathic Medical
  Examiners COMLEX exam. J Atten Disord. 2010 Sep;14(2):104-8. doi:
  10.1177/1087054710365056. PMID: 20424009.</p>
      <p>171. Nelson JM, Whipple B, Lindstrom W, et al. How Is ADHD Assessed
  and Documented? Examination of Psychological Reports Submitted to
  Determine Eligibility for Postsecondary Disability. J Atten Disord.
  2019 Dec;23(14):1780-91. doi: 10.1177/1087054714561860. PMID:
  25534434.</p>
      <p>172. Knutson KC, O'Malley M. Adult attention-deficit/hyperactivity
  disorder: a survey of diagnosis and treatment practices. J Am Acad
  Nurse Pract. 2010 Nov;22(11):593-601. doi:
  10.1111/j.1745-7599.2010.00546.x. PMID: 21054633.</p>
      <p>173. Fuermaier ABM, Fricke JA, de Vries SM, et
  al. Neuropsychological assessment of adults with ADHD: A Delphi
  consensus study. Appl Neuropsychol Adult. 2019 Jul-Aug;26(4):340-54.
  doi: 10.1080/23279095.2018.1429441. PMID: 29424567.</p>
      <p>174. DuPaul GJ, Power TJ, Anastopoulos AD, et al. ADHD Rating
  Scale-5 for children and adolescents: Checklists, norms, and clinical
  interpretation. New York, NY, US: The Guilford Press; 2016.</p>
      <p>175. Conners CK. Conners third edition (Conners 3). Los Angeles,
  CA: Western Psychological Services. 2008:203-2.</p>
      <p>176. Kroenke K, Spitzer RL, Williams JB. The PHQ-9: validity of a
  brief depression severity measure. J Gen Intern Med. 2001
  Sep;16(9):606-13. doi: 10.1046/j.1525-1497.2001.016009606.x. PMID:
  11556941.</p>
      <p>177. Spitzer RL, Kroenke K, Williams JB, et al. A brief measure for
  assessing generalized anxiety disorder: the GAD-7. Arch Intern Med.
  2006 May 22;166(10):1092-7. doi: 10.1001/archinte.166.10.1092. PMID:
  16717171.</p>
      <p>178. Wallace ER, Garcia-Willingham NE, Walls BD, et al. A
  meta-analysis of malingering detection measures for
  attention-deficit/hyperactivity disorder. Psychol Assess. 2019
  Feb;31(2):265-70. doi: 10.1037/pas0000659. PMID: 30359048.</p>
      <p>179. Tucha L, Fuermaier AB, Koerts J, et al. Detection of feigned
  attention deficit hyperactivity disorder. J Neural Transm (Vienna).
  2015 Aug;122 Suppl 1:S123-34. doi: 10.1007/s00702-014-1274-3. PMID:
  25096370.</p>
      <p>180. Sagar S, Miller CJ, Erdodi LA. Detecting feigned
  attention-deficit/hyperactivity disorder (ADHD): Current methods and
  future directions. Psychological Injury and Law. 2017;10(2):105-13.
  doi: 10.1007/s12207-017-9286-6.</p>
      <p>181. Weyandt LL, DuPaul GJ. College students with ADHD: Current
  issues and future directions: Springer; 2013.</p>
      <p>182. Ramsay JR. Psychological assessment of adults with ADHD.
  Attention-deficit hyperactivity disorder: A handbook for diagnosis and
  treatment, 4th ed. New York, NY, US: The Guilford Press;
  2015:475-500.</p>
      <p>183. Bordoff B. The challenges and limitations of diagnosing and
  pharmacologically treating ADHD in university students. Psychological
  Injury and Law. 2017;10(2):114-20. doi: 10.1007/s12207-017-9288-4.</p>
      <p>184. Barkley RA. Barkley deficits in executive functioning scale
  (BDEFS Scale). New York: Guilford Press; 2011.</p>
      <p>185. Boone KB. The need for continuous and comprehensive sampling
  of effort/response bias during neuropsychological examinations. Clin
  Neuropsychol. 2009 May;23(4):729-41. doi: 10.1080/13854040802427803.
  PMID: 18949583.</p>
      <p>186. Snyder SM. Systems and methods to identify a subgroup of ADHD
  at higher risk for complicating conditions. US Patent and Trademark
  Office. (U.S. PPA Number 61/237,911; August 27, 2009) (U.S. PA Number
  12/870,328; August 28, 2010). 2009.</p>
      <p>187. Snyder SM, Rugino TA, Hornig M, et al. Integration of an EEG
  biomarker with a clinician's ADHD evaluation. Brain Behav. 2015
  Apr;5(4):e00330. doi: 10.1002/brb3.330. PMID: 25798338.</p>
      <p>188. Ahmad SI, Owens EB, Hinshaw SP. Little evidence for late-onset
  ADHD in a longitudinal sample of women. J Consult Clin Psychol. 2019
  Jan;87(1):112-7. doi: 10.1037/ccp0000353. PMID: 30570306.</p>
      <p>189. Caye A, Sibley MH, Swanson JM, et al. Late-Onset ADHD:
  Understanding the Evidence and Building Theoretical Frameworks. Curr
  Psychiatry Rep. 2017 Nov 13;19(12):106. doi:
  10.1007/s11920-017-0858-7. PMID: 29130145.</p>
      <p>190. Sibley MH, Rohde LA, Swanson JM, et al. Late-Onset ADHD
  Reconsidered With Comprehensive Repeated Assessments Between Ages 10
  and 25. Am J Psychiatry. 2018 Feb 1;175(2):140-9. doi:
  10.1176/appi.ajp.2017.17030298. PMID: 29050505.</p>
      <p>191. Breda V, Rohde LA, Menezes AMB, et al. Revisiting ADHD
  age-of-onset in adults: to what extent should we rely on the recall of
  childhood symptoms? Psychol Med. 2020 Apr;50(5):857-66. doi:
  10.1017/s003329171900076x. PMID: 30968792.</p>
      <p>192. Mannuzza S, Klein RG, Klein DF, et al. Accuracy of adult
  recall of childhood attention deficit hyperactivity disorder. Am J
  Psychiatry. 2002 Nov;159(11):1882-8. doi:
  10.1176/appi.ajp.159.11.1882. PMID: 12411223.</p>
      <p>193. Miller CJ, Newcorn JH, Halperin JM. Fading memories:
  retrospective recall inaccuracies in ADHD. J Atten Disord. 2010
  Jul;14(1):7-14. doi: 10.1177/1087054709347189. PMID: 19794136.</p>
      <p><named-content id="_Toc193749416" content-type="anchor"/>Abbreviations
  and Acronyms</p>
      <p>ABC Aberrant Behavior Checklist</p>
      <p>ADHD Attention-Deficit/Hyperactivity Disorder</p>
      <p>AHRQ Agency for Healthcare Research and Quality</p>
      <p>AQ10 Autism Quotient - 10</p>
      <p>BAARS-IV Barkley Adult ADHD Rating Scale-IV</p>
      <p>DSM-5 Diagnostic and Statistical Manual of Mental Disorders, Fifth
  Edition</p>
      <p>EEG Electroencephalogram</p>
      <p>EPC Evidence-based Practice Center</p>
      <p>FDA Food and Drug Administration</p>
      <p>N/A Not available</p>
      <p>SEADs Supplemental Evidence And Data for Systematic Reviews</p>
      <p>SOE Strength of Evidence</p>
      <p>TEP Technical Expert Panel</p>
      <p>TOVA Test of Variables of Attention</p>
      <p>Appendixes</p>
      <p>Appendix A. Search Strategy</p>
      <p>Appendix B. List of Included, Background, and Excluded Studies</p>
      <p>Appendix C. Evidence Tables</p>
      <p>Appendix D. Critical Appraisal and Applicability Tables</p>
      <p>Appendix A. Search Strategy</p>
      <p>
        <bold>Date: October 14, 2024</bold>
      </p>
      <p>
        <bold>PubMed</bold>
      </p>
      <table-wrap>
        <table>
          <colgroup>
            <col width="100%"/>
          </colgroup>
          <thead>
            <tr>
              <th>
                <p>"Attention Deficit Disorder with
          Hyperactivity"[Mesh] OR "attention deficit
          hyperactivity disorder"[tiab] OR "ADHD"[tiab]
          OR "attention deficit disorder"[tiab])</p>
                <p>AND</p>
                <p>Adult[MESH] OR Aged[MESH] OR Middle Aged[MESH] OR Young
          Adult[MESH] OR Adult[Title/Abstract] OR
          Adults[Title/Abstract]</p>
                <p>AND</p>
                <p>"Attention Deficit and Disruptive Behavior
          Disorders/diagnosis"[Majr] OR mass screening[mesh] OR
          questionnaires[mesh] OR Interviews as Topic[Mesh] OR
          Psychometrics[Mesh] OR Psychiatric Status Rating Scales[Mesh]
          OR diagnosis[mesh:noexp] OR "Diagnostic Techniques and
          Procedures"[Mesh] OR "Referral and
          Consultation"[Mesh] OR questionnaire[tiab] OR
          questionnaires[tiab] OR screening[tiab] OR screen[tiab] OR
          scale[tiab] OR instrument[tiab] OR instruments[tiab] OR
          interview[tiab] OR interviews[tiab] OR diagnosis[tiab] OR
          diagnostic[tiab] OR diagnosed[tiab] OR Measure [tiab] OR
          test[tiab] OR tests[tiab] OR testing[tiab] OR "Attention
          Deficit Disorder with Hyperactivity/diagnostic
          imaging"[Majr] OR ((("Adaptive Behavior Assessment
          System"[Title/Abstract] OR
          "ABAS-3"[Title/Abstract] OR "Advanced Clinical
          Solutions"[Title/Abstract] OR "Word Choice
          Test"[Title/Abstract] OR "Test of Premorbid
          Functioning"[Title/Abstract] OR "Social
          Cognition"[Title/Abstract] OR "Beck Anxiety
          Inventory"[Title/Abstract] OR
          "BAI"[Title/Abstract] OR "Beck Depression
          Inventory"[Title/Abstract] OR
          "BDI-2"[Title/Abstract] OR "Behavioral
          Assessment System for Children"[Title/Abstract] OR
          "Self-Report of Personality"[Title/Abstract] OR
          "BASC-3 SRP Adolescent"[Title/Abstract] OR
          "Behavioral Assessment System for
          Children"[Title/Abstract] OR "Parent Rating
          Scales"[Title/Abstract] OR "BASC-3 PRS
          Adolescent"[Title/Abstract] OR "BASC-3 SRP
          College"[Title/Abstract] OR "Teacher Rating
          Scales"[Title/Abstract] OR "BASC-3 TRS
          Adolescent"[Title/Abstract] OR "Brown Executive
          Function/Attention Scales"[Title/Abstract] OR "Brown
          EF/A Self"[Title/Abstract] OR "California Verbal
          Learning Test"[Title/Abstract] OR
          "CVLT-3"[Title/Abstract] OR "Standard Form
          California Verbal" "CVLT-3
          Brief"[Title/Abstract] OR "California Verbal
          Learning Test"[Title/Abstract] OR
          "CVLT-C"[Title/Abstract] OR "Childhood Autism
          Rating Scale"[Title/Abstract] OR
          "CARS-2"[Title/Abstract] OR "Childhood Autism
          Rating Scale"[Title/Abstract] OR "High-Functioning
          Version"[Title/Abstract] OR "CARS-2
          HF"[Title/Abstract] OR "Clinical Evaluation of
          Language Fundamentals"[Title/Abstract] OR
          "CELF-5"[Title/Abstract] OR "Comprehensive
          Executive Function Inventory"[Title/Abstract] OR
          "CEFI Adult Observer"[Title/Abstract] OR
          "Comprehensive Executive Function
          Inventory"[Title/Abstract] OR "CEFI Adult
          Self-Report"[Title/Abstract] OR "Conners’ Adult ADHD
          Diagnostic Interview for DSM-IV"[Title/Abstract] OR
          "CAADID Part 1"[Title/Abstract] OR "CAADID Part
          2"[Title/Abstract] OR
          "CAARS–O:L"[Title/Abstract] OR
          "CAARS–S:L"[Title/Abstract] OR "CAARS-2
          Observer"[Title/Abstract] OR "Conners’ Adult ADHD
          Rating Scales"[Title/Abstract] OR "CAARS-2
          Self-Report"[Title/Abstract] OR "Delis-Kaplan
          Executive Function System"[Title/Abstract] OR
          "D-KEFS"[Title/Abstract] OR "Dot Counting
          Test"[Title/Abstract] OR "Grooved Pegboard Test
          Kaufman Test of Educational Achievement"[Title/Abstract]
          OR "KTEA-3"[Title/Abstract] OR
          "Neuropsychological Assessment
          Battery"[Title/Abstract] OR "Attention, Language,
          Memory, Spatial, and Executive Functions
          Modules"[Title/Abstract] OR "NIH Executive
          Abilities–Measures and Instruments for Neurobehavioral
          Evaluation and Re-search"[Title/Abstract] OR "NIH
          EXAMINER"[Title/Abstract] OR "Personality Assessment
          Inventory"[Title/Abstract] OR "PROMIS Sleep
          Assessments Pediatric Parent Proxy"[Title/Abstract] OR
          "Repeatable Battery for the Assessment of
          Neuropsychological Status"[Title/Abstract] OR
          "RBANS"[Title/Abstract] OR "Rey-Osterrieth
          Complex"[Title/Abstract] OR "Wechsler Abbreviated
          Scale of Intelligence"[Title/Abstract] OR
          "WASI-2"[Title/Abstract] OR "Wechsler Adult
          Intelligence Scale"[Title/Abstract] OR
          "WAIS-4"[Title/Abstract] OR
          "WAIS-IV"[Title/Abstract] OR "Wechsler
          Individual Achievement Test"[Title/Abstract] OR
          "WIAT-4"[Title/Abstract] OR "Wechsler
          Intelligence Scale "[Title/Abstract] OR "Wechsler
          Memory Scale"[Title/Abstract] OR
          "WMS-4"[Title/Abstract] OR "Wide Range
          Achievement Test"[Title/Abstract] OR
          "WRAT-5"[Title/Abstract] OR "Adult ADHD Rating
          Scale"[Title/Abstract] OR
          "ADHD-RS"[Title/Abstract] OR "Brown ADD
          scales"[Title/Abstract] OR "Continuous Performance
          Tests"[Title/Abstract] OR "Conners
          CPT"[Title/Abstract] OR "QB
          Test"[Title/Abstract] OR "TOVA"[Title/Abstract]
          OR "Wender Utah Adult ADHD
          Scale"[Title/Abstract]))</p>
                <p>AND</p>
                <p>"Sensitivity and Specificity"[Mesh] OR
          "Diagnostic Errors"[Mesh] OR sensitivity[tiab] OR
          specificity[tiab] OR (accura*[tiab] AND (diagnos*[tiab] OR
          classif*[tiab])) OR "ROC curve"[tiab] OR
          "positive predictive value"[tiab] OR "negative
          predictive value"[tiab] OR "false
          positive"[tiab] OR "false negative"[tiab] OR
          "likelihood ratio"[tiab]</p>
                <p>NOT</p>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>
                <p>Editorial[ptyp] OR Letter[pt] OR Case Reports[pt] OR
          Comment[pt] address[pt] OR "autobiography"[pt] OR
          "bibliography"[pt] OR "biography"[pt] OR
          "case report"[tw] OR "case reports"[tw] OR
          "case series"[tw] OR "comment on"[All
          Fields] OR congress[pt] OR "dictionary"[pt] OR
          "directory"[pt] OR "festschrift"[pt] OR
          "historical article"[pt] OR lecture[pt] OR
          "legal case"[pt] OR "legislation"[pt] OR
          "news"[pt] OR "newspaper article"[pt] OR
          "patient education handout"[pt] OR "periodical
          index"[pt]</p>
                <p>NOT</p>
              </td>
            </tr>
            <tr>
              <td>"animals"[mesh] NOT
          "humans"[mesh])</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>
        <bold>EMBASE</bold>
      </p>
      <p>(((('adaptive behavior assessment system':ti OR 'abas-3':ti OR
  'advanced clinical solutions':ti OR 'word choice test':ti OR 'test of
  premorbid functioning':ti OR 'social cognition':ti OR 'beck anxiety
  inventory':ti OR 'bai':ti OR 'beck depression inventory':ti OR
  'bdi-2':ti OR 'self-report of personality':ti OR 'basc-3 srp
  adolescent':ti OR 'behavioral assessment system for children':ti OR
  'parent rating scales':ti OR 'basc-3 prs adolescent':ti OR 'basc-3 srp
  college':ti OR 'teacher rating scales':ti OR 'basc-3 trs
  adolescent':ti OR 'brown executive function/attention scales':ti OR
  'brown ef/a self':ti OR 'california verbal learning test':ti OR
  'cvlt-3':ti OR 'standard form california verbal':ti) AND 'cvlt-3
  brief':ti OR 'california verbal learning test':ti OR 'cvlt-c':ti OR
  'cars-2':ti OR 'childhood autism rating scale':ti OR 'high-functioning
  version':ti OR 'cars-2 hf':ti OR 'clinical evaluation of language
  fundamentals':ti OR 'celf-5':ti OR 'cefi adult observer':ti OR
  'comprehensive executive function inventory':ti OR 'cefi adult
  self-report':ti OR 'conners adult adhd diagnostic interview for
  dsm-iv':ti OR 'caadid part 1':ti OR 'caadid part 2':ti OR
  'caars–o:l':ti OR 'caars–s:l':ti OR 'caars-2 observer':ti OR 'conners
  adult adhd rating scales':ti OR 'caars-2 self-report':ti OR
  'delis-kaplan executive function system':ti OR 'd-kefs':ti OR 'dot
  counting test':ti OR 'grooved pegboard test kaufman test of
  educational achievement':ti OR 'ktea-3':ti OR 'nepsy-ii developmental
  neuropsychological battery':ti OR 'neuropsychological assessment
  battery':ti OR 'attention, language, memory, spatial,':ti) AND 'ex-
  ecutive functions modules':ti OR 'nih executive
  abilities–measures':ti) AND 'instruments for neurobehavioral
  evaluation':ti AND 're search':ti OR 'nih examiner':ti OR 'personality
  assessment inventory':ti OR 'promis sleep assessments pediatric parent
  proxy':ti OR 'repeatable battery for the assessment of
  neuropsychological status':ti OR 'rbans':ti OR 'rey-osterrieth
  complex':ti OR 'wechsler abbreviated scale of intelligence':ti OR
  'wasi-2':ti OR 'wechsler adult intelligence scale':ti OR 'wais-4':ti
  OR 'wais-iv':ti OR 'wechsler individual achievement test':ti OR
  'wiat-4':ti OR 'wechsler intelligence scale':ti OR OR 'wechsler memory
  scale':ti OR 'wms-4':ti OR 'wide range achievement test':ti OR
  'wrat-5':ti OR 'adult adhd rating scale':ti OR 'adhd-rs':ti OR 'brown
  add scales':ti OR 'continuous performance tests':ti OR 'conners
  cpt':ti OR 'qb test':ti OR 'tova':ti OR 'wender utah adult adhd
  scale':ti OR 'diagnostic interview for adult adhd':ti</p>
      <p>AND</p>
      <p>"Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder")</p>
      <p>OR</p>
      <p>(#1 'attention deficit disorder with hyperactivity':ab,ti OR
  'attention deficit hyperactivity disorder':ab,ti OR 'adhd':ab,ti OR
  'attention deficit disorder':ab,ti 61194</p>
      <p>#2 ((adult:ab,ti OR aged:ab,ti OR middle:ab,ti) AND aged:ab,ti OR
  young:ab,ti) AND adult:ab,ti OR adult:ab,ti OR adults:ab,ti
  2231374</p>
      <p>#3 ((('attention deficit and disruptive behavior
  disorders/diagnosis':ab,ti OR mass:ab,ti) AND screening:ab,ti OR
  questionnaires:ab,ti OR interviews:ab,ti) AND as:ab,ti AND topic:ab,ti
  OR psychometrics:ab,ti OR psychiatric:ab,ti) AND status:ab,ti AND
  rating:ab,ti AND scales:ab,ti OR 'diagnostic techniques and
  procedures':ab,ti OR 'referral and consultation':ab,ti OR
  questionnaire:ab,ti OR questionnaires:ab,ti OR screening:ab,ti OR
  screen:ab,ti OR scale:ab,ti OR instrument:ab,ti OR instruments:ab,ti
  OR interview:ab,ti OR interviews:ab,ti OR diagnosis:ab,ti OR
  diagnostic:ab,ti OR diagnosed:ab,ti OR measure:ab,ti OR test:ab,ti OR
  tests:ab,ti OR testing:ab,ti OR 'attention deficit disorder with
  hyperactivity/diagnostic imaging':ab,ti 11386521</p>
      <p>#4 'sensitivity and specificity':ab,ti OR 'diagnostic errors':ab,ti
  OR sensitivity:ab,ti OR specificity:ab,ti OR (accura*:ab,ti AND
  (diagnos*:ab,ti OR classif*:ab,ti)) OR 'roc curve':ab,ti OR 'positive
  predictive value':ab,ti OR 'negative predictive value':ab,ti OR 'false
  positive':ab,ti OR 'false negative':ab,ti OR 'likelihood ratio':ab,ti
  2280552</p>
      <p>#5 #1 AND #2 AND #3 AND #4 814</p>
      <p>#6 #5 AND [humans]/lim 787</p>
      <p>#7 #6 AND ([article]/lim OR [article in press]/lim) 509)</p>
      <p>
        <bold>APA PsycINFO</bold>
      </p>
      <p>(((title: ("Adaptive Behavior Assessment System") OR
  title: ("ABAS-3") OR title: ("Advanced Clinical
  Solutions") OR title: ("Word Choice Test") OR title:
  ("Test of Premorbid Functioning") OR title: ("Social
  Cognition") OR title: ("Beck Anxiety Inventory") OR
  title: ("BAI") OR title: ("Beck Depression
  Inventory") OR title: ("BDI-2") OR title:
  ("Behavioral Assessment System for Children") OR title:
  ("Self-Report of Personality") OR title: ("BASC-3 SRP
  Adolescent") OR title: ("Behavioral Assessment System for
  Children") OR title: ("Parent Rating Scales") OR title:
  ("BASC-3 PRS Adolescent") OR title: ("BASC-3 SRP
  College") OR title: ("Teacher Rating Scales") OR title:
  ("BASC-3 TRS Adolescent") OR title: ("Brown Executive
  Function/Attention Scales") OR title: ("Brown EF/A
  Self") OR title: ("California Verbal Learning Test") OR
  title: ("CVLT-3") OR title: ("Standard Form California
  Verbal" "CVLT-3 Brief") OR title: ("California
  Verbal Learning Test") OR title: ("CVLT-C") OR title:
  ("Childhood Autism Rating Scale") OR title:
  ("CARS-2") OR title: ("Childhood Autism Rating
  Scale") OR title: ("High-Functioning Version") OR
  title: ("CARS-2 HF") OR title: ("Clinical Evaluation of
  Language Fundamentals") OR title: ("CELF-5") OR title:
  ("Comprehensive Executive Function Inventory") OR title:
  ("CEFI Adult Observer") OR title: ("Comprehensive
  Executive Function Inventory") OR title: ("CEFI Adult
  Self-Report") OR title: ("Conners' Adult ADHD Diagnostic
  Interview for DSM-IV") OR title: ("CAADID Part 1") OR
  title: ("CAADID Part 2") OR title: ("CAARS–O:L")
  OR title: ("CAARS–S:L") OR title: ("CAARS-2
  Observer") OR title: ("Conners' Adult ADHD Rating
  Scales") OR title: ("CAARS-2 Self-Report") OR title:
  ("Delis-Kaplan Executive Function System") OR title:
  ("D-KEFS") OR title: ("Dot Counting Test") OR
  title: ("Grooved Pegboard Test Kaufman Test of Educational
  Achievement") OR title: ("KTEA-3") OR title:
  ("NEPSY-II Developmental Neuropsychological Battery") OR
  title: ("Neuropsychological Assessment Battery") OR title:
  ("Attention, Language, Memory, Spatial, and Ex- ecutive Functions
  Modules") OR title: ("NIH Executive Abilities–Measures and
  Instruments for Neurobehavioral Evaluation and Re-search") OR
  title: ("NIH EXAMINER") OR title: ("Personality
  Assessment Inventory") OR title: ("PROMIS Sleep Assessments
  Pediatric Parent Proxy") OR title: ("Repeatable Battery for
  the Assessment of Neuropsychological Status") OR title:
  ("RBANS") OR title: ("Rey-Osterrieth Complex") OR
  title: ("Wechsler Abbreviated Scale of Intelligence") OR
  title: ("WASI-2") OR title: ("Wechsler Adult
  Intelligence Scale") OR title: ("WAIS-4") OR title:
  ("WAIS-IV") OR title: ("Wechsler Individual Achievement
  Test") OR title: ("WIAT-4") OR title: ("Wechsler
  Intelligence Scale ") OR title: ("Wechsler Memory
  Scale") OR title: ("WMS-4") OR title: ("Wide Range
  Achievement Test") OR title: ("WRAT-5") OR title:
  ("Adult ADHD Rating Scale") OR title: ("ADHD-RS")
  OR title: ("Brown ADD scales") OR title: ("Continuous
  Performance Tests") OR title: ("Conners CPT") OR title:
  ("QB Test") OR title: ("TOVA") OR title:
  ("Wender Utah Adult ADHD Scale") OR title: ("diagnostic
  interview for Adult ADHD")))</p>
      <p>AND</p>
      <p>((title: ("Attention Deficit Disorder with
  Hyperactivity") OR title: ("attention deficit hyperactivity
  disorder") OR title: ("ADHD") OR title:
  ("attention deficit disorder")) OR (abstract:
  ("Attention Deficit Disorder with Hyperactivity") OR
  abstract: ("attention deficit hyperactivity disorder") OR
  abstract: ("ADHD") OR abstract: ("attention deficit
  disorder"))))</p>
      <p>OR</p>
      <p>(((title: ("Attention Deficit Disorder with
  Hyperactivity") OR title: ("attention deficit hyperactivity
  disorder") OR title: ("ADHD") OR title:
  ("attention deficit disorder")) OR (abstract:
  ("Attention Deficit Disorder with Hyperactivity") OR
  abstract: ("attention deficit hyperactivity disorder") OR
  abstract: ("ADHD") OR abstract: ("attention deficit
  disorder"))) AND ((title: (Adult) OR title: (Aged) OR title:
  (Middle Aged) OR title: (Young Adult) OR title: (Adult) OR title:
  (Adults)) OR (abstract: (Adult) OR abstract: (Aged) OR abstract:
  (Middle Aged) OR abstract: (Young Adult) OR abstract: (Adult) OR
  abstract: (Adults))) AND ((title: ("Attention Deficit and
  Disruptive Behavior Disorders/diagnosis") OR title: (mass
  screening) OR title: (questionnaires) OR title: (Interviews as Topic)
  OR title: (Psychometrics) OR title: (Psychiatric Status Rating Scales)
  OR title: (diagnosis) OR title: ("Diagnostic Techniques and
  Procedures") OR title: ("Referral and Consultation") OR
  title: (questionnaire) OR title: (questionnaires) OR title:
  (screening) OR title: (screen) OR title: (scale) OR title:
  (instrument) OR title: (instruments) OR title: (interview) OR title:
  (interviews) OR title: (diagnosis) OR title: (diagnostic) OR title:
  (diagnosed) OR title: (Measure) OR title: (test) OR title: (tests) OR
  title: (testing) OR title: ("Attention Deficit Disorder with
  Hyperactivity/diagnostic imaging")) OR (abstract:
  ("Attention Deficit and Disruptive Behavior
  Disorders/diagnosis") OR abstract: (mass screening) OR abstract:
  (questionnaires) OR abstract: (Interviews as Topic) OR abstract:
  (Psychometrics) OR abstract: (Psychiatric Status Rating Scales) OR
  abstract: (diagnosis) OR abstract: ("Diagnostic Techniques and
  Procedures") OR abstract: ("Referral and Consultation")
  OR abstract: (questionnaire) OR abstract: (questionnaires) OR
  abstract: (screening) OR abstract: (screen) OR abstract: (scale) OR
  abstract: (instrument) OR abstract: (instruments) OR abstract:
  (interview) OR abstract: (interviews) OR abstract: (diagnosis) OR
  abstract: (diagnostic) OR abstract: (diagnosed) OR abstract: (Measure)
  OR abstract: (test) OR abstract: (tests) OR abstract: (testing) OR
  abstract: ("Attention Deficit Disorder with
  Hyperactivity/diagnostic imaging"))) AND ((title:
  ("Sensitivity and Specificity") OR title: ("Diagnostic
  Errors") OR title: (sensitivity) OR title: (specificity) OR
  (title: (accura*) AND (title: (diagnos*) OR title: (classif*))) OR
  title: ("ROC curve") OR title: ("positive predictive
  value") OR title: ("negative predictive value") OR
  title: ("false positive") OR title: ("false
  negative") OR title: ("likelihood ratio")) OR
  (abstract: ("Sensitivity and Specificity") OR abstract:
  ("Diagnostic Errors") OR abstract: (sensitivity) OR
  abstract: (specificity) OR (abstract: (accura*) AND (abstract:
  (diagnos*) OR abstract: (classif*))) OR abstract: ("ROC
  curve") OR abstract: ("positive predictive value") OR
  abstract: ("negative predictive value") OR abstract:
  ("false positive") OR abstract: ("false negative")
  OR abstract: ("likelihood ratio"))) AND Population Group:
  Human AND Publication Type: Peer Reviewed Journal)</p>
      <p><bold>Cochrane Database of Systematic Reviews</bold> (CDSR)</p>
      <p>(#1 ("Adaptive Behavior Assessment System" OR
  "ABAS-3" OR "Advanced Clinical Solutions" OR
  "Word Choice Test" OR "Test of Premorbid
  Functioning" OR "Social Cognition" OR "Beck
  Anxiety Inventory" OR "BAI" OR "Beck Depression
  Inventory" OR "BDI-2" OR "Behavioral Assessment
  System for Children" OR "Self-Report of Personality" OR
  "BASC-3 SRP Adolescent" OR "Behavioral Assessment
  System for Children" OR "Parent Rating Scales" OR
  "BASC-3 PRS Adolescent" OR "BASC-3 SRP College" OR
  "Teacher Rating Scales" OR "BASC-3 TRS Adolescent"
  OR "Brown Executive Function/Attention Scales" OR
  "Brown EF/A Self" OR "California Verbal Learning
  Test" OR "CVLT-3" OR "Standard Form California
  Verbal" "CVLT-3 Brief" OR "California Verbal
  Learning Test" OR "CVLT-C" OR "Childhood Autism
  Rating Scale" OR "CARS-2" OR "Childhood Autism
  Rating Scale" OR "High-Functioning Version" OR
  "CARS-2 HF" OR "Clinical Evaluation of Language
  Fundamentals" OR "CELF-5" OR "Comprehensive
  Executive Function Inventory" OR "CEFI Adult Observer"
  OR "Comprehensive Executive Function Inventory" OR
  "CEFI Adult Self-Report" OR "Conners’ Adult ADHD
  Diagnostic Interview for DSM-IV" OR "CAADID Part 1" OR
  "CAADID Part 2" OR "CAARS–O:L" OR
  "CAARS–S:L" OR "CAARS-2 Observer" OR
  "Conners’ Adult ADHD Rating Scales" OR "CAARS-2
  Self-Report" OR "Delis-Kaplan Executive Function
  System" OR "D-KEFS" OR "Dot Counting Test" OR
  "Grooved Pegboard Test Kaufman Test of Educational
  Achievement" OR "KTEA-3" OR "NEPSY-II
  Developmental Neuropsychological Battery" OR
  "Neuropsychological Assessment Battery" OR "Attention,
  Language, Memory, Spatial, and Ex- ecutive Functions Modules" OR
  "NIH Executive Abilities–Measures and Instruments for
  Neurobehavioral Evaluation and Re-search" OR "NIH
  EXAMINER" OR "Personality Assessment Inventory" OR
  "PROMIS Sleep Assessments Pediatric Parent Proxy" OR
  "Repeatable Battery for the Assessment of Neuropsychological
  Status" OR "RBANS" OR "Rey-Osterrieth
  Complex" OR "Wechsler Abbreviated Scale of
  Intelligence" OR "WASI-2" OR "Wechsler Adult
  Intelligence Scale" OR "WAIS-4" OR "WAIS-IV"
  OR "Wechsler Individual Achievement Test" OR
  "WIAT-4" OR "Wechsler Intelligence Scale" OR
  "Wechsler Memory Scale" OR "WMS-4" OR "Wide
  Range Achievement Test" OR "WRAT-5" OR "Adult ADHD
  Rating Scale" OR "ADHD-RS" OR "Brown ADD
  scales" OR "Continuous Performance Tests" OR
  "Conners CPT" OR "QB Test" OR "TOVA" OR
  "Wender Utah Adult ADHD Scale" OR "diagnostic interview
  for Adult ADHD"):ti,ab,kw (Word variations have been
  searched)</p>
      <p>#2 ("Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder"):ti,ab,kw
  (Word variations have been searched)</p>
      <p>#3 #1 AND #2 )</p>
      <p>OR</p>
      <p>(#1</p>
      <p>MeSH descriptor: [Attention Deficit Disorder with Hyperactivity]
  explode all trees</p>
      <p>#2</p>
      <p>("attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit
  disorder"):ti,ab,kw</p>
      <p>(Word variations have been searched)</p>
      <p>#3</p>
      <p>#1 OR #2</p>
      <p>#4</p>
      <p>MeSH descriptor: [Adult] explode all trees</p>
      <p>#5</p>
      <p>MeSH descriptor: [Aged] in all MeSH products</p>
      <p>#6</p>
      <p>MeSH descriptor: [Middle Aged] explode all trees</p>
      <p>#7</p>
      <p>(Young Adult OR Adult OR Adults):ti,ab,kw</p>
      <p>(Word variations have been searched)</p>
      <p>#8</p>
      <p>#4 OR #5 OR #6 OR #7</p>
      <p>#9</p>
      <p>MeSH descriptor: [Mass Screening] explode all trees</p>
      <p>#10</p>
      <p>MeSH descriptor:[Surveys and Questionnaires] explode all trees</p>
      <p>#11</p>
      <p>MeSH descriptor: [Interviews as Topic] explode all trees</p>
      <p>#12</p>
      <p>MeSH descriptor: [Psychometrics] explode all trees</p>
      <p>#13</p>
      <p>MeSH descriptor: [Psychiatric Status Rating Scales] explode all
  trees</p>
      <p>#14</p>
      <p>MeSH descriptor: [Diagnosis] this term only</p>
      <p>#15</p>
      <p>MeSH descriptor: [Diagnostic Techniques and Procedures] explode all
  trees</p>
      <p>#16</p>
      <p>MeSH descriptor: [Referral and Consultation] explode all trees</p>
      <p>#17</p>
      <p>("Attention Deficit and Disruptive Behavior Disorders"
  AND diagnosis):ti,ab,kw</p>
      <p>(Word variations have been searched)</p>
      <p>#18</p>
      <p>("Attention Deficit and Disruptive Behavior Disorders"
  AND "diagnostic imaging"):ti,ab,kw</p>
      <p>(Word variations have been searched)</p>
      <p>#19</p>
      <p>(questionnaire OR questionnaires OR screening OR screen OR scale OR
  instrument OR instruments OR interview OR interviews OR diagnosis OR
  diagnostic OR diagnosed OR Measure OR test OR tests OR
  testing):ti,ab,kw</p>
      <p>#20</p>
      <p>#9 OR #10 OR #11 OR #12 OR #13 OR #14 OR #15 OR #16 OR #17 OR #18
  OR #19</p>
      <p>#21</p>
      <p>("Sensitivity and Specificity" OR "Diagnostic
  Errors" OR sensitivity OR specificity OR (accura* AND (diagnos*
  OR classif*)) OR "ROC curve" OR "positive predictive
  value" OR "negative predictive value" OR "false
  positive" OR "false negative" OR "likelihood
  ratio"):ti,ab,kw</p>
      <p>#22</p>
      <p>#3 AND #8 AND #20 AND #21)</p>
      <p>
        <bold>Campbell Collaboration</bold>
      </p>
      <p>("Adaptive Behavior Assessment System" OR
  "ABAS-3" OR "Advanced Clinical Solutions" OR
  "Word Choice Test" OR "Test of Premorbid
  Functioning" OR "Social Cognition" OR "Beck
  Anxiety Inventory" OR "BAI" OR "Beck Depression
  Inventory" OR "BDI-2" OR "Behavioral Assessment
  System for Children" OR "Self-Report of Personality" OR
  "BASC-3 SRP Adolescent" OR "Behavioral Assessment
  System for Children" OR "Parent Rating Scales" OR
  "BASC-3 PRS Adolescent" OR "BASC-3 SRP College" OR
  "Teacher Rating Scales" OR "BASC-3 TRS Adolescent"
  OR "Brown Executive Function/Attention Scales" OR
  "Brown EF/A Self" OR "California Verbal Learning
  Test" OR "CVLT-3" OR "Standard Form California
  Verbal" "CVLT-3 Brief" OR "California Verbal
  Learning Test" OR "CVLT-C" OR "Childhood Autism
  Rating Scale" OR "CARS-2" OR "Childhood Autism
  Rating Scale" OR</p>
      <p>"High-Functioning Version" OR "CARS-2 HF" OR
  "Clinical Evaluation of Language Fundamentals" OR
  "CELF-5" OR "Comprehensive Executive Function
  Inventory" OR "CEFI Adult Observer" OR
  "Comprehensive Executive Function Inventory" OR "CEFI
  Adult Self-Report" OR "Conners’ Adult ADHD Diagnostic
  Interview for DSM-IV" OR "CAADID Part 1" OR
  "CAADID Part 2" OR "CAARS–O:L" OR
  "CAARS–S:L" OR "CAARS-2 Observer" OR
  "Conners’ Adult ADHD Rating Scales" OR "CAARS-2
  Self-Report" OR "Delis-Kaplan Executive Function
  System" OR "D-KEFS" OR "Dot Counting Test" OR
  "Grooved Pegboard Test Kaufman Test of Educational
  Achievement" OR "KTEA-3" OR "NEPSY-II
  Developmental Neuropsychological Battery" OR
  "Neuropsychological Assessment Battery" OR "Attention,
  Language, Memory, Spatial, and Executive Functions Modules" OR
  "NIH Executive Abilities–Measures and Instruments for
  Neurobehavioral Evaluation and Re-search" OR "NIH
  EXAMINER" OR "Personality Assessment Inventory" OR
  "PROMIS Sleep Assessments Pediatric Parent Proxy" OR
  "Repeatable Battery for the Assessment of Neuropsychological
  Status" OR "RBANS" OR "Rey-Osterrieth
  Complex" OR "Wechsler Abbreviated Scale of
  Intelligence" OR "WASI-2" OR "Wechsler Adult
  Intelligence Scale" OR "WAIS-4" OR "WAIS-IV"
  OR "Wechsler Individual Achievement Test" OR
  "WIAT-4" OR "Wechsler Intelligence Scale" OR
  "Wechsler Memory Scale" OR "WMS-4" OR "Wide
  Range Achievement Test" OR "WRAT-5" OR "Adult ADHD
  Rating Scale" OR "ADHD-RS" OR "Brown ADD
  scales" OR "Continuous Performance Tests" OR
  "Conners CPT" OR "QB Test" OR "TOVA" OR
  "Wender Utah Adult ADHD Scale" OR "diagnostic interview
  for Adult ADHD")</p>
      <p>OR</p>
      <p>("Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder")</p>
      <p><bold>PROSPERO</bold> (https://www.crd.york.ac.uk/prospero/)</p>
      <p>(#1 ("Adaptive Behavior Assessment System" OR
  "ABAS-3" OR "Advanced Clinical Solutions" OR
  "Word Choice Test" OR "Test of Premorbid
  Functioning" OR "Social Cognition" OR "Beck
  Anxiety Inventory" OR "BAI" OR "Beck Depression
  Inventory" OR "BDI-2" OR "Behavioral Assessment
  System for Children" OR "Self-Report of Personality" OR
  "BASC-3 SRP Adolescent" OR "Behavioral Assessment
  System for Children" OR "Parent Rating Scales" OR
  "BASC-3 PRS Adolescent" OR "BASC-3 SRP College" OR
  "Teacher Rating Scales" OR "BASC-3 TRS Adolescent"
  OR "Brown Executive Function/Attention Scales" OR
  "Brown EF/A Self" OR "California Verbal Learning
  Test" OR "CVLT-3" OR "Standard Form California
  Verbal" "CVLT-3 Brief" OR "California Verbal
  Learning Test" OR "CVLT-C" OR "Childhood Autism
  Rating Scale" OR "CARS-2" OR "Childhood Autism
  Rating Scale" OR "High-Functioning Version" OR
  "CARS-2 HF" OR "Clinical Evaluation of Language
  Fundamentals" OR "CELF-5" OR "Comprehensive
  Executive Function Inventory" OR "CEFI Adult
  Observer"):TI</p>
      <p>#2 ("Comprehensive Executive Function Inventory" OR
  "CEFI Adult Self-Report" OR "Conners Adult ADHD
  Diagnostic Interview for DSM-IV" OR "CAADID Part 1" OR
  "CAADID Part 2" OR "CAARS?OL" OR
  "CAARS?SL" OR "CAARS-2 Observer" OR "Conners
  Adult ADHD Rating Scales" OR "CAARS-2 Self-Report" OR
  "Delis-Kaplan Executive Function System" OR
  "D-KEFS" OR "Dot Counting Test" OR "Grooved
  Pegboard Test Kaufman Test of Educational Achievement" OR
  "KTEA-3" OR "NEPSY-II Developmental Neuropsychological
  Battery" OR "Neuropsychological Assessment Battery" OR
  "Attention, Language, Memory, Spatial, and Ex- ecutive Functions
  Modules" OR "NIH Executive Abilities?Measures and
  Instruments for Neurobehavioral Evaluation and Re-search"):TI</p>
      <p>#3 ("NIH EXAMINER" OR "Personality Assessment
  Inventory" OR "PROMIS Sleep Assessments Pediatric Parent
  Proxy" OR "Repeatable Battery for the Assessment of
  Neuropsychological Status" OR "RBANS" OR
  "Rey-Osterrieth Complex" OR "Wechsler Abbreviated Scale
  of Intelligence" OR "WASI-2" OR "Wechsler Adult
  Intelligence Scale" OR "WAIS-4" OR "WAIS-IV"
  OR "Wechsler Individual Achievement Test" OR
  "WIAT-4" OR "Wechsler Intelligence Scale" OR
  "Wechsler Memory Scale" OR "WMS-4" OR "Wide
  Range Achievement Test" OR "WRAT-5" OR "Adult ADHD
  Rating Scale" OR "ADHD-RS" OR "Brown ADD
  scales" OR "Continuous Performance Tests" OR
  "Conners CPT" OR "QB Test" OR "TOVA" OR
  "Wender Utah Adult ADHD Scale" OR "diagnostic interview
  for Adult ADHD"):TI</p>
      <p>#4 #3 OR #2 OR #1</p>
      <p>#5 (MeSH DESCRIPTOR Attention Deficit Disorder with Hyperactivity
  EXPLODE ALL TREES):TI</p>
      <p>#6 MeSH DESCRIPTOR Attention Deficit Disorder with Hyperactivity
  EXPLODE ALL TREES</p>
      <p>#7 ("Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder"):TI</p>
      <p>#8 #7 OR #6</p>
      <p>#9 #8 AND #4)</p>
      <p>OR</p>
      <p>#1 MeSH DESCRIPTOR Attention Deficit Disorder with Hyperactivity
  EXPLODE ALL TREES</p>
      <p>#2 "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder"</p>
      <p>#3 #2 OR #1</p>
      <p>#4 MeSH DESCRIPTOR Aged, 80 and over EXPLODE ALL TREES</p>
      <p>#5 MeSH DESCRIPTOR Adult EXPLODE ALL TREES</p>
      <p>#6 MeSH DESCRIPTOR Middle Aged EXPLODE ALL TREES</p>
      <p>#7 Young Adult OR Adult OR Adults</p>
      <p>#8 #4 OR #5 OR #6 OR #7</p>
      <p>#9 MeSH DESCRIPTOR Mass Screening EXPLODE ALL TREES</p>
      <p>#10 "interviews as topics"</p>
      <p>#11 psychometrics</p>
      <p>#12 MeSH DESCRIPTOR Psychiatric Status Rating Scales EXPLODE ALL
  TREES</p>
      <p>#13 MeSH DESCRIPTOR Diagnosis EXPLODE ALL TREES</p>
      <p>#14 MeSH DESCRIPTOR diagnosis EXPLODE ALL TREES</p>
      <p>#15 MeSH DESCRIPTOR diagnosis</p>
      <p>#16 MeSH DESCRIPTOR Diagnostic Techniques and Procedures EXPLODE
  ALL TREES</p>
      <p>#17 MeSH DESCRIPTOR Referral and Consultation EXPLODE ALL TREES</p>
      <p>#18 attention deficit and disruptive behavior disorders</p>
      <p>#19 "attention deficit and disruptive behavior disorders"
  AND diagnosis</p>
      <p>#20 "attention deficit and disruptive behavior disorders"
  AND "diagnostic imaging"</p>
      <p>#21 questionnaire OR questionnaires OR screening OR screen OR scale
  OR instrument OR instruments OR interview OR interviews OR diagnosis
  OR diagnostic OR diagnosed OR Measure OR test OR tests OR testing</p>
      <p>#22 #9 OR #10 OR #11 OR #12 OR #15 OR #16 OR #17 OR #19 OR #20 OR
  #21</p>
      <p>#23 "Sensitivity and Specificity" OR "Diagnostic
  Errors" OR sensitivity OR specificity OR (accura* AND (diagnos*
  OR classif*)) OR "ROC curve" OR "positive predictive
  value" OR "negative predictive value" OR "false
  positive" OR "false negative" OR "likelihood
  ratio"</p>
      <p>#24 #3 AND #8 AND #22 AND #23</p>
      <p><bold>ECRI Guidelines Trust</bold> https://guidelines.ecri.org/</p>
      <p>('"Adaptive Behavior Assessment System" OR
  "ABAS-3" OR "Advanced Clinical Solutions" OR
  "Word Choice Test" OR "Test of Premorbid
  Functioning" OR "Social Cognition" OR "Beck
  Anxiety Inventory" OR "BAI" OR "Beck Depression
  Inventory" OR "BDI-2" OR "Behavioral Assessment
  System for Children" OR "Self-Report of Personality" OR
  "BASC-3 SRP Adolescent" OR "Behavioral Assessment
  System for Children" OR "Parent Rating Scales" OR
  "BASC-3 PRS Adolescent" OR "BASC-3 SRP College" OR
  "Teacher Rating Scales" OR "BASC-3 TRS Adolescent"
  OR "Brown Executive Function/Attention Scales" OR
  "Brown EF/A Self" OR "California Verbal Learning
  Test" OR "CVLT-3" OR "Standard Form California
  Verbal" "CVLT-3 Brief" OR "California Verbal
  Learning Test" OR "CVLT-C" OR "Childhood Autism
  Rating Scale" OR "CARS-2" OR "Childhood Autism
  Rating Scale" OR "High-Functioning Version" OR
  "CARS-2 HF" OR "Clinical Evaluation of Language
  Fundamentals" OR "CELF-5" OR "Comprehensive
  Executive Function Inventory" OR "CEFI Adult Observer"
  OR "Comprehensive Executive Function Inventory" OR
  "CEFI Adult Self-Report" OR "Conners’ Adult ADHD
  Diagnostic Interview for DSM-IV" OR "CAADID Part 1" OR
  "CAADID Part 2" OR "CAARS–O:L" OR
  "CAARS–S:L" OR "CAARS-2 Observer" OR
  "Conners’ Adult ADHD Rating Scales" OR "CAARS-2
  Self-Report" OR "Delis-Kaplan Executive Function
  System" OR "D-KEFS" OR "Dot Counting Test" OR
  "Grooved Pegboard Test Kaufman Test of Educational
  Achievement" OR "KTEA-3" OR "NEPSY-II
  Developmental Neuropsychological Battery" OR
  "Neuropsychological Assessment Battery" OR "Attention,
  Language, Memory, Spatial, and Executive Functions Modules" OR
  "NIH Executive Abilities–Measures and Instruments for
  Neurobehavioral Evaluation and Re-search" OR "NIH
  EXAMINER" OR "Personality Assessment Inventory" OR
  "PROMIS Sleep Assessments Pediatric Parent Proxy" OR
  "Repeatable Battery for the Assessment of Neuropsychological
  Status" OR "RBANS" OR "Rey-Osterrieth
  Complex" OR "Wechsler Abbreviated Scale of
  Intelligence" OR "WASI-2" OR "Wechsler Adult
  Intelligence Scale" OR "WAIS-4" OR "WAIS-IV"
  OR "Wechsler Individual Achievement Test" OR
  "WIAT-4" OR "Wechsler Intelligence Scale" OR
  "Wechsler Memory Scale" OR "WMS-4" OR "Wide
  Range Achievement Test" OR "WRAT-5" OR "Adult ADHD
  Rating Scale" OR "ADHD-RS" OR "Brown ADD
  scales" OR "Continuous Performance Tests" OR
  "Conners CPT" OR "QB Test" OR "TOVA" OR
  "Wender Utah Adult ADHD Scale" OR "diagnostic interview
  for Adult ADHD"')</p>
      <p>OR</p>
      <p>("Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder"</p>
      <p>FILTER: Patient Age</p>
      <p>Adolescent (13 to 18 years), Adult (19 to 44 years), Middle Age(45
  to 64 years), Aged(65 to 79 years), Aged (80 and over)</p>
      <p><bold>Guidelines International Network Library</bold> (G-I-N,
  https://guidelines.ebmportal.com/)</p>
      <p>("Adaptive Behavior Assessment System" OR
  "ABAS-3" OR "Advanced Clinical Solutions" OR
  "Word Choice Test" OR "Test of Premorbid
  Functioning" OR "Social Cognition" OR "Beck
  Anxiety Inventory" OR "BAI" OR "Beck Depression
  Inventory" OR "BDI-2" OR "Behavioral Assessment
  System for Children" OR "Self-Report of Personality" OR
  "BASC-3 SRP Adolescent" OR "Behavioral Assessment
  System for Children" OR "Parent Rating Scales" OR
  "BASC-3 PRS Adolescent" OR "BASC-3 SRP College" OR
  "Teacher Rating Scales" OR "BASC-3 TRS Adolescent"
  OR "Brown Executive Function/Attention Scales" OR
  "Brown EF/A Self" OR "California Verbal Learning
  Test" OR "CVLT-3" OR "Standard Form California
  Verbal" "CVLT-3 Brief" OR "California Verbal
  Learning Test" OR "CVLT-C" OR "Childhood Autism
  Rating Scale" OR "CARS-2" OR "Childhood Autism
  Rating Scale" OR "High-Functioning Version" OR
  "CARS-2 HF" OR "Clinical Evaluation of Language
  Fundamentals" OR "CELF-5" OR "Comprehensive
  Executive Function Inventory" OR "CEFI Adult Observer"
  OR "Comprehensive Executive Function Inventory" OR
  "CEFI Adult Self-Report" OR "Conners’ Adult ADHD
  Diagnostic Interview for DSM-IV" OR "CAADID Part 1" OR
  "CAADID Part 2" OR "CAARS–O:L" OR
  "CAARS–S:L" OR "CAARS-2 Observer" OR
  "Conners’ Adult ADHD Rating Scales" OR "CAARS-2
  Self-Report" OR "Delis-Kaplan Executive Function
  System" OR "D-KEFS" OR "Dot Counting Test" OR
  "Grooved Pegboard Test Kaufman Test of Educational
  Achievement" OR "KTEA-3" OR "NEPSY-II
  Developmental Neuropsychological Battery" OR
  "Neuropsychological Assessment Battery" OR "Attention,
  Language, Memory, Spatial, and Ex- ecutive Functions Modules" OR
  "NIH Executive Abilities–Measures and Instruments for
  Neurobehavioral Evaluation and Re-search" OR "NIH
  EXAMINER" OR "Personality Assessment Inventory" OR
  "PROMIS Sleep Assessments Pediatric Parent Proxy" OR
  "Repeatable Battery for the Assessment of Neuropsychological
  Status" OR "RBANS" OR "Rey-Osterrieth
  Complex" OR "Wechsler Abbreviated Scale of
  Intelligence" OR "WASI-2" OR "Wechsler Adult
  Intelligence Scale" OR "WAIS-4" OR "WAIS-IV"
  OR "Wechsler Individual Achievement Test" OR
  "WIAT-4" OR "Wechsler Intelligence Scale" OR
  "Wechsler Memory Scale" OR "WMS-4" OR "Wide
  Range Achievement Test" OR "WRAT-5" OR "Adult ADHD
  Rating Scale" OR "ADHD-RS" OR "Brown ADD
  scales" OR "Continuous Performance Tests" OR
  "Conners CPT" OR "QB Test" OR "TOVA" OR
  "Wender Utah Adult ADHD Scale" OR "diagnostic interview
  for Adult ADHD")</p>
      <p>OR</p>
      <p>("Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder")</p>
      <p>
        <bold>ClinicalKey</bold>
      </p>
      <p>("Adaptive Behavior Assessment System" OR
  "ABAS-3" OR "Advanced Clinical Solutions" OR
  "Word Choice Test" OR "Test of Premorbid
  Functioning" OR "Social Cognition" OR "Beck
  Anxiety Inventory" OR "BAI" OR "Beck Depression
  Inventory" OR "BDI-2" OR "Behavioral Assessment
  System for Children" OR "Self-Report of Personality" OR
  "BASC-3 SRP Adolescent" OR "Behavioral Assessment
  System for Children" OR "Parent Rating Scales" OR
  "BASC-3 PRS Adolescent" OR "BASC-3 SRP College" OR
  "Teacher Rating Scales" OR "BASC-3 TRS Adolescent"
  OR "Brown Executive Function/Attention Scales" OR
  "Brown EF/A Self" OR "California Verbal Learning
  Test" OR "CVLT-3" OR "Standard Form California
  Verbal" "CVLT-3 Brief" OR "California Verbal
  Learning Test" OR "CVLT-C" OR "Childhood Autism
  Rating Scale" OR "CARS-2" OR "Childhood Autism
  Rating Scale" OR "High-Functioning Version" OR
  "CARS-2 HF" OR "Clinical Evaluation of Language
  Fundamentals" OR "CELF-5" OR "Comprehensive
  Executive Function Inventory" OR "CEFI Adult Observer"
  OR "Comprehensive Executive Function Inventory" OR
  "CEFI Adult Self-Report" OR "Conners’ Adult ADHD
  Diagnostic Interview for DSM-IV" OR "CAADID Part 1" OR
  "CAADID Part 2" OR "CAARS–O:L" OR
  "CAARS–S:L" OR "CAARS-2 Observer" OR
  "Conners’ Adult ADHD Rating Scales" OR "CAARS-2
  Self-Report" OR "Delis-Kaplan Executive Function
  System" OR "D-KEFS" OR "Dot Counting Test" OR
  "Grooved Pegboard Test Kaufman Test of Educational
  Achievement" OR "KTEA-3" OR "NEPSY-II
  Developmental Neuropsychological Battery" OR
  "Neuropsychological Assessment Battery" OR "Attention,
  Language, Memory, Spatial, and Executive Functions Modules" OR
  "NIH Executive Abilities–Measures and Instruments for
  Neurobehavioral Evaluation and Re-search" OR "NIH
  EXAMINER" OR "Personality Assessment Inventory" OR
  "PROMIS Sleep Assessments Pediatric Parent Proxy" OR
  "Repeatable Battery for the Assessment of Neuropsychological
  Status" OR "RBANS" OR "Rey-Osterrieth
  Complex" OR "Wechsler Abbreviated Scale of
  Intelligence" OR "WASI-2" OR "Wechsler Adult
  Intelligence Scale" OR "WAIS-4" OR "WAIS-IV"
  OR "Wechsler Individual Achievement Test" OR
  "WIAT-4" OR "Wechsler Intelligence Scale" OR
  "Wechsler Memory Scale" OR "WMS-4" OR "Wide
  Range Achievement Test" OR "WRAT-5" OR "Adult ADHD
  Rating Scale" OR "ADHD-RS" OR "Brown ADD
  scales" OR "Continuous Performance Tests" OR
  "Conners CPT" OR "QB Test" OR "TOVA" OR
  "Wender Utah Adult ADHD Scale" OR "diagnostic interview
  for Adult ADHD")</p>
      <p>OR</p>
      <p>("Attention Deficit Disorder with Hyperactivity" OR
  "attention deficit hyperactivity disorder" OR
  "ADHD" OR "attention deficit disorder"</p>
      <p>FILTERS: Journal Articles, Guidelines)</p>
      <p>Appendix B. List of Included, Background, and Excluded
  Publications</p>
      <p>This appendix shows the list of included, background studies, and
  excluded studies with reasons for exclusion. Background papers
  provided more information on the topic or were retained for
  reference-mining. We recorded only one reason for exclusion per
  publications.</p>
      <p>Included Publications</p>
      <p>1. Abramson DA, White DJ, Rhoads T, et al. Cross-validating the Dot
  Counting Test Among an Adult ADHD Clinical Sample and Analyzing the
  Effect of ADHD Subtype and Comorbid Psychopathology. Assessment. 2023
  Mar;30(2):264-73. doi: 10.1177/10731911211050895. PMID: 34643101.</p>
      <p>2. Adamou M, Jones SL, Marks L, et al. Efficacy of Continuous
  Performance Testing in Adult ADHD in a Clinical Sample Using QbTest. J
  Atten Disord. 2022 Sep;26(11):1483-91. doi: 10.1177/10870547221079798.
  PMID: 35255743.</p>
      <p>3. Aita SL, Sofko CA, Hill BD, et al. Utility of the Personality
  Assessment Inventory in detecting feigned
  Attention-Deficit/Hyperactivity Disorder (ADHD): The Feigned Adult
  ADHD index. Arch Clin Neuropsychol. 2018 Nov 1;33(7):832-44. doi:
  10.1093/arclin/acx113. PMID: 29186287.</p>
      <p>4. Amen DG, Hanks C, Prunella J. Preliminary evidence
  differentiating ADHD using brain SPECT imaging in older patients. J
  Psychoactive Drugs. 2008 Jun;40(2):139-46. doi:
  10.1080/02791072.2008.10400623. PMID: 18720662.</p>
      <p>5. Amen DG, Henderson TA, Newberg A. SPECT Functional Neuroimaging
  Distinguishes Adult Attention Deficit Hyperactivity Disorder From
  Healthy Controls in Big Data Imaging Cohorts. Front Psychiatry.
  2021;12:725788. doi: 10.3389/fpsyt.2021.725788. PMID: 34899414.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8653781/pdf/fpsyt-12-725788.pdf</p>
      <p>6. Andrikopoulos D, Vassiliou G, Fatouros P, et al. Machine
  learning-enabled detection of attention-deficit/hyperactivity disorder
  with multimodal physiological data: a case-control study. BMC
  Psychiatry. 2024;24(1). doi: 10.1186/s12888-024-05987-7.
  https://www.embase.com/search/results?subaction=viewrecord&amp;id=L2030847356&amp;from=export</p>
      <p>7. Bakare B, Jordanova V. Psychometric Properties of a Brief
  Screening Measure for ADHD in Adults. Int J Psychol Res (Medellin).
  2020 Jul-Dec;13(2):78-88. doi: 10.21500/20112084.4511. PMID: 33329880.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7735513/pdf/2011-2084-ijpr-13-02-78.pdf</p>
      <p>8. Bastiaens L, Galus J. Comparison of the Adult ADHD Self Report
  Scale Screener for DSM-IV and DSM-5 in a Dually Diagnosed Correctional
  Population. Psychiatr Q. 2018 Jun;89(2):505-10. doi:
  10.1007/s11126-017-9553-4. PMID: 29270886.
  https://link.springer.com/article/10.1007/s11126-017-9553-4</p>
      <p>9. Becke M, Tucha L, Butzbach M, et al. Feigning Adult ADHD on a
  Comprehensive Neuropsychological Test Battery: An Analogue Study. Int
  J Environ Res Public Health. 2023 Feb 24;20(5). doi:
  10.3390/ijerph20054070. PMID: 36901080.
  https://mdpi-res.com/d_attachment/ijerph/ijerph-20-04070/article_deploy/ijerph-20-04070.pdf?version=1677231890</p>
      <p>10. Berger C, Lev A, Braw Y, et al. Detection of Feigned ADHD Using
  the MOXO-d-CPT. J Atten Disord. 2021 May;25(7):1032-47. doi:
  10.1177/1087054719864656. PMID: 31364437.</p>
      <p>11. Biederman J, Hammerness P, Sadeh B, et al. Diagnostic utility
  of brain activity flow patterns analysis in attention deficit
  hyperactivity disorder. Psychol Med. 2017 May;47(7):1259-70. doi:
  10.1017/s0033291716003329. PMID: 28065167.
  https://www.cambridge.org/core/journals/psychological-medicine/article/abs/diagnostic-utility-of-brain-activity-flow-patterns-analysis-in-attention-deficit-hyperactivity-disorder/D50FB7D73029E6859363142E894C4B5E</p>
      <p>12. Brunkhorst-Kanaan N, Verdenhalven M, Kittel-Schneider S, et
  al. The Quantified Behavioral Test-A Confirmatory Test in the
  Diagnostic Process of Adult ADHD? Front Psychiatry. 2020;11:216. doi:
  10.3389/fpsyt.2020.00216. PMID: 32265761.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7100366/pdf/fpsyt-11-00216.pdf</p>
      <p>13. Chaim-Avancini TM, Doshi J, Zanetti MV, et al. Neurobiological
  support to the diagnosis of ADHD in stimulant-naïve adults: pattern
  recognition analyses of MRI data. Acta Psychiatr Scand. 2017
  Dec;136(6):623-36. doi: 10.1111/acps.12824. PMID: 29080396.
  https://onlinelibrary.wiley.com/doi/10.1111/acps.12824</p>
      <p>14. Chen T, Antoniou G, Adamou M, et al. Automatic diagnosis of
  attention deficit hyperactivity disorder using machine learning.
  Applied Artificial Intelligence. 2021;35(9):657-69. doi:
  10.1080/08839514.2021.1933761.
  https://www.tandfonline.com/doi/pdf/10.1080/08839514.2021.1933761</p>
      <p>15. Chiasson JP, Stavro K, Rizkallah É, et al. Questioning the
  specificity of ASRS-v1.1 to accurately detect ADHD in substance
  abusing populations. J Atten Disord. 2012 Nov;16(8):661-3. doi:
  10.1177/1087054711425768. PMID: 22049481.</p>
      <p>16. Cohen AL, Shapiro SK. Exploring the performance differences on
  the flicker task and the conners' continuous performance test in
  adults with ADHD. J Atten Disord. 2007 Jul;11(1):49-63. doi:
  10.1177/1087054706292162. PMID: 17606772.</p>
      <p>17. Cook CM, Bolinger E, Suhr J. Further Validation of the Conner's
  Adult Attention Deficit/Hyperactivity Rating Scale Infrequency Index
  (CII) for Detection of Non-Credible Report of Attention
  Deficit/Hyperactivity Disorder Symptoms. Arch Clin Neuropsychol. 2016
  Jun;31(4):358-64. doi: 10.1093/arclin/acw015. PMID: 27193367.</p>
      <p>18. Courrégé SC, Skeel RL, Feder AH, et al. The ADHD Symptom
  Infrequency Scale (ASIS): A novel measure designed to detect adult
  ADHD simulators. Psychol Assess. 2019 Jul;31(7):851-60. doi:
  10.1037/pas0000706. PMID: 30802120.</p>
      <p>19. Dakwar E, Mahony A, Pavlicova M, et al. The utility of
  attention-deficit/hyperactivity disorder screening instruments in
  individuals seeking treatment for substance use disorders. J Clin
  Psychiatry. 2012 Nov;73(11):e1372-8. doi: 10.4088/JCP.12m07895. PMID:
  23218166.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3627386/pdf/nihms455145.pdf</p>
      <p>20. De QUIROS GB, Kinsbourne M. Adult ADHD: Analysis of
  Self‐ratings on a Behavior Questionnaire. Annals of the New York
  Academy of Sciences. 2001;931(1):140-7.</p>
      <p>21. Dunlop BW, Wu R, Helms K. Performance of the Adult ADHD
  Self-Report Scale-v1.1 in Adults with Major Depressive Disorder. Behav
  Sci (Basel). 2018 Mar 29;8(4). doi: 10.3390/bs8040037. PMID: 29596328.
  https://mdpi-res.com/d_attachment/behavsci/behavsci-08-00037/article_deploy/behavsci-08-00037.pdf?version=1525345716</p>
      <p>22. Dvorsky MR, Langberg JM, Molitor SJ, et al. Clinical utility
  and predictive validity of parent and college student symptom ratings
  in predicting an ADHD diagnosis. Journal of Clinical Psychology.
  2016;72(4):401-18.</p>
      <p>23. Edebol H, Helldin L, Norlander T. Objective Measures of
  Behavior Manifestations in Adult ADHD and Differentiation from
  Participants with Bipolar II Disorder, Borderline Personality
  Disorder, Participants with Disconfirmed ADHD as Well as Normative
  Participants. Clin Pract Epidemiol Ment Health. 2012;8:134-43. doi:
  10.2174/1745017901208010134. PMID: 23166565.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3497060/pdf/CPEMH-8-134.pdf</p>
      <p>24. Edebol H, Helldin L, Norlander T. Measuring adult Attention
  Deficit Hyperactivity Disorder using the Quantified Behavior Test
  Plus. Psych J. 2013 Apr;2(1):48-62. doi: 10.1002/pchj.17. PMID:
  24294490.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3832237/pdf/pchj0002-0048.pdf</p>
      <p>25. Elbaum T, Braw Y, Lev A, et al. Attention-Deficit/Hyperactivity
  Disorder (ADHD): Integrating the MOXO-dCPT with an Eye Tracker
  Enhances Diagnostic Precision. Sensors (Basel). 2020 Nov 9;20(21).
  doi: 10.3390/s20216386. PMID: 33182303.
  https://mdpi-res.com/d_attachment/sensors/sensors-20-06386/article_deploy/sensors-20-06386.pdf?version=1604921168</p>
      <p>26. Emser TS, Johnston BA, Steele JD, et al. Assessing ADHD
  symptoms in children and adults: evaluating the role of objective
  measures. Behav Brain Funct. 2018 May 18;14(1):11. doi:
  10.1186/s12993-018-0143-x. PMID: 29776429.
  https://behavioralandbrainfunctions.biomedcentral.com/counter/pdf/10.1186/s12993-018-0143-x.pdf</p>
      <p>27. Erhardt D, Epstein JN, Conners CK, et al. Self-ratings of ADHD
  symptoms in adults: II. Reliability, validity, and diagnostic
  sensitivity. Journal of Attention Disorders. 1999;3(3):153-8. doi:
  10.1177/108705479900300304.</p>
      <p>28. Faraone S, Biederman J, Spencer T. Diagnostic efficiency of
  symptom items for identifying adult ADHD. Journal of ADHD &amp;
  Related Disorders. 2010;1:38-48.</p>
      <p>29. Finley JA, Brooks JM, Nili AN, et al. Multivariate examination
  of embedded indicators of performance validity for ADHD evaluations: A
  targeted approach. Appl Neuropsychol Adult. 2023 Sep 13:1-14. doi:
  10.1080/23279095.2023.2256440. PMID: 37703401.</p>
      <p>30. Finley JA, Cerny BM, Brooks JM, et al. Cross-validating the
  Clinical Assessment of Attention Deficit-Adult symptom validity scales
  for assessment of attention deficit/hyperactivity disorder in adults.
  J Clin Exp Neuropsychol. 2024 Mar;46(2):111-23. doi:
  10.1080/13803395.2023.2283940. PMID: 37994688.</p>
      <p>31. Fuermaier ABM, Tucha O, Koerts J, et al. The development of an
  embedded figures test for the detection of feigned attention deficit
  hyperactivity disorder in adulthood. PLoS ONE. 2016;11(10). doi:
  10.1371/journal.pone.0164297.
  https://www.embase.com/search/results?subaction=viewrecord&amp;id=L612656059&amp;from=export</p>
      <p>32. Galloway-Long H, Huang-Pollock C, Neely K. Ahead of the (ROC)
  Curve: A Statistical Approach to Utilizing Ex-Gaussian Parameters of
  Reaction Time in Diagnosing ADHD Across Three Developmental Periods. J
  Int Neuropsychol Soc. 2022 Sep;28(8):821-34. doi:
  10.1017/s1355617721000990. PMID: 34488917.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9521363/pdf/nihms-1780514.pdf</p>
      <p>33. Gift TE, Reimherr ML, Marchant BK, et al. Wender Utah Rating
  Scale: Psychometrics, clinical utility and implications regarding the
  elements of ADHD. J Psychiatr Res. 2021 Mar;135:181-8. doi:
  10.1016/j.jpsychires.2021.01.013. PMID: 33493947.</p>
      <p>34. Grogan K, Gormley CI, Rooney B, et al. Differential diagnosis
  and comorbidity of ADHD and anxiety in adults. Br J Clin Psychol. 2018
  Mar;57(1):99-115. doi: 10.1111/bjc.12156. PMID: 28895146.
  https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/bjc.12156</p>
      <p>35. Groom MJ, Young Z, Hall CL, et al. The incremental validity of
  a computerised assessment added to clinical rating scales to
  differentiate adult ADHD from autism spectrum disorder. Psychiatry
  Res. 2016 Sep 30;243:168-73. doi: 10.1016/j.psychres.2016.06.042.
  PMID: 27400220.</p>
      <p>36. Grünblatt E, Geissler J, Jacob CP, et al. Pilot study:
  potential transcription markers for adult attention-deficit
  hyperactivity disorder in whole blood. Atten Defic Hyperact Disord.
  2012 Jun;4(2):77-84. doi: 10.1007/s12402-012-0074-6. PMID: 22562805.
  https://core.ac.uk/download/11300165.pdf</p>
      <p>37. Hadas I, Hadar A, Lazarovits A, et al. Right prefrontal
  activation predicts ADHD and its severity: A TMS-EEG study in young
  adults. Prog Neuropsychopharmacol Biol Psychiatry. 2021 Dec
  20;111:110340. doi: 10.1016/j.pnpbp.2021.110340. PMID: 33957168.</p>
      <p>38. Harp J, Jasinski L, Shandera-Ochsner A, et al. Detection of
  Malingered ADHD Using the MMPI2RF. Psychological Injury and Law. 2011
  03/01;4:32-43. doi: 10.1007/s12207-011-9100-9.
  https://link.springer.com/content/pdf/10.1007/s12207-011-9100-9.pdf</p>
      <p>39. Harrison AG, Armstrong IT. Development of a symptom validity
  index to assist in identifying ADHD symptom exaggeration or feigning.
  Clin Neuropsychol. 2016 Feb;30(2):265-83. doi:
  10.1080/13854046.2016.1154188. PMID: 26954905.</p>
      <p>40. Harrison AG, Armstrong IT. Differences in performance on the
  test of variables of attention between credible vs. noncredible
  individuals being screened for attention deficit hyperactivity
  disorder. Appl Neuropsychol Child. 2020 Oct-Dec;9(4):314-22. doi:
  10.1080/21622965.2020.1750115. PMID: 32301339.</p>
      <p>41. Harrison AG, Edwards MJ, Parker KC. Identifying students faking
  ADHD: Preliminary findings and strategies for detection. Arch Clin
  Neuropsychol. 2007 Jun;22(5):577-88. doi: 10.1016/j.acn.2007.03.008.
  PMID: 17507198.
  https://academic.oup.com/acn/article-abstract/22/5/577/2847?redirectedFrom=fulltext</p>
      <p>42. Harrison AG, Harrison KA, Armstrong IT. Discriminating
  malingered attention Deficit Hyperactivity Disorder from genuine
  symptom reporting using novel Personality Assessment Inventory
  validity measures. Appl Neuropsychol Adult. 2022 Jan-Feb;29(1):10-22.
  doi: 10.1080/23279095.2019.1702043. PMID: 31852281.</p>
      <p>43. Harrison AG, Nay S, Armstrong IT. Diagnostic Accuracy of the
  Conners' Adult ADHD Rating Scale in a Postsecondary Population. J
  Atten Disord. 2019 Dec;23(14):1829-37. doi: 10.1177/1087054715625299.
  PMID: 26794674.</p>
      <p>44. Houston JP, Kroenke K, Faries DE, et al. A provisional
  screening instrument for four common mental disorders in adult primary
  care patients. Psychosomatics. 2011 Jan-Feb;52(1):48-55. doi:
  10.1016/j.psym.2010.11.011. PMID: 21300195.</p>
      <p>45. Jiménez EC, Avella-Garcia C, Kustow J, et al. Eye Vergence
  Responses During an Attention Task in Adults With ADHD and Clinical
  Controls. J Atten Disord. 2021 Jul;25(9):1302-10. doi:
  10.1177/1087054719897806. PMID: 31959011.</p>
      <p>46. Juselius Baghdassarian E, Nilsson Markhed M, Lindström E, et
  al. Auditory brainstem response (ABR) profiling tests as diagnostic
  support for schizophrenia and adult attention-deficit hyperactivity
  disorder (ADHD). Acta Neuropsychiatr. 2018 Jun;30(3):137-47. doi:
  10.1017/neu.2017.24. PMID: 28803577.
  https://www.cambridge.org/core/journals/acta-neuropsychiatrica/article/abs/auditory-brainstem-response-abr-profiling-tests-as-diagnostic-support-for-schizophrenia-and-adult-attentiondeficit-hyperactivity-disorder-adhd/5B1F577C0F088CA82F8B87D85D06B9FA</p>
      <p>47. Katz LJ, Wood DS, Goldstein G, et al. The utility of
  neuropsychological tests in evaluation of Attention-Deficit/
  Hyperactivity Disorder (ADHD) versus depression in adults. Assessment.
  1998 Mar;5(1):45-52. doi: 10.1177/107319119800500107. PMID:
  9458341.</p>
      <p>48. Kaur S, Singh S, Arun P, et al. Phase Space Reconstruction of
  EEG Signals for Classification of ADHD and Control Adults. Clin EEG
  Neurosci. 2020 Mar;51(2):102-13. doi: 10.1177/1550059419876525. PMID:
  31533446.</p>
      <p>49. Kessler RC, Adler L, Ames M, et al. The World Health
  Organization Adult ADHD Self-Report Scale (ASRS): a short screening
  scale for use in the general population. Psychol Med. 2005
  Feb;35(2):245-56. doi: 10.1017/s0033291704002892. PMID: 15841682.
  https://www.cambridge.org/core/journals/psychological-medicine/article/abs/world-health-organization-adult-adhd-selfreport-scale-asrs-a-short-screening-scale-for-use-in-the-general-population/28DF9AC948CE49D49B42AE9DABA325C1</p>
      <p>50. Kessler RC, Adler LA, Gruber MJ, et al. Validity of the World
  Health Organization Adult ADHD Self-Report Scale (ASRS) Screener in a
  representative sample of health plan members. Int J Methods Psychiatr
  Res. 2007;16(2):52-65. doi: 10.1002/mpr.208. PMID: 17623385.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2044504/pdf/MPR-16-52.pdf</p>
      <p>51. Kessler RC, Green JG, Adler LA, et al. Structure and diagnosis
  of adult attention-deficit/hyperactivity disorder: analysis of
  expanded symptom criteria from the Adult ADHD Clinical Diagnostic
  Scale. Arch Gen Psychiatry. 2010 Nov;67(11):1168-78. doi:
  10.1001/archgenpsychiatry.2010.146. PMID: 21041618.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3131739/pdf/nihms266485.pdf</p>
      <p>52. Khan H, Rauch AA, Obolsky MA, et al. A comparison of embedded
  validity indicators from the Stroop Color and Word Test among adults
  referred for clinical evaluation of suspected or confirmed
  attention-deficit/hyperactivity disorder. Psychol Assess. 2022
  Jul;34(7):697-703. doi: 10.1037/pas0001137. PMID: 35357873.</p>
      <p>53. Kiiski H, Rueda-Delgado LM, Bennett M, et al. Functional EEG
  connectivity is a neuromarker for adult attention deficit
  hyperactivity disorder symptoms. Clin Neurophysiol. 2020
  Jan;131(1):330-42. doi: 10.1016/j.clinph.2019.08.010. PMID:
  31506235.</p>
      <p>54. Kim S, Baek JH, Kwon YJ, et al. Machine-learning-based
  diagnosis of drug-naive adult patients with attention-deficit
  hyperactivity disorder using mismatch negativity. Transl Psychiatry.
  2021 Sep 18;11(1):484. doi: 10.1038/s41398-021-01604-3. PMID:
  34537812. https://www.nature.com/articles/s41398-021-01604-3.pdf</p>
      <p>55. Kingston DA, Ahmed AG, Gray J, et al. The assessment and
  diagnosis of attention deficit hyperactivity disorder in adult
  forensic psychiatric outpatients. Journal of Psychopathology and
  Behavioral Assessment. 2013;35(3):293-300. doi:
  10.1007/s10862-013-9346-5.
  https://www.embase.com/search/results?subaction=viewrecord&amp;id=L52480928&amp;from=export</p>
      <p>56. Kovner R, Budman C, Frank Y, et al. Neuropsychological testing
  in adult attention deficit hyperactivity disorder: a pilot study. Int
  J Neurosci. 1998 Dec;96(3-4):225-35. doi: 10.3109/00207459808986470.
  PMID: 10069622.</p>
      <p>57. Kumar G, Faden J, Steer RA. Screening for
  attention-deficit/hyperactivity disorder in adult inpatients with
  psychiatric disorders. Psychol Rep. 2011 Jun;108(3):815-24. doi:
  10.2466/03.05.09.13.15.Pr0.108.3.815-824. PMID: 21879629.</p>
      <p>58. Kwan D, Davin N, Harrison AG, et al. Determining cutoff scores
  on the Conners' adult ADHD rating scales that can definitively rule
  out the presence of ADHD in a clinical sample. Appl Neuropsychol
  Adult. 2024 Apr 3:1-11. doi: 10.1080/23279095.2024.2336204. PMID:
  38569190.</p>
      <p>59. Lancaster A, Liljequist L. Cross-validation of PAI scales for
  the detection of suspected ADHD in adults. J Clin Psychol. 2018
  Oct;74(10):1710-8. doi: 10.1002/jclp.22620. PMID: 29574728.
  https://onlinelibrary.wiley.com/doi/10.1002/jclp.22620</p>
      <p>60. Lee Booksh R, Pella RD, Singh AN, et al. Ability of college
  students to simulate ADHD on objective measures of attention. J Atten
  Disord. 2010 Jan;13(4):325-38. doi: 10.1177/1087054708329927. PMID:
  19439760.</p>
      <p>61. Lev A, Braw Y, Elbaum T, et al. Eye Tracking During a
  Continuous Performance Test: Utility for Assessing ADHD Patients. J
  Atten Disord. 2022 Jan;26(2):245-55. doi: 10.1177/1087054720972786.
  PMID: 33238787.</p>
      <p>62. Lewandowski LJ, Lovett BJ, Codding RS, et al. Symptoms of ADHD
  and academic concerns in college students with and without ADHD
  diagnoses. J Atten Disord. 2008 Sep;12(2):156-61. doi:
  10.1177/1087054707310882. PMID: 18192625.</p>
      <p>63. Liu YS, Cao B, Chokka PR. Screening for Adulthood ADHD and
  Comorbidities in a Tertiary Mental Health Center Using EarlyDetect: A
  Machine Learning-Based Pilot Study. J Atten Disord. 2023
  Feb;27(3):324-31. doi: 10.1177/10870547221136228. PMID: 36367134.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9850394/pdf/10.1177_10870547221136228.pdf</p>
      <p>64. Lovejoy DW, Ball JD, Keats M, et al. Neuropsychological
  performance of adults with attention deficit hyperactivity disorder
  (ADHD): diagnostic classification estimates for measures of frontal
  lobe/executive functioning. J Int Neuropsychol Soc. 1999
  Mar;5(3):222-33. doi: 10.1017/s1355617799533055. PMID: 10217922.
  https://www.cambridge.org/core/journals/journal-of-the-international-neuropsychological-society/article/abs/neuropsychological-performance-of-adults-with-attention-deficit-hyperactivity-disorder-adhd-diagnostic-classification-estimates-for-measures-of-frontal-lobeexecutive-functioning/CDCA0AC838EAA441C3EAC3B37D0E0735</p>
      <p>65. Luty J, Rajagopal Arokiadass SM, Sarkhel A, et al. Validation
  of self-report instruments to assess attention deficit hyperactivity
  disorder symptoms in adults attending community drug and alcohol
  services. J Addict Med. 2009 Sep;3(3):151-4. doi:
  10.1097/ADM.0b013e31819343d0. PMID: 21769011.</p>
      <p>66. Marchant BK, Reimherr FW, Wender PH, et al. Psychometric
  properties of the Self-Report Wender-Reimherr Adult Attention Deficit
  Disorder Scale. Ann Clin Psychiatry. 2015 Nov;27(4):267-77; quiz
  78-82. PMID: 26554368.</p>
      <p>67. Marshall P, Schroeder R, O'Brien J, et al. Effectiveness of
  symptom validity measures in identifying cognitive and behavioral
  symptom exaggeration in adult attention deficit hyperactivity
  disorder. Clin Neuropsychol. 2010 Oct;24(7):1204-37. doi:
  10.1080/13854046.2010.514290. PMID: 20845231.</p>
      <p>68. McCann BS, Roy-Byrne P. Screening and diagnostic utility of
  self-report attention deficit hyperactivity disorder scales in adults.
  Compr Psychiatry. 2004 May-Jun;45(3):175-83. doi:
  10.1016/j.comppsych.2004.02.006. PMID: 15124147.</p>
      <p>69. Mehringer AM, Downey KK, Schuh LM, et al. The Assessment of
  Hyperactivity and Attention (AHA): development and preliminary
  validation of a brief self-assessment of adult ADHD. J Atten Disord.
  2002 Mar;5(4):223-31. doi: 10.1177/108705470100500404. PMID:
  11967478.</p>
      <p>70. Morey LC. Examining a novel performance validity task for the
  detection of feigned attentional problems. Appl Neuropsychol Adult.
  2019 May-Jun;26(3):255-67. doi: 10.1080/23279095.2017.1409749. PMID:
  29251998.</p>
      <p>71. Mostert JC, Onnink AMH, Klein M, et al. Cognitive heterogeneity
  in adult attention deficit/hyperactivity disorder: A systematic
  analysis of neuropsychological measurements. Eur Neuropsychopharmacol.
  2015 Nov;25(11):2062-74. doi: 10.1016/j.euroneuro.2015.08.010. PMID:
  26336867.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4788979/pdf/nihms-720197.pdf</p>
      <p>72. Mueller A, Candrian G, Grane VA, et al. Discriminating between
  ADHD adults and controls using independent ERP components and a
  support vector machine: a validation study. Nonlinear Biomed Phys.
  2011 Jul 19;5:5. doi: 10.1186/1753-4631-5-5. PMID: 21771289.
  https://nonlinearbiomedphys.biomedcentral.com/counter/pdf/10.1186/1753-4631-5-5.pdf</p>
      <p>73. Müller A, Vetsch S, Pershin I, et al. EEG/ERP-based
  biomarker/neuroalgorithms in adults with ADHD: Development,
  reliability, and application in clinical practice. World J Biol
  Psychiatry. 2020 Mar;21(3):172-82. doi: 10.1080/15622975.2019.1605198.
  PMID: 30990349.</p>
      <p>74. Musso MW, Hill BD, Barker AA, et al. Utility of the Personality
  Assessment Inventory for Detecting Malingered ADHD in College
  Students. J Atten Disord. 2016 Sep;20(9):763-74. doi:
  10.1177/1087054714548031. PMID: 25204276.</p>
      <p>75. Nielsen NP, Wiig EH. AQT cognitive speed and processing
  efficiency differentiate adults with and without ADHD: a preliminary
  study. Int J Psychiatry Clin Pract. 2011 Sep;15(3):219-27. doi:
  10.3109/13651501.2011.582538. PMID: 22121933.</p>
      <p>76. Nikolas MA, Marshall P, Hoelzle JB. The role of neurocognitive
  tests in the assessment of adult attention-deficit/hyperactivity
  disorder. Psychological assessment. 2019;31(5):685.</p>
      <p>77. Notzon DP, Pavlicova M, Glass A, et al. ADHD Is Highly
  Prevalent in Patients Seeking Treatment for Cannabis Use Disorders. J
  Atten Disord. 2020 Sep;24(11):1487-92. doi: 10.1177/1087054716640109.
  PMID: 27033880.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5568505/pdf/nihms893124.pdf</p>
      <p>78. Palma-Álvarez RF, Barta C, Carpentier PJ, et al. Validity of
  the ADHD module of the Mini International Neuropsychiatric Interview
  PLUS for screening of adult ADHD in treatment seeking substance use
  disorder patients: ADHD screening with MINI-Plus. Span J Psychiatry
  Ment Health. 2023 Jan-Mar;16(1):11-5. doi: 10.1016/j.rpsm.2020.04.013.
  PMID: 32561156.</p>
      <p>79. Palmer M, Fang Z, Hollocks MJ, et al. Screening for Attention
  Deficit Hyperactivity Disorder in Young Autistic Adults: The
  Diagnostic Accuracy of Three Commonly Used Questionnaires. J Autism
  Dev Disord. 2023 Oct 28. doi: 10.1007/s10803-023-06146-9. PMID:
  37898580.
  https://link.springer.com/content/pdf/10.1007/s10803-023-06146-9.pdf</p>
      <p>80. Pettersson R, Söderström S, Nilsson KW. Diagnosing ADHD in
  Adults: An Examination of the Discriminative Validity of
  Neuropsychological Tests and Diagnostic Assessment Instruments. J
  Atten Disord. 2018 Sep;22(11):1019-31. doi: 10.1177/1087054715618788.
  PMID: 26681530.</p>
      <p>81. Phillips MS, Wisinger AM, Lapitan-Moore FT, et
  al. Cross-validation of multiple embedded performance validity indices
  in the Rey Auditory Verbal Learning Test and Brief Visuospatial Memory
  Test‑Revised in an adult attention deficit/hyperactivity disorder
  clinical sample. Psychological Injury and Law. 2023;16(1):27-35. doi:
  10.1007/s12207-022-09443-3.
  https://link.springer.com/article/10.1007/s12207-022-09443-3</p>
      <p>82. Poil SS, Bollmann S, Ghisleni C, et al. Age dependent
  electroencephalographic changes in attention-deficit/hyperactivity
  disorder (ADHD). Clin Neurophysiol. 2014 Aug;125(8):1626-38. doi:
  10.1016/j.clinph.2013.12.118. PMID: 24582383.</p>
      <p>83. Ponomarev VA, Mueller A, Candrian G, et al. Group Independent
  Component Analysis (gICA) and Current Source Density (CSD) in the
  study of EEG in ADHD adults. Clin Neurophysiol. 2014 Jan;125(1):83-97.
  doi: 10.1016/j.clinph.2013.06.015. PMID: 23871197.</p>
      <p>84. Potts HE, Lewandowski LJ, Lovett BJ. Identifying Feigned ADHD
  in College Students: Comparing the Multidimensional ADHD Rating Scale
  to Established Validity Measures. J Atten Disord. 2022
  Oct;26(12):1622-30. doi: 10.1177/10870547221092095. PMID:
  35466735.</p>
      <p>85. Quinn CA. Detection of malingering in assessment of adult ADHD.
  Arch Clin Neuropsychol. 2003 May;18(4):379-95. PMID: 14591453.</p>
      <p>86. Ramachandran S, Holmes ER, Rosenthal M, et al. Development of
  the Subtle ADHD Malingering Screener. Assessment. 2019
  Apr;26(3):524-34. doi: 10.1177/1073191118773881. PMID: 29749255.</p>
      <p>87. Reimherr FW, Marchant BK, Gift TE, et al. Psychometric data and
  versions of the Wender Utah Rating Scale including the WURS-25 &amp;
  WURS-45. Data Brief. 2021 Aug;37:107232. doi:
  10.1016/j.dib.2021.107232. PMID: 34235235.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8246143/pdf/main.pdf</p>
      <p>88. Reyes MM, Schneekloth TD, Hitschfeld MJ, et al. The Clinical
  Utility of ASRS-v1.1 for Identifying ADHD in Alcoholics Using PRISM as
  the Reference Standard. J Atten Disord. 2019 Aug;23(10):1119-25. doi:
  10.1177/1087054716646450. PMID: 27138328.</p>
      <p>89. Robeva R, Penberthy JK, Loboschefski T, et al. Combined
  psychophysiological assessment of ADHD: A pilot study of Bayesian
  probability approach illustrated by appraisal of ADHD in female
  college students. Applied Psychophysiology and Biofeedback.
  2004;29:1-18.</p>
      <p>90. Robinson A, Reed C, Davis K, et al. Settling the Score: Can
  CPT-3 Embedded Validity Indicators Distinguish Between Credible and
  Non-Credible Responders Referred for ADHD and/or SLD? J Atten Disord.
  2023 Jan;27(1):80-8. doi: 10.1177/10870547221121781. PMID:
  36113024.</p>
      <p>91. Rogers R, Velsor SF, Donnelly JW, 2nd, et al. Embedded WAIS-IV
  Detection Strategies and Feigned Cognitive Impairment: An
  Investigation of Malingered ADHD. Assessment. 2021 Jan;28(1):44-56.
  doi: 10.1177/1073191120927788. PMID: 32495690.</p>
      <p>92. Roy-Byrne P, Scheele L, Brinkley J, et al. Adult
  attention-deficit hyperactivity disorder: assessment guidelines based
  on clinical presentation to a specialty clinic. Compr Psychiatry. 1997
  May-Jun;38(3):133-40. doi: 10.1016/s0010-440x(97)90065-1. PMID:
  9154368.</p>
      <p>93. Schneider H, Thornton JF, Freeman MA, et al. Conventional SPECT
  Versus 3D Thresholded SPECT Imaging in the Diagnosis of ADHD: A
  Retrospective Study. J Neuropsychiatry Clin Neurosci. 2014
  Fall;26(4):335-43. doi: 10.1176/appi.neuropsych.12110280. PMID:
  26037855.</p>
      <p>94. Schreiber HE, Javorsky DJ, Robinson JE, et al. Rey-Osterrieth
  Complex Figure performance in adults with attention deficit
  hyperactivity disorder: a validation study of the Boston Qualitative
  Scoring System. Clin Neuropsychol. 1999 Nov;13(4):509-20. doi:
  10.1076/1385-4046(199911)13:04;1-y;ft509. PMID: 10806464.</p>
      <p>95. Selek S, Bulut M, Ocak AR, et al. Evaluation of total oxidative
  status in adult attention deficit hyperactivity disorder and its
  diagnostic implications. J Psychiatr Res. 2012 Apr;46(4):451-5. doi:
  10.1016/j.jpsychires.2011.12.007. PMID: 22257388.</p>
      <p>96. Shahaf G, Reches A, Pinchuk N, et al. Introducing a novel
  approach of network oriented analysis of ERPs, demonstrated on adult
  attention deficit hyperactivity disorder. Clin Neurophysiol. 2012
  Aug;123(8):1568-80. doi: 10.1016/j.clinph.2011.12.010. PMID:
  22261156.</p>
      <p>97. Shepler DK, Callan PD. Differences in executive functioning
  between adults with ADHD and those diagnosed with other psychiatric
  diagnoses: Utility of the CTMT and the WAIS-IV. Appl Neuropsychol
  Adult. 2024 Sep-Oct;31(5):984-93. doi: 10.1080/23279095.2022.2102923.
  PMID: 35894662.</p>
      <p>98. Singh P, White S, Saleem K, et al. Identifying ADHD in adults
  using the international personality disorder examination screening
  questionnaire. J Ment Health. 2015 Aug;24(4):236-41. doi:
  10.3109/09638237.2015.1057331. PMID: 26445014.</p>
      <p>99. Skirrow C, Asherson P. Emotional lability, comorbidity and
  impairment in adults with attention-deficit hyperactivity disorder.
  Journal of affective disorders. 2013;147(1-3):80-6.
  https://www.sciencedirect.com/science/article/abs/pii/S016503271200688X?via%3Dihub</p>
      <p>100. Smith ST, Cox J, Mowle EN, et al. Intentional inattention:
  Detecting feigned attention-deficit/hyperactivity disorder on the
  Personality Assessment Inventory. Psychol Assess. 2017
  Dec;29(12):1447-57. doi: 10.1037/pas0000435. PMID: 29227126.</p>
      <p>101. Söderström S, Pettersson R, Nilsson KW. Quantitative and
  subjective behavioural aspects in the assessment of attention-deficit
  hyperactivity disorder (ADHD) in adults. Nord J Psychiatry. 2014
  Jan;68(1):30-7. doi: 10.3109/08039488.2012.762940. PMID: 23527787.</p>
      <p>102. Solanto MV, Etefia K, Marks DJ. The utility of self-report
  measures and the continuous performance test in the diagnosis of ADHD
  in adults. CNS Spectr. 2004 Sep;9(9):649-59. doi:
  10.1017/s1092852900001929. PMID: 15337862.
  https://www.cambridge.org/core/journals/cns-spectrums/article/abs/utility-of-selfreport-measures-and-the-continuous-performance-test-in-the-diagnosis-of-adhd-in-adults/CC8BB59E83E5404C3DD2BA66D6EFF9A2</p>
      <p>103. Sollman MJ, Ranseen JD, Berry DT. Detection of feigned ADHD in
  college students. Psychol Assess. 2010 Jun;22(2):325-35. doi:
  10.1037/a0018857. PMID: 20528060.</p>
      <p>104. Spenceley LM, Wood WLM, Lovett BJ. Using the Woodcock-Johnson
  IV tests of cognitive abilities to detect feigned ADHD. Appl
  Neuropsychol Adult. 2022 May-Jun;29(3):324-32. doi:
  10.1080/23279095.2020.1748631. PMID: 32320323.</p>
      <p>105. Suhr J, Hammers D, Dobbins-Buckland K, et al. The relationship
  of malingering test failure to self-reported symptoms and
  neuropsychological findings in adults referred for ADHD evaluation.
  Arch Clin Neuropsychol. 2008 Sep;23(5):521-30. doi:
  10.1016/j.acn.2008.05.003. PMID: 18562158.
  https://watermark.silverchair.com/23-5-521.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA10wggNZBgkqhkiG9w0BBwagggNKMIIDRgIBADCCAz8GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM8-Tr8CrC8n8M5lj-AgEQgIIDEPBFG_m1qzONPS4mO4YJz5JQBLTTaDLZqFeBeFPG_BkijkHDOEWq1A_Pp8rWUGNem9CS5D_JHjMTR3APwSAf0uZwZTE0jmBQi7H6fzTfYPYN7ptq3nz4iK1NAQyP8en61s8pRtzUaRiggVJsG2urO2QBrdWREDbipTo62zMKftdOMCF4FX0C_2OX6opKxS_zp6-Wxb3kTmvoXp07qQkKuIYwRwF_210y-lmXAgWC6TJaJJL3yVc3OrAmoCzidyAs3EVlmEam0UQiXm1qvU_l6GqD1c7zxb2QtIZRywG_5fTRrdQByVrdz5vXaBTHmaO1AEcg2glGfN1LRATGZHyH9lQAJHEhVNxH21nWAFKCAnlsxTkaxhIjgPNNjOwBSfu08LzV232aB3n16X4CEg53VXNpbYJZtUNVzvKcOJlBnw5BmUUE_986JliazEdpoQwUNp9SwRpcQfIz8nsVRMYUpAzRgzzx1iQ0e6aIpPke_XdxufPLMRbdMUO7MPBzONaPIjwfiUJ-Km0XCC6RInnRtPOX9eyCogoaDe_51v-Ut347ZJrYNHBmzbW8Y2l2z1jUiUA__a0cHq1VmcqezhX-SMLJU9u4BnOb8kONahKdiN8QK7jEqzjU-MG-lcYT8KO9s6ciTxml_KuWiR9-nQw0uJKKpCXn2YQZMud4J730koTX3tfK5--YtHR30DUDnAfI7NLUjZSWbqGcpdBonaiNe9b3ELpWMsXH3wSLVtQdcMNQbHlK0a3nW9tYxD08Gm75zwfAtHkIl9vIGF8c49JIKFe1-7hrlimZtdywf5RDzkps9Z2q8jYBdfEkTRNh9NOBhgzWbzatBg_RwKHA8M8sYSGB7GM4G2-ERVHC_UIJqONG3g_DSYO6wCvwM-MXCva805lqeYFcH31PPcArGxpZE0Y1sNyYl-3xoQOX-IbhX4F1VZJMZez6DNHlUDSfkRnV3BYpcoamBWs4TdxCJGbkfw8jV6ciR0zDDdzxUWE509zoGHWEYUn9glbRkyGyfhixTChEF29076ON_22VVfqQMGA</p>
      <p>106. Suhr JA, Buelow M, Riddle T. Development of an infrequency
  index for the CAARS. Journal of Psychoeducational Assessment.
  2011;29(2):160-70. doi: 10.1177/0734282910380190.</p>
      <p>107. Udal ABH, Stray LL, Pripp AH, et al. The Utility of
  Neuromuscular Assessment to Identify ADHD Among Patients with a
  Complex Symptom Picture. Journal of attention disorders.
  2024;28(12):1577-88. doi: 10.1177/10870547241273102.
  https://www.embase.com/search/results?subaction=viewrecord&amp;id=L645163091&amp;from=export</p>
      <p>108. Unal M, O'Mahony E, Dunne C, et al. The clinical utility of
  three visual attention tests to distinguish adults with ADHD from
  normal controls. Riv Psichiatr. 2019 Sep-Oct;54(5):211-7. doi:
  10.1708/3249.32185. PMID: 31657805.
  https://www.rivistadipsichiatria.it/r.php?&amp;v=3249&amp;a=32185&amp;l=338622&amp;f=allegati/03249_2019_05/fulltext/04-Unal
  (211-217).pdf</p>
      <p>109. Ustun B, Adler LA, Rudin C, et al. The World Health
  Organization Adult Attention-Deficit/Hyperactivity Disorder
  Self-Report Screening Scale for DSM-5. JAMA Psychiatry. 2017 May
  1;74(5):520-7. doi: 10.1001/jamapsychiatry.2017.0298. PMID: 28384801.
  https://jamanetwork.com/journals/jamapsychiatry/fullarticle/2616166</p>
      <p>110. van de Glind G, van den Brink W, Koeter MW, et al. Validity of
  the Adult ADHD Self-Report Scale (ASRS) as a screener for adult ADHD
  in treatment seeking substance use disorder patients. Drug Alcohol
  Depend. 2013 Oct 1;132(3):587-96. doi:
  10.1016/j.drugalcdep.2013.04.010. PMID: 23660242.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4083506/pdf/nihms598068.pdf</p>
      <p>111. Van Voorhees EE, Hardy KK, Kollins SH. Reliability and
  validity of self- and other-ratings of symptoms of ADHD in adults. J
  Atten Disord. 2011 Apr;15(3):224-34. doi: 10.1177/1087054709356163.
  PMID: 20424007.
  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3556723/pdf/nihms432446.pdf</p>
      <p>112. Vizgaitis AL, Bottini S, Polizzi CP, et al. Self-Reported
  Adult ADHD Symptoms: Evidence Supporting Cautious Use in an
  Assessment-Seeking Sample. J Atten Disord. 2023 Aug;27(10):1156-66.
  doi: 10.1177/10870547231172764. PMID: 37158158.</p>
      <p>113. Walls BD, Wallace ER, Brothers SL, et al. Utility of the
  Conners' Adult ADHD Rating Scale validity scales in identifying
  simulated attention-deficit hyperactivity disorder and random
  responding. Psychol Assess. 2017 Dec;29(12):1437-46. doi:
  10.1037/pas0000530. PMID: 29227125.</p>
      <p>114. Wang X, Jiao Y, Tang T, et al. Altered regional homogeneity
  patterns in adults with attention-deficit hyperactivity disorder. Eur
  J Radiol. 2013 Sep;82(9):1552-7. doi: 10.1016/j.ejrad.2013.04.009.
  PMID: 23684384.
  https://www.ejradiology.com/article/S0720-048X(13)00204-0/abstract</p>
      <p>115. Wiig EH, Nielsen NP. A quick test of cognitive speed for
  comparing processing speed to differentiate adult psychiatric
  referrals with and without attention-deficit/hyperactivity disorders.
  Prim Care Companion CNS Disord. 2012;14(2). doi: 10.4088/PCC.11m01273.
  PMID: 22943032.</p>
      <p>116. Williamson KD, Combs HL, Berry DT, et al. Discriminating among
  ADHD alone, ADHD with a comorbid psychological disorder, and feigned
  ADHD in a college sample. Clin Neuropsychol. 2014;28(7):1182-96. doi:
  10.1080/13854046.2014.956674. PMID: 25225947.</p>
      <p>117. Woods SP, Lovejoy DW, Stutts ML, et al. Comparative efficiency
  of a discrepancy analysis for the classification of
  Attention-Deficit/Hyperactivity Disorder in adults. Arch Clin
  Neuropsychol. 2002 May;17(4):351-69. PMID: 14589720.</p>
      <p>118. Yao D, Guo X, Zhao Q, et al. Discriminating ADHD From Healthy
  Controls Using a Novel Feature Selection Method Based on Relative
  Importance and Ensemble Learning. Annu Int Conf IEEE Eng Med Biol Soc.
  2018 Jul;2018:4632-5. doi: 10.1109/embc.2018.8513155. PMID: 30441383.
  https://ieeexplore.ieee.org/document/8513155/</p>
      <p>119. Young JC, Gross AM. Detection of response bias and noncredible
  performance in adult attention-deficit/hyperactivity disorder. Arch
  Clin Neuropsychol. 2011 Apr;26(3):165-75. doi: 10.1093/arclin/acr013.
  PMID: 21441258.</p>
      <p>120. Young JL, Powell RN, Zabel C, et al. Development and
  validation of the ADHD Symptom and Side Effect Tracking - Baseline
  Scale (ASSET-BS): a novel short screening measure for ADHD in clinical
  populations. BMC Psychiatry. 2023 Nov 6;23(1):806. doi:
  10.1186/s12888-023-05295-6. PMID: 37932675.
  https://bmcpsychiatry.biomedcentral.com/counter/pdf/10.1186/s12888-023-05295-6.pdf</p>
      <p>121. Young S, González RA, Mutch L, et al. Diagnostic accuracy of a
  brief screening tool for attention deficit hyperactivity disorder in
  UK prison inmates. Psychol Med. 2016 May;46(7):1449-58. doi:
  10.1017/s0033291716000039. PMID: 26867860.
  https://www.cambridge.org/core/journals/psychological-medicine/article/abs/diagnostic-accuracy-of-a-brief-screening-tool-for-attention-deficit-hyperactivity-disorder-in-uk-prison-inmates/88212D6658B833DE8E7FA85585EA4D8A</p>
    </sec>
  </body>
  <back>
</back>
  <sub-article article-type="notebook" id="nb-3-nb-1">
    <front-stub>
</front-stub>
    <body>
      <sec id="contributing-nb-1">
        <title>Contributing</title>
        <p>The source files are under the <monospace>sources</monospace>
  subdirectory. The <monospace>.sfd</monospace> files are FontForge
  source font format and should be edited with
  <ext-link ext-link-type="uri" xlink:href="https://fontforge.org">FontForge</ext-link>.
  The <monospace>.fea</monospace> files are
  <ext-link ext-link-type="uri" xlink:href="https://adobe-type-tools.github.io/afdko/OpenTypeFeatureFileSpecification.html">OpenType
  feature files</ext-link> and should be edited by a plain text
  editor.</p>
        <p>To build the fonts locally, you will need to setup
  <ext-link ext-link-type="uri" xlink:href="https://github.com/theleagueof/fontship">Fontship</ext-link>.
  Several methods are available for installation including a simple
  one-liner with no installation
  <ext-link ext-link-type="uri" xlink:href="https://github.com/theleagueof/fontship#docker-setup">using
  Docker</ext-link>. One Fontship is setup, regenerate the fonts at any
  time using:</p>
        <preformat>fontship make</preformat>
        <p>A remote CI runner will also automatically run
  <monospace>fontship</monospace> for all PRs on this repository, so in
  some cases you may not need to install it at all. You can even
  download and review the fonts it builds after each push. Hovever this
  is cumbersome for actual font development and we recomend checking
  your work with local feedback.</p>
        <p>Note that FontForge adds unnecessary clutter to its source files on
  each save that <bold>must</bold> be removed before committing. After
  modifying the <monospace>.sfd</monospace> files, and before committing
  the changes, you can automatically clean them up with:</p>
        <preformat>fontship make normalize</preformat>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
</article>
